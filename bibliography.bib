% Encoding: UTF-8
@inproceedings{girshick2014rich,
  title={Rich feature hierarchies for accurate object detection and semantic segmentation},
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={580--587},
  year={2014}
}
@incollection{NIPS2012_4824,
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  title={Imagenet classification with deep convolutional neural networks},
  booktitle = {Advances in Neural Information Processing Systems 25},
  editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
  volume={25},
  pages={1097--1105},
  year={2012}
}
@inproceedings{wienhofen2016defining,
  title={Defining the Initial Case-Base for a CBR Operator Support System in Digital Finishing},
  author={Wienhofen, Leendert WM and Mathisen, Bj{\o}rn Magnus},
  booktitle={International Conference on Case-Based Reasoning},
  pages={430--444},
  year={2016},
  organization={Springer}
}
@inproceedings{gulbrandsen2012social,
  title={Social Network for Elderly.},
  author={Gulbrandsen, Simen Kind and Fikkan, Eirik and Grunt, Emil and Mehl, Kjetil and Shamsolketabi, Safoura and Singh, Jaspreet and Vrucinic, Miso and Mathisen, Bj{\o}rn Magnus and Kofod-Petersen, Anders},
  booktitle={IICS},
  pages={28--37},
  year={2012}
}
@inproceedings{mathisen2012co,
  title={Co-Living Social Community for Elderly.},
  author={Mathisen, Bj{\o}rn Magnus and Kofod-Petersen, Anders and Olalde, Idoia},
  booktitle={IICS},
  pages={38--46},
  year={2012}
}
@inproceedings{strisland2013esums,
  title={ESUMS: A mobile system for continuous home monitoring of rehabilitation patients},
  author={Strisland, Frode and Svagard, Ingrid and Seeberg, Trine M and Mathisen, Bjorn Magnus and Vedum, Jon and Austad, Hanne O and Liverud, Anders E and Kofod-Petersen, Anders and Bendixen, Ole Christian},
  booktitle={Engineering in Medicine and Biology Society (EMBC), 2013 35th Annual International Conference of the IEEE},
  pages={4670--4673},
  year={2013},
  organization={IEEE}
}
@article{mathisen2007evolving,
  title={Evolving a roving-eye for go revisited},
  author={Mathisen, Bj{\o}rn Magnus},
  year={2007},
  publisher={Institutt for datateknikk og informasjonsvitenskap}
}
@incollection{mathisen2013social,
  title={Social sub-group identification using social graph and semantic analysis},
  author={Mathisen, Bj{\o}rn Magnus and Kofod-Petersen, Anders and McGovern, John and Vilarinho, Thomas and Farshchian, Babak A},
  booktitle={Workshop Proceedings of the 9th International Conference on Intelligent Environments},
  volume={17},
  pages={90},
  year={2013},
  publisher={IOS Press}
}
@incollection{vilarinho2013communication,
  title={A Communication Framework for the Internet of People and Things Based on the Concept of Activity Feeds in Social Computing},
  author={Vilarinho, Thomas and Farshchian, Babak A and Floch, Jacqueline and Mathisen, Bj{\o}rn Magnus},
  booktitle={2013 9th International Conference on Intelligent Environments},
  year={2013},
  publisher={IEEE conference proceedings}
}
@incollection{roman2014linked,
  title={The Linked Data AppStore},
  author={Roman, Dumitru and Pop, Claudia Daniela and Roman, Roxana I and Mathisen, Bj{\o}rn Magnus and Wienhofen, Leendert and Elves{\ae}ter, Brian and Berre, Arne J},
  booktitle={Mining Intelligence and Knowledge Exploration},
  pages={382--396},
  year={2014},
  publisher={Springer}
}

@article{mathisen2020opsitu,
author="Mathisen, Bj{\o}rn Magnus
and Bach, Kerstin
and Aamodt, Agnar",
title="Using extended siamese networks in a CBR system to provide decision
  support in aquaculture operations",
journal="Applied Intelligence",
year=2021
}
@article{kaya2019deep,
  title={Deep metric learning: A survey},
  author={Kaya, Mahmut and Bilge, Hasan {\c{S}}akir},
  journal={Symmetry},
  volume={11},
  number={9},
  pages={1066},
  year={2019},
  publisher={Multidisciplinary Digital Publishing Institute}
}
@InProceedings{keane2019,
author="Keane, Mark T.
and Kenny, Eoin M.",
editor="Bach, Kerstin
and Marling, Cindy",
title="How case-based reasoning explains neural networks: A theoretical analysis of XAI using post-hoc explanation-by-example from a survey of ANN-CBR twin-systems",
booktitle="Case-Based Reasoning Research and Development",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="155--171",
abstract="This paper proposes a theoretical analysis of one approach to the eXplainable AI (XAI) problem, using post-hoc explanation-by-example, that relies on the twinning of artificial neural networks (ANNs) with case-based reasoning (CBR) systems; so-called ANN-CBR twins. It surveys these systems to advance a new theoretical interpretation of previous work and define a road map for CBR's further role in XAI. A systematic survey of 1,102 papers was conducted to identify a fragmented literature on this topic and trace its influence to more recent work involving deep neural networks (DNNs). The twin-systems approach is advanced as one possible coherent, generic solution to the XAI problem. The paper concludes by road-mapping future directions for this XAI solution, considering (i) further tests of feature-weighting techniques, (ii) how explanatory cases might be deployed (e.g., in counterfactuals, a fortori cases), and (iii) the unwelcome, much-ignored issue of user evaluation.",
isbn="978-3-030-29249-2"
}

@article{golshani2017two,
  title={Two-stage adaptive restoration decision support system for a self-healing power grid},
  author={Golshani, Amir and Sun, Wei and Zhou, Qun and Zheng, Qipeng P and Tong, Jianzhong},
  journal={IEEE Transactions on Industrial Informatics},
  volume={13},
  number={6},
  pages={2802--2812},
  year={2017},
  publisher={IEEE}
}

@book{schank1983dynamic,
  title={Dynamic memory: A theory of reminding and learning in computers and people},
  author={Schank, Roger C},
  year={1983},
  publisher={Cambridge University Press}
}
@article{sormo2005explanation,
  title={Explanation in case-based reasoning--perspectives and goals},
  author={S{\o}rmo, Frode and Cassens, J{\"o}rg and Aamodt, Agnar},
  journal={Artificial Intelligence Review},
  volume={24},
  number={2},
  pages={109--143},
  year={2005},
  publisher={Springer}
}

@Article{Mathisen2019,
  author   = {Mathisen, Bj{\o}rn Magnus and Aamodt, Agnar and Bach, Kerstin and Langseth, Helge},
  journal  = {Progress in Artificial Intelligence},
  title    = {Learning similarity measures from data},
  year     = {2019},
  issn     = {2192-6360},
  month    = {10},
  pages    = {129-143},
  abstract = {Defining similarity measures is a requirement for some machine learning methods. One such method is case-based reasoning (CBR) where the similarity measure is used to retrieve the stored case or a set of cases most similar to the query case. Describing a similarity measure analytically is challenging, even for domain experts working with CBR experts. However, datasets are typically gathered as part of constructing a CBR or machine learning system. These datasets are assumed to contain the features that correctly identify the solution from the problem features; thus, they may also contain the knowledge to construct or learn such a similarity measure. The main motivation for this work is to automate the construction of similarity measures using machine learning. Additionally, we would like to do this while keeping training time as low as possible. Working toward this, our objective is to investigate how to apply machine learning to effectively learn a similarity measure. Such a learned similarity measure could be used for CBR systems, but also for clustering data in semi-supervised learning, or one-shot learning tasks. Recent work has advanced toward this goal which relies on either very long training times or manually modeling parts of the similarity measure. We created a framework to help us analyze the current methods for learning similarity measures. This analysis resulted in two novel similarity measure designs: The first design uses a pre-trained classifier as basis for a similarity measure, and the second design uses as little modeling as possible while learning the similarity measure from data and keeping training time low. Both similarity measures were evaluated on 14 different datasets. The evaluation shows that using a classifier as basis for a similarity measure gives state-of-the-art performance. Finally, the evaluation shows that our fully data-driven similarity measure design outperforms state-of-the-art methods while keeping training time low.},
  day      = {30},
  doi      = {10.1007/s13748-019-00201-2},
}

@Misc{tensorflow2015-whitepaper,
  author = {Mart{\'i}n~Abadi and Ashish~Agarwal and Paul~Barham and Eugene~Brevdo and Zhifeng~Chen and Craig~Citro and Greg~S.~Corrado and Andy~Davis and Jeffrey~Dean and Matthieu~Devin and Sanjay~Ghemawat and Ian~Goodfellow and Andrew~Harp and Geoffrey~Irving and Michael~Isard and Yangqing Jia and Rafal~Jozefowicz and Lukasz~Kaiser and Manjunath~Kudlur and Josh~Levenberg and Dan~Man{\'e} and Rajat~Monga and Sherry~Moore and Derek~Murray and Chris~Olah and Mike~Schuster and Jonathon~Shlens and Benoit~Steiner and Ilya~Sutskever and Kunal~Talwar and Paul~Tucker and Vincent~Vanhoucke and Vijay~Vasudevan and Fernanda~Vi{\'e}gas and Oriol~Vinyals and Pete~Warden and Martin~Wattenberg and Martin~Wicke and Yuan~Yu and Xiaoqiang~Zheng},
  note   = {Software available from tensorflow.org},
  title  = {{TensorFlow}: Large-scale machine learning on heterogeneous systems},
  year   = {2015},
  url    = {http://tensorflow.org/},
}

%powerdss start

@article{wang2018review,
  title={Review of smart meter data analytics: Applications, methodologies, and challenges},
  author={Wang, Yi and Chen, Qixin and Hong, Tao and Kang, Chongqing},
  journal={IEEE Transactions on Smart Grid},
  volume={10},
  number={3},
  pages={3125--3148},
  year={2018},
  publisher={IEEE}
}
@inproceedings{sharma2011predicting,
  title={Predicting solar generation from weather forecasts using machine learning},
  author={Sharma, Navin and Sharma, Pranshu and Irwin, David and Shenoy, Prashant},
  booktitle={2011 IEEE international conference on smart grid communications (SmartGridComm)},
  pages={528--533},
  year={2011},
  organization={IEEE}
}
@techreport{morchusecase19,
     title = {Use cases for future (2030-2040) smart distribution
grid operation},
     author = {Morch, Andrei Z. and Istad, Maren and Ingebrigtsen, Karoline and Garn{\aa}s, Synne and Foros, J{\o}rn and Mathisen, Bj{\o}rn M.},
     utl = {https://www.sintef.no/projectweb/cinxeldi/results/reports/},
     year = {2019},
}
@techreport{sasutilanalytics17,
     title = {Utility analytics in 2017: Aligning data and analytics with business strategy},
     author = {SAS},
     utl = {https://www.sas.com/content/dam/SAS/en_us/doc/whitepaper1/utility-analytics-108902.pdf},
     year = {2017},
}
@article{rudin2011machine,
  title={Machine learning for the New York City power grid},
  author={Rudin, Cynthia and Waltz, David and Anderson, Roger N and Boulanger, Albert and Salleb-Aouissi, Ansaf and Chow, Maggie and Dutta, Haimonti and Gross, Philip N and Huang, Bert and Ierome, Steve and others},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={34},
  number={2},
  pages={328--345},
  year={2011},
  publisher={IEEE}
}

@article{jiang2016a,
	Author = {Jiang, Y.},
	Date = {2016},
	Date-Added = {2020-03-24 18:09:08 +0100},
	Date-Modified = {2020-03-24 18:09:08 +0100},
	Journal = {IEEE Transactions on power systems},
	More-Authors = {true},
	Number = {5},
	Pages = {4144--4154},
	Title = {Outage management of distribution systems incorporating information from smart meter,},
	Volume = {31}}

@article{lee-a,
  title={A fuzzy expert system for the integrated fault diagnosis},
  author={Lee, Heung-Jae and Park, Deung-Yong and Ahn, Bok-Shin and Park, Young-Moon and Park, Jong-Keun and Venkata, SS},
  journal={IEEE Transactions on Power Delivery},
  volume={15},
  number={2},
  pages={833--838},
  year={2000},
  publisher={IEEE}
}
}

@article{yang1992a,
	Author = {Yang, C. and Okamoto, H. and Yokoyama, A. and Sekine, Y.},
	Year = 1992,
	Date-Added = {2020-03-24 18:03:50 +0100},
	Date-Modified = {2020-03-24 18:03:50 +0100},
	Journal = {International Journal of Electrical Power \& Energy Systems},
	Pages = {2--3},
	Title = {Expert system for fault section estimation of power systems using time-sequence information,},
	Volume = 14}

@article{thukaram2005a,
	Author = {Thukaram, D. and Khincha, H. and Vijaynarasimha, H.},
	Date = {2005},
	Date-Added = {2020-03-24 18:05:21 +0100},
	Date-Modified = {2020-03-24 18:05:21 +0100},
	Journal = {IEEE Transactions on Power Delivery},
	Number = {2},
	Pages = {710--721},
	Title = {Artificial neural network and support vector machine approach for locating faults in radial distribution systems,},
	Volume = {20}}

@article{q2015a,
  Author = {Q.Wei, D.Liu and Shi, G.},
  Date = {2015},
  Date-Added = {2020-03-24 18:05:59 +0100},
  Date-Modified = {2020-03-24 18:05:59 +0100},
  Journal = {IEEE Transactions on Industrial Electronics},
  Number = {4},
  Pages = {2509--2518},
  Title = {A novel dual iterative Q- learning method for optimal battery management in smart residential environments,},
  Volume = {62}}

@article{j2014a,
	Author = {J. Morales, E. Ordu{\~n}a and Rehtanz, C.},
	Date = {2014},
	Date-Added = {2020-03-24 18:06:26 +0100},
	Date-Modified = {2020-03-24 18:06:26 +0100},
	Journal = {International Journal of Electrical Power \& Energy Systems},
	Pages = {19--31},
	Title = {Classification of lightning stroke on transmission line using multi- resolution analysis and machine learning,},
	Volume = {58}}

@article{rafinia2014a,
	Author = {Rafinia, A. and Moshtagh, J.},
	Date = {2014},
	Date-Added = {2020-03-24 18:06:54 +0100},
	Date-Modified = {2020-03-24 18:06:54 +0100},
	Journal = {International Journal of Electrical Power \& Energy Systems},
	Pages = {261--274},
	Title = {A new approach to fault location in three-phase underground distribution system using combination of wavelet analysis with ANN and FLS,},
	Volume = {55}}

@article{samantaray2007a,
	Author = {Samantaray, S. and Dash, P. and Panda, G.},
	Date = {2007},
	Date-Added = {2020-03-24 18:07:30 +0100},
	Date-Modified = {2020-03-24 18:07:30 +0100},
	Journal = {International Journal of Electrical Power \& Energy Systems},
	Number = {7},
	Pages = {551--556},
	Title = {Distance relaying for transmission line using support vector machine and radial basis function neural network,},
	Volume = {29}}

@article{ekici2012a,
	Author = {Ekici, S.},
	Date = {2012},
	Date-Added = {2020-03-24 18:07:45 +0100},
	Date-Modified = {2020-03-24 18:07:45 +0100},
	Journal = {Applied Soft Computing},
	Number = {6},
	Pages = {1650--1658},
	Title = {Support Vector Machines for classification and locating faults on transmission lines,},
	Volume = {12}}

@article{ferreira2016a,
	Author = {Ferreira, V.},
	Date = {2016},
	Date-Added = {2020-03-24 18:08:22 +0100},
	Date-Modified = {2020-03-24 18:08:22 +0100},
	Journal = {Electric Power Systems Research},
	More-Authors = {true},
	Pages = {135--153},
	Title = {A survey on intelligent system application to fault diagnosis in electric power system transmission lines,},
	Volume = {136}}

@Online{myhrsmartgrid,
  author       = {Myhr Ingrid},
  date         = {2019-05-02},
  doi          = {10/1100},
  organization = {Danske Bank},
  title        = {Smartgrid conference},
  urldate      = {2019-05-04},
}


% end powerdss


@incollection{NIPS2019_8487,
title = {Discrimination in Online Markets: Effects of Social Bias on Learning from Reviews and Policy Design},
author = {Monachou, Faidra Georgia and Ashlagi, Itai},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {2142--2152},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8487-discrimination-in-online-markets-effects-of-social-bias-on-learning-from-reviews-and-policy-design.pdf}
}
@incollection{NIPS2019_9471,
title = {Episodic Memory in Lifelong Language Learning},
author = {de Masson d\textquotesingle Autume, Cyprien and Ruder, Sebastian and Kong, Lingpeng and Yogatama, Dani},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {13122--13131},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9471-episodic-memory-in-lifelong-language-learning.pdf}
}
@incollection{NIPS2019_9061,
title = {Large Memory Layers with Product Keys},
author = {Lample, Guillaume and Sablayrolles, Alexandre and Ranzato, Marc\textquotesingle Aurelio and Denoyer, Ludovic and Jegou, Herve},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {8546--8557},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9061-large-memory-layers-with-product-keys.pdf}
}
@incollection{NIPS2019_9351,
title = {On the Downstream Performance of Compressed Word Embeddings},
author = {May, Avner and Zhang, Jian and Dao, Tri and R{\'e}, Christopher},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {11782--11793},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9351-on-the-downstream-performance-of-compressed-word-embeddings.pdf}
}
@incollection{NIPS2019_8740,
title = {Breaking the Glass Ceiling for Embedding-Based Classifiers for Large Output Spaces},
author = {Guo, Chuan and Mousavi, Ali and Wu, Xiang and Holtmann-Rice, Daniel N and Kale, Satyen and Reddi, Sashank and Kumar, Sanjiv},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {4944--4954},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8740-breaking-the-glass-ceiling-for-embedding-based-classifiers-for-large-output-spaces.pdf}
}
@incollection{NIPS2019_8771,
title = {Learning Disentangled Representation for Robust Person Re-identification},
author = {Eom, Chanho and Ham, Bumsub},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {5298--5309},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8771-learning-disentangled-representation-for-robust-person-re-identification.pdf}
}
@incollection{NIPS2019_9539,
title = {GOT: An Optimal Transport framework for Graph comparison},
author = {Petric Maretic, Hermina and El Gheche, Mireille and Chierchia, Giovanni and Frossard, Pascal},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {13876--13887},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9539-got-an-optimal-transport-framework-for-graph-comparison.pdf}
}

@incollection{NIPS2019_8611,
title = {Making AI Forget You: Data Deletion in Machine Learning},
author = {Ginart, Antonio and Guan, Melody and Valiant, Gregory and Zou, James Y},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {3513--3526},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8611-making-ai-forget-you-data-deletion-in-machine-learning.pdf}
}
@incollection{NIPS2019_8596,
title = {Transfusion: Understanding Transfer Learning for Medical Imaging},
author = {Raghu, Maithra and Zhang, Chiyuan and Kleinberg, Jon and Bengio, Samy},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {3342--3352},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8596-transfusion-understanding-transfer-learning-for-medical-imaging.pdf}
}

@incollection{NIPS2019_9355,
title = {Attribution-Based Confidence Metric For Deep Neural Networks},
author = {Jha, Susmit and Raj, Sunny and Fernandes, Steven and Jha, Sumit K and Jha, Somesh and Jalaian, Brian and Verma, Gunjan and Swami, Ananthram},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {11826--11837},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9355-attribution-based-confidence-metric-for-deep-neural-networks.pdf}
}

@incollection{NIPS2019_9704,
title = {On the Transfer of Inductive Bias from Simulation to the Real World: a New Disentanglement Dataset},
author = {Gondal, Muhammad Waleed and Wuthrich, Manuel and Miladinovic, Djordje and Locatello, Francesco and Breidt, Martin and Volchkov, Valentin and Akpo, Joel and Bachem, Olivier and Sch\"{o}lkopf, Bernhard and Bauer, Stefan},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {15714--15725},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9704-on-the-transfer-of-inductive-bias-from-simulation-to-the-real-world-a-new-disentanglement-dataset.pdf}
}

@article{gonzalez2019improved,
  title={Improved Training Speed, Accuracy, and Data Utilization Through Loss Function Optimization},
  author={Gonzalez, Santiago and Miikkulainen, Risto},
  journal={arXiv preprint arXiv:1905.11528},
  year={2019}
}
@article{dasgupta2019causal,
  title={Causal reasoning from meta-reinforcement learning},
  author={Dasgupta, Ishita and Wang, Jane and Chiappa, Silvia and Mitrovic, Jovana and Ortega, Pedro and Raposo, David and Hughes, Edward and Battaglia, Peter and Botvinick, Matthew and Kurth-Nelson, Zeb},
  journal={arXiv preprint arXiv:1901.08162},
  year={2019}
}
@article{song2019maml,
  title={Es-maml: Simple hessian-free meta learning},
  author={Song, Xingyou and Gao, Wenbo and Yang, Yuxiang and Choromanski, Krzysztof and Pacchiano, Aldo and Tang, Yunhao},
  journal={arXiv preprint arXiv:1910.01215},
  year={2019}
}
@incollection{NIPS2019_9165,
title = {Regularization Matters: Generalization and Optimization of Neural Nets v.s. their Induced Kernel},
author = {Wei, Colin and Lee, Jason D and Liu, Qiang and Ma, Tengyu},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {9709--9721},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9165-regularization-matters-generalization-and-optimization-of-neural-nets-vs-their-induced-kernel.pdf}
}
@incollection{NIPS2019_8872,
title = {Wasserstein Weisfeiler-Lehman Graph Kernels},
author = {Togninalli, Matteo and Ghisu, Elisabetta and Llinares-L{\'o}pez, Felipe and Rieck, Bastian and Borgwardt, Karsten},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {6436--6446},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8872-wasserstein-weisfeiler-lehman-graph-kernels.pdf}
}
@incollection{NIPS2019_8595,
title = {KerGM: Kernelized Graph Matching},
author = {Zhang, Zhen and Xiang, Yijian and Wu, Lingfei and Xue, Bing and Nehorai, Arye},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {3330--3341},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8595-kergm-kernelized-graph-matching.pdf}
}
@incollection{NIPS2019_9109,
title = {Nonparametric Density Estimation \&amp; Convergence Rates for GANs under Besov IPM Losses},
author = {Uppal, Ananya and Singh, Shashank and Poczos, Barnabas},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {9086--9097},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9109-nonparametric-density-estimation-convergence-rates-for-gans-under-besov-ipm-losses.pdf}
}

@incollection{NIPS2019_9095,
title = {This Looks Like That: Deep Learning for Interpretable Image Recognition},
author = {Chen, Chaofan and Li, Oscar and Tao, Daniel and Barnett, Alina and Rudin, Cynthia and Su, Jonathan K},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {8928--8939},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9095-this-looks-like-that-deep-learning-for-interpretable-image-recognition.pdf}
}

@incollection{NIPS2019_8747,
title = {Neural Similarity Learning},
author = {Liu, Weiyang and Liu, Zhen and Rehg, James M and Song, Le},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {5026--5037},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8747-neural-similarity-learning.pdf}
}
@incollection{NIPS2019_9009,
title = {Fast and Flexible Multi-Task Classification using Conditional Neural Adaptive Processes},
author = {Requeima, James and Gordon, Jonathan and Bronskill, John and Nowozin, Sebastian and Turner, Richard E},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {7957--7968},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9009-fast-and-flexible-multi-task-classification-using-conditional-neural-adaptive-processes.pdf}
}

@incollection{NIPS2019_8434,
title = {Guided Similarity Separation for Image Retrieval},
author = {Liu, Chundi and Yu, Guangwei and Volkovs, Maksims and Chang, Cheng and Rai, Himanshu and Ma, Junwei and Gorti, Satya Krishna},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch{\'e}-Buc and E. Fox and R. Garnett},
pages = {1554--1564},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8434-guided-similarity-separation-for-image-retrieval.pdf}
}

@book{bergmann2002experience,
  title={Experience management: foundations, development methodology, and internet-based applications},
  author={Bergmann, Ralph},
  year={2002},
  publisher={Springer-Verlag}
}

@Article{Yang,
  author    = {Yang, Qiang and Cheng, Hong},
  journal   = {Lecture Notes in Computer Science},
  title     = {Case mining from large databases},
  pages     = {691–702},
  doi       = {10.1007/3-540-45006-8_52},
  isbn      = {http://id.crossref.org/isbn/978-3-540-40433-0},
  publisher = {Springer Nature},
}

@Article{Zaluski_2003,
  author    = {Zaluski, Marvin and Japkowicz, Nathalie and Matwin, Stan},
  journal   = {Lecture Notes in Computer Science},
  title     = {Case authoring from text and historical experiences},
  year      = {2003},
  issn      = {1611-3349},
  pages     = {222–236},
  doi       = {10.1007/3-540-44886-1_18},
  isbn      = {http://id.crossref.org/isbn/978-3-540-44886-0},
  publisher = {Springer Nature},
}

@Article{Yang2007,
  author    = {Yang, Chunsheng and Farley, Benoit and Orchard, Bob},
  journal   = {Applied Intelligence},
  title     = {Automated case creation and management for diagnostic CBR systems},
  year      = {2007},
  issn      = {1573-7497},
  month     = {2},
  number    = {1},
  pages     = {17–28},
  volume    = {28},
  doi       = {10.1007/s10489-007-0039-1},
  publisher = {Springer Nature},
}

@Article{Funk2006,
  author    = {Funk, Peter and Xiong, Ning},
  journal   = {Computational Intelligence},
  title     = {Case-based reasoning and knowledge discovery in medical applications with time series},
  year      = {2006},
  issn      = {1467-8640},
  month     = {8},
  number    = {3-4},
  pages     = {238–253},
  volume    = {22},
  doi       = {10.1111/j.1467-8640.2006.00286.x},
  publisher = {Wiley-Blackwell},
}
@article{cunningham2009taxonomy,
  title={A taxonomy of similarity mechanisms for case-based reasoning},
  author={Cunningham, Padraig},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={21},
  number={11},
  pages={1532--1543},
  year={2009},
  publisher={IEEE}
}
@article{richter03,
   author = {Richter, Michael M.},
   title = {Knowledge containers},
   journal = {Readings in Case-Based Reasoning},
   volume = {Morgan Kaufmann Publishers},
   year = {2003},
   type = {Journal Article}
}
@Book{veloso95,
  title     = {Case-Based Reasoning Research and Development: First International Conference, ICCBR-95, Sesimbra, {Portugal}, {October} 23-26, 1995. Proceeding},
  publisher = {Springer Science \& Business Media},
  year      = {1995},
  author    = {Veloso, Manuela and Aamodt, Agnar},
  volume    = {1010},
  url       = {http://www.springer.com/computer/ai/book/978-3-540-60598-0},
}
@InBook{cunningham98,
  pages     = {517--524},
  title     = {{CBR}: Strengths and weaknesses},
  publisher = {Springer Berlin Heidelberg},
  year      = {1998},
  author    = {Cunningham, P{\'a}draig},
  editor    = {Pobil, Angel Pasqual del and Mira, Jos{\'e} and Ali, Moonis},
  series    = {Lecture Notes in Computer Science},
  type      = {Book Section},
  booktitle = {Tasks and Methods in Applied Artificial Intelligence},
  keywords  = {Artificial Intelligence (incl. Robotics) Business Information Systems Computer-Aided Engineering (CAD, CAE) and Design},
  url       = {http://link.springer.com/chapter/10.1007/3-540-64574-8\_437},
}
@phdthesis{gundersen2014enhancing,
  title={Enhancing the situation awareness of decision makers by applying case-based reasoning on streaming data},
  author={Gundersen, Odd Erik},
  year={2014},
  publisher={NTNU},
  School={NTNU}
}

@Article{arshadi-2005-data-minin,
  author     = {N. Arshadi and I. Jurisica},
  journal    = {IEEE Transactions on Knowledge and Data Engineering},
  title      = {Data Mining for Case-Based Reasoning in High-Dimensional Biological Domains},
  year       = {2005},
  number     = {8},
  pages      = {1127-1137},
  volume     = {17},
  date_added = {Tue Feb 21 22:03:25 2017},
  doi        = {10.1109/tkde.2005.124},
}

@InBook{bach-2011-case-based,
  author     = {Kerstin Bach and Klaus-Dieter Althoff and R{\'e}gis Newo and Armin Stahl},
  pages      = {363-377},
  publisher  = {Springer Nature},
  title      = {A case-based reasoning approach for providing machine diagnosis from service reports},
  year       = {2011},
  series     = {Case-Based Reasoning Research and Development},
  booktitle  = {Case-Based Reasoning Research and Development},
  date_added = {Tue Feb 21 22:04:23 2017},
  doi        = {10.1007/978-3-642-23291-6_27},
}

@InBook{cummins-2009-maint-commit-exper,
  author     = {Lisa Cummins and Derek Bridge},
  pages      = {120-134},
  publisher  = {Springer Nature},
  title      = {Maintenance by a Committee of Experts: The MACE Approach to Case-Base Maintenance},
  year       = {2009},
  series     = {Case-Based Reasoning Research and Development},
  booktitle  = {Case-Based Reasoning Research and Development},
  date_added = {Tue Feb 21 23:31:10 2017},
  doi        = {10.1007/978-3-642-02998-1_10},
}

@InBook{cummins-2011-datas-compl,
  author     = {Lisa Cummins and Derek Bridge},
  pages      = {47-61},
  publisher  = {Springer Nature},
  title      = {On Dataset Complexity for Case Base Maintenance},
  year       = {2011},
  series     = {Case-Based Reasoning Research and Development},
  booktitle  = {Case-Based Reasoning Research and Development},
  date_added = {Tue Feb 21 23:32:09 2017},
  doi        = {10.1007/978-3-642-23291-6_6},
}

@Article{dufour-lussier-2014-autom-case,
  author     = {Valmi Dufour-Lussier and Florence Le Ber and Jean Lieber and Emmanuel Nauer},
  journal    = {Information Systems},
  title      = {Automatic case acquisition from texts for process-oriented case-based reasoning},
  year       = {2014},
  number     = {nil},
  pages      = {153-167},
  volume     = {40},
  date_added = {Tue Feb 21 23:32:49 2017},
  doi        = {10.1016/j.is.2012.11.014},
}

@Article{farley-2001-extrac-infor,
  author     = {BENOIT FARLEY},
  journal    = {AI EDAM},
  title      = {Extracting Information From Free-Text Aircraft Repair Notes},
  year       = {2001},
  number     = {4},
  pages      = {295-305},
  volume     = {15},
  date_added = {Tue Feb 21 23:35:12 2017},
  doi        = {10.1017/s0890060401154041},
}
@inproceedings{farley1999free,
  title={From free-text repair action messages to automated case generation},
  author={Farley, Benoit},
  booktitle={Proceedings of AAAI 1999 Spring Symposium: AI in Equipment Maintenance Service \& Support, Technical Reprot SS-99-02, Menlo Park, CA, AAAI Press},
  pages={109--118},
  year={1999}
}

@InBook{flinter-1995,
  author     = {Stephen Flinter and Mark T. Keane},
  pages      = {421-430},
  publisher  = {Springer Nature},
  title      = {On the automatic generation of case libraries by chunking chess games},
  year       = {1995},
  series     = {Case-Based Reasoning Research and Development},
  booktitle  = {Case-Based Reasoning Research and Development},
  date_added = {Tue Feb 21 23:37:44 2017},
  doi        = {10.1007/3-540-60598-3_38},
}

@InBook{floyd-2009-activ-approac,
  author     = {Michael W. Floyd and Babak Esfandiari},
  pages      = {150-164},
  publisher  = {Springer Nature},
  title      = {An Active Approach to Automatic Case Generation},
  year       = {2009},
  series     = {Case-Based Reasoning Research and Development},
  booktitle  = {Case-Based Reasoning Research and Development},
  date_added = {Tue Feb 21 23:38:22 2017},
  doi        = {10.1007/978-3-642-02998-1_12},
}
@inproceedings{RecioGarciaDG13,
  author    = {Recio-Garc{\'\i}a, Juan A and D{\'\i}az-Agudo, Bel{\'e}n and Gonz{\'a}lez-Calero, Pedro Antonio},
  title     = {The {COLIBRI} open platform for the reproducibility of {CBR} applications},
  booktitle = {Case-Based Reasoning Research and Development - 21st International
               Conference, {ICCBR} 2013, Saratoga Springs, NY, USA, July 8-11, 2013.
               Proceedings},
  pages     = {255--269},
  year      = {2013}
}
@misc{chollet2015keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  howpublished={\url{https://keras.io}},
}
@article{Pedregosa2011,
 author = {Pedregosa, Fabian and Varoquaux, Ga\"{e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, {\'E}douard},
 title = {Scikit-learn: Machine learning in Python},
 journal = {J. Mach. Learn. Res.},
 issue_date = {2/1/2011},
 volume = {12},
 month = nov,
 year = {2011},
 issn = {1532-4435},
 pages = {2825--2830},
 numpages = {6},
 acmid = {2078195},
 publisher = {JMLR.org},
}

@InProceedings{manzoor-2012-autom-case,
  author     = {Jaweria Manzoor and Saara Asif and Maryum Masud and Malik Jahan Khan},
  booktitle  = {2012 Third Global Congress on Intelligent Systems},
  title      = {Automatic case generation for case-based reasoning systems using genetic algorithms},
  year       = {2012},
  month      = {11},
  pages      = {nil},
  date_added = {Tue Feb 21 23:43:37 2017},
  doi        = {10.1109/gcis.2012.89},
}
@Misc{shokouhi10,
  author   = {Shokouhi, S. V. and Aamodt, A. and Skalle, P.},
  title    = {A semi-automatic method for case acquisition in {CBR} a study in oil well drilling},
  year     = {2010},
  keywords = {case-based reasoning Knowledge discovery Oil well drilling},
  pages    = {263--270},
  type     = {Generic},
}
@Article{shokouhi14,
  author   = {Shokouhi, Samad Valipour and Skalle, P{\aa}l and Aamodt, Agnar},
  title    = {An overview of case-based reasoning applications in drilling engineering},
  journal  = {Artificial Intelligence Review},
  year     = {2014},
  volume   = {41},
  number   = {3},
  pages    = {317--329},
  doi      = {10.1007/s10462-011-9310-2},
  keywords = {Artificial Intelligence (incl. Robotics) case-based reasoning Computer Science, general Decision support Oil well drilling Petroleum engineering},
  type     = {Journal Article},
}
@inproceedings{patterson2002towards,
  title={Towards Dynamic Maintenance of Retrieval Knowledge in CBR.},
  author={Patterson, David W and Rooney, Niall and Galushka, Mykola and Anand, Sarab S},
  booktitle={FLAIRS Conference},
  pages={126--131},
  year={2002}
}
@article{lannan1993user,
  title={User’s Guide to PONDCLASS: Guidelines for Fertilizing Aquaculture Ponds},
  author={Lannan, JE},
  journal={Pond Dynamics/Aquaculture CRSP, Oregon State University, Corvallis, Oregon},
  year={1993}
}
@article{kawamoto2005improving,
  title={Improving clinical practice using clinical decision support systems: a systematic review of trials to identify features critical to success},
  author={Kawamoto, Kensaku and Houlihan, Caitlin A and Balas, E Andrew and Lobach, David F},
  journal={Bmj},
  volume={330},
  number={7494},
  pages={765},
  year={2005},
  publisher={BMJ Publishing Group Ltd}
}
@article{crossland1995spatial,
  title={Spatial decision support systems: An overview of technology and a test of efficacy},
  author={Crossland, Martin D and Wynne, Bayarad E and Perkins, Wiliam C},
  journal={Decision support systems},
  volume={14},
  number={3},
  pages={219--235},
  year={1995},
  publisher={Elsevier}
}
@book{petticrew2008systematic,
  title={Systematic reviews in the social sciences: A practical guide},
  author={Petticrew, Mark and Roberts, Helen},
  year={2008},
  publisher={John Wiley \& Sons}
}
@inproceedings{scuse1983information,
  title={Information manipulation in biological decision-support systems},
  author={Scuse, David H and Arnason, A Neil},
  booktitle={Proceedings of the Sixteenth Hawaii International Conference on System Sciences, 1983},
  volume={1},
  pages={377},
  year={1983},
  organization={Western Periodicals Company}
}
@book{caddy1995reference,
  title={Reference points for fisheries management},
  author={Caddy, John F and Mahon, Robin},
  volume={374},
  year={1995},
  publisher={Food and Agriculture Organization of the United Nations Rome}
}
@article{malczewski2006gis,
  title={GIS-based multicriteria decision analysis: a survey of the literature},
  author={Malczewski, Jacek},
  journal={International Journal of Geographical Information Science},
  volume={20},
  number={7},
  pages={703--726},
  year={2006},
  publisher={Taylor \& Francis}
}
@incollection{power2008decision,
  title={Decision support systems: a historical overview},
  author={Power, Daniel J},
  booktitle={Handbook on Decision Support Systems 1},
  pages={121--140},
  year={2008},
  publisher={Springer}
}
@article{power2002decision,
  title={Decision support systems: concepts and resources for managers},
  author={Power, Daniel J},
  year={2002},
  publisher={Quorum Books}
}
@article{hunt1998effects,
  title={Effects of computer-based clinical decision support systems on physician performance and patient outcomes: a systematic review},
  author={Hunt, Dereck L and Haynes, R Brian and Hanna, Steven E and Smith, Kristina},
  journal={Jama},
  volume={280},
  number={15},
  pages={1339--1346},
  year={1998},
  publisher={American Medical Association}
}
@article{garg2005effects,
  title={Effects of computerized clinical decision support systems on practitioner performance and patient outcomes: a systematic review},
  author={Garg, Amit X and Adhikari, Neill KJ and McDonald, Heather and Rosas-Arellano, M Patricia and Devereaux, PJ and Beyene, Joseph and Sam, Justina and Haynes, R Brian},
  journal={Jama},
  volume={293},
  number={10},
  pages={1223--1238},
  year={2005},
  publisher={American Medical Association}
}

@Article{ram-1997-contin-case,
  author     = {A. Ram and J.C. Santamar{\'i}a},
  journal    = {Artificial Intelligence},
  title      = {Continuous Case-Based Reasoning},
  year       = {1997},
  number     = {1-2},
  pages      = {25-77},
  volume     = {90},
  date_added = {Tue Feb 21 23:45:58 2017},
  doi        = {10.1016/s0004-3702(96)00037-9},
}

@article{ram1993multistrategy,
  title={Multistrategy learning in reactive control systems for autonomous robotic navigation},
  author={Ram, Ashwin and Santamaria, Juan Carlos},
  year={1993},
  publisher={Georgia Institute of Technology}
}

@InBook{bonzano-1997-using-cbr,
  author     = {Andrea Bonzano and P{\'a}draig Cunningham and Barry Smyth},
  pages      = {291-302},
  publisher  = {Springer Nature},
  title      = {Using introspective learning to improve retrieval in CBR: A case study in air traffic control},
  year       = {1997},
  series     = {Case-Based Reasoning Research and Development},
  booktitle  = {Case-Based Reasoning Research and Development},
  date_added = {Tue Feb 21 23:49:20 2017},
  doi        = {10.1007/3-540-63233-6_500},
}

@inproceedings{smyth1995remembering,
  title={Remembering to forget: A competence-preserving deletion policy for cbr},
  author={Smyth, Barry and Keane, Mark},
  booktitle={Proceedings IJCAI-95},
  year={1995}
}

@InBook{smyth-1998-model,
  author     = {Barry Smyth and Elizabeth McKenna},
  pages      = {208-220},
  publisher  = {Springer Nature},
  title      = {Modelling the competence of case-bases},
  year       = {1998},
  booktitle={Proceedings of european Workshop on Advances in Case-Based Reasoning},
  date_added = {Tue Feb 21 23:51:41 2017},
  doi        = {10.1007/bfb0056334},
}

@InBook{smyth-1999-build-compac,
  author     = {Barry Smyth and Elizabeth McKenna},
  pages      = {329-342},
  publisher  = {Springer Nature},
  title      = {Building compact competent case-bases},
  year       = {1999},
  booktitle =  {Proceedings of the third International Conference on Case-Based Reasoning},
  date_added = {Tue Feb 21 23:52:20 2017},
  doi        = {10.1007/3-540-48508-2_24},
}

@article{vernet2003unsupervised,
  title={An unsupervised learning approach for case-based classifier systems},
  author={Vernet, David and Golobardes, Elisabet},
  journal={Expert Update. The Specialist Group on Artificial Intelligence},
  volume={6},
  number={2},
  pages={37--42},
  year={2003}
}

@inproceedings{zhu1999remembering,
  title={Remembering to add: competence-preserving case-addition policies for case-base maintenance},
  author={Zhu, Jun and Yang, Qiang},
  booktitle={IJCAI},
  volume={99},
  pages={234--241},
  year={1999}
}

@inproceedings{bach2014automatic,
  title={Automatic case capturing for problematic drilling situations},
  author={Bach, Kerstin and Gundersen, Odd Erik and Knappskog, Christian and {\"O}zt{\"u}rk, Pinar},
  booktitle={International Conference on Case-Based Reasoning},
  pages={48--62},
  year={2014},
  organization={Springer}
}
@Article{Pinar14,
  author  = {{\"O}zt{\"u}rk, Pinar and Tidemann, Axel},
  title   = {A review of case-based reasoning in cognition--action continuum: a step toward bridging symbolic and non-symbolic artificial intelligence},
  journal = {The Knowledge Engineering Review},
  year    = {2014},
  volume  = {29},
  number  = {01},
  pages   = {51--77},
  type    = {Journal Article},
  url     = {http://journals.cambridge.org/article\_S0269888913000076},
}
@article{Hinkle95,
   author = {Hinkle, David and Toomey, Christopher},
   title = {Applying case-based reasoning to manufacturing},
   journal = {AI magazine},
   volume = {16},
   number = {1},
   pages = {65},
   url={http://www.aaai.org/ojs/index.php/aimagazine/article/viewArticle/1124},
   year = {1995},
   type = {Journal Article}
}

@inproceedings{breivik2007high,
  title={A high-resolution hindcast study for the North Sea, the Norwegian Sea and the Barents Sea},
  author={Breivik, {\O}yvind and Reistad, Magnar and Haakenstad, Hilde},
  booktitle={10th International Workshop on Wave Hindcasting and Forecasting},
  year={2007}
}
@article{reistad2011high,
  title={A high-resolution hindcast of wind and waves for the North Sea, the Norwegian Sea, and the Barents Sea},
  author={Reistad, Magnar and Breivik, {\O}yvind and Haakenstad, Hilde and Aarnes, Ole Johan and Furevik, Birgitte R and Bidlot, Jean-Raymond},
  journal={Journal of Geophysical Research: Oceans},
  volume={116},
  number={C5},
  year={2011},
  publisher={Wiley Online Library}
}
@inproceedings{lader2017,
        booktitle={Proceedings of the ASME 2017 36th International Conference on Ocean, Offshore and Arctic Engineering
OMAE2017},
author = {Lader, P{\aa}l and Kristiansen, David and Alver, Morten and  Bjelland, Hans. V and Myrhaug, Dag},
title = {Classification of aquaculture locations in norway with respect to wind wave exposure},
year = {2017}
}
@article{schank1980language,
  title={Language and memory},
  author={Schank, Roger C},
  journal={Cognitive science},
  volume={4},
  number={3},
  pages={243--284},
  year={1980},
  publisher={Wiley Online Library}
}
@inproceedings{aha1991case,
  title={Case-based learning algorithms},
  author={Aha, David W},
  booktitle={Proceedings of the 1991 DARPA Case-Based Reasoning Workshop},
  volume={1},
  pages={147--158},
  year={1991}
}

@inproceedings{hoffmann_graph_embedding_2020,
	title = {{Using siamese graph neural networks for similarity-based retrieval in process-oriented case-based reasoning}},
	booktitle = {Case-{Based} {Reasoning} {Research} and {Development}: 28th {International} {Conference}, {ICCBR} 2020, {Salamanca}, {Spain}, {June} 8-12, 2020, {Proceedings}},
	publisher = {Springer.},
	author = {Hoffmann, Maximilian and Malburg, Lukas and Klein, Patrick and Bergmann, Ralph},
	year = {2020},
	keywords = {{Process-Oriented Case-Based Reasoning, MAC/FAC Retrieval, Graph Embeddings, Siamese Graph Neural Networks}},
	abstract = {Similarity-based retrieval of semantic graphs is widely used in
				real-world scenarios, e.g., in the domain of business workflows. To tackle
				the problem of complex and time-consuming graph similarity computations
				during retrieval, the MAC/FAC approach is used in Process-
				Oriented Case-Based Reasoning (POCBR), where similar graphs are extracted
				from a preselected set of candidate graphs. These graphs result
				from a similarity computation with a computationally inexpensive similarity
				measure. The contribution of this paper is a novel similarity measure
				where vector space embeddings generated by two siamese Graph
				Neural Networks (GNNs) are used to approximate the similarities of
				a precise but therefore computationally complex graph similarity measure.
				This includes a special scheme for encoding semantic graphs to be
				used in the neural networks. The evaluation examines the quality and
				performance of these models in preselecting retrieval candidates and in
				approximating the ground-truth similarities of the graph similarity measure.
				The results show great potential of the approach for being used in
				a MAC/FAC scenario, either as a preselection model or as an approximation
				of the graph similarity measure.},
	note = {Accepted for publication.}
}
@inproceedings{xiameng_2020,
	title = {{Applying Class-to-Class Siamese Networks to Explain Classifications with Supportive and Contrastive Cases}},
	booktitle = {Case-{Based} {Reasoning} {Research} and {Development}: 28th {International} {Conference}, {ICCBR} 2020, {Salamanca}, {Spain}, {June} 8-12, 2020, {Proceedings}},
	publisher = {Springer.},
	author = {Ye, Xiaomeng and Leake, David and Huibregtse, William and Dalkilic, Mehmet},
	year = {2020},
	note = {Accepted for publication.}
}

@inproceedings{Of2017,
        booktitle={Proceedings of the ASME 2017 36th International Conference on Ocean, Offshore and Arctic Engineering
OMAE2017},
author = {Lader, P{\aa}l and Kristiansen, David and Alver, Morten and  Bjelland, Hans. V and Myrhaug, Dag},
title = {Classification of aquaculture locations in norway with respect to wind wave exposure},
year = {2017}
}
%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Bjorn Magnus Mathisen at 2015-07-07 22:00:45 +0200


%% Saved with string encoding Unicode (UTF-8)

@Article{bourke1993decision,
  author    = {Bourke, Gerry and Stagnitti, Frank and Mitchell, Brad},
  journal   = {Aquacultural Engineering},
  title     = {A decision support system for aquaculture research and management},
  year      = {1993},
  number    = {2},
  pages     = {111--123},
  volume    = {12},
  abstract  = {A decision support system was developed to facilitate the collection,
manipulation and analysis of physico-chemical and biological data
generated in aquaculture research. The Aquaculture Research and
Monitoring System (ARMS) consists of integrated hardware and software
packages that facilitate the operational decision making process in
aquaculture research via a user-friendly, visual interactive-modelling
interface. A R M S provides a management system for the capture and
manipulation of real, online environmental data sampled by a data
logger and a modelling system allowing the user to input their own
judgements in the analytical decision-making process. These judgements
may be qualitative as well as quantitative. The user is able to assign
importance values to the various environmental parameters and
management practices that constitute variables in experiments and A R
M S determines the probability of specific experimental outcomes.
Thus, A R M S may be used to examine the validity of the assumptions
used in past experiments and, more importantly, to simulate new
experiments before actual implementation. A R M S also has a
demonstration capacity that may be used to train other managers or
students. [abriged]},
  citations = {17},
  citedbyid = {18224417294628871544},
  file      = {file:/Users/epic/research/papers/DSS in Fisheries and Aquaculture -Systematic Survey/papers/1-Bourke1993.pdf:pdf},
  md5sum    = {282caf971d6a7e09303bcd093a9f14aa},
  pdfmeat   = {timestamp: 2015-09-16 21:54:27; queries: 1; inode: 77086675},
  publisher = {Elsevier},
  url       = {http://www.sciencedirect.com/science/article/pii/014486099390020C},
}
@InProceedings{Silvert2010,
  author    = {Silvert, William},
  title     = {Decision support for stakeholders},
  year      = {2010},
  volume    = {1},
  pages     = {523 - 529},
  address   = {Ottawa, ON, Canada},
  abstract  = {Decision Support Systems (DSS) offer more transparency than traditional modelling approaches but are designed for use by government agents to use in the regulatory process. Stakeholders are in the position of looking over the shoulder of the person in charge, and while this is better than just waiting for answers it still separates them from the modelling process. If stakeholders were actually able to operate a DSS by themselves it could increase transparency, build confidence, and create possibilities for new approaches to environmentally significant developments which could benefit all parties concerned. This talk describes three simple DSS programs for aquaculture siting, two for finfish and one for shellfish, which are designed in such a way that they not only provide information relevant to the regulatory process but also can be used by fish farmers, NGOs and other interested parties to evaluate potential activities from their individual perspectives. For example, a fish farmer could use a DSS in private to explore potentials for site development without having to prepare a detailed proposal in advance and without having to share proprietary information with government scientists or anyone else. Furthermore the use of a publicly available DSS would lessen concerns about bias and preference in the regulation of the industry and could contribute to an attitude of mutual trust which might decrease the potential for social conflict about potential harmful developments.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
  journal   = {Modelling for Environment's Sake: Proceedings of the 5th Biennial Conference of the International Environmental Modelling and Software Society, iEMSs 2010},
  key       = {Decision support systems},
  keywords  = {Agriculture;Aquaculture;Artificial intelligence;Fish;Transparency;},
  language  = {English}
}
@Article{Radulescu201106,
  author    = {Radulescu, C.Z. and Rahoveanu, M.T.},
  title     = {A multi-criteria evaluation framework for fish farms},
  journal   = {Studies in Informatics and Control},
  year      = {2011},
  volume    = {20},
  number    = {2},
  pages     = {181 - 6},
  issn      = {1220-1766},
  abstract  = {This paper presents a multi-criteria evaluation framework which integrates the Analytical Hierarchy Process (AHP) and the Simple Additive Weighting (SAW) methods. This approach takes into consideration subjective judgments of the decision makers. The criteria weights are calculated by using the AHP method. Subsequently, rankings of the alternatives are determined by the SAW method. Our multi-criteria evaluation framework is used for evaluating the performance of a fish farm, called Malina, located near the villages Sendreni and Smardan, Galati county, Romania. The analysis ranks the performance of the fish farm over a period of seven years, so the output is a trend over time reflecting the progress of the fish farm. The proposed framework enables the decision makers to better understand the whole evaluation process. It provides a more accurate, effective, and systematic evaluation tool.},
  address   = {Romania},
  copyright = {Copyright 2012, The Institution of Engineering and Technology},
  keywords  = {aquaculture;decision making;},
  language  = {English}
}
@Article{Magno-Tan201712,
  author    = {Magno-Tan, M.J. and Alejandrino, A.C. and Dela Cruz, C.G. and Inoc, A.C. and Coronado, A.S.},
  title     = {Web-based decision support system for broodstock management of Siganus guttatus (Bloch, 1787) in open fish cage},
  journal   = {International Journal of Machine Learning and Computing},
  year      = {2017},
  volume    = {7},
  number    = {6},
  pages     = {208 - 12},
  issn      = {2010-3700},
  address   = {Singapore},
  copyright = {Copyright 2019, The Institution of Engineering and Technology},
  doi       = {10.18178/ijmlc.2017.7.6.648},
  file      = {:Magno-Tan2017_12_ - Web Based Decision Support System for Broodstock Management of Siganus Guttatus (Bloch, 1787) in Open Fish Cage.pdf:PDF},
  keywords  = {aquaculture;decision support systems;neural nets;water quality;},
  language  = {English}
}
@Article{Cobo2018,
  author        = {{\'A}ngel Cobo and Ignacio Llorente and Ladislao Luna and Manuel Luna},
  title         = {A decision support system for fish farming using particle swarm optimization},
  journal       = {Computers and Electronics in Agriculture},
  year          = {2018},
  issn          = {0168-1699},
  abstract      = {This work presents a Decision Support System (DSS) for fish farming in cages that determines the production strategies that maximize the present profits of the farming process. It is a model-driven cooperative DSS in which the cultivation process is simulated through a bioeconomic model that considers economic, environmental, biological and technical data. The optimal production strategies are determined using Particle Swarm Optimization (PSO). The DSS helps to deal with two types of decisions: operational decisions in which the DSS obtains the optimal solution under particular conditions; and strategic decisions, in which the DSS allows to obtain the optimal economic result in different scenarios. There are a broad range of strategic decisions in which this DSS can be applied, among others, site selection, feed, production capacity, or harvest weight.},
  doi           = {10.1016/j.compag.2018.03.036},
  url           = {http://www.sciencedirect.com/science/article/pii/S0168169917312279}
}

@article{silvert1994decision,
  title={A decision support system for regulating finfish aquaculture},
  author={Silvert, William},
  journal={Ecological modelling},
  volume={75},
  pages={609--615},
  year={1994},
  publisher={Elsevier}
}
@article{renaud1995decision,
  title={Decision support system for quality assurance programs in the fish and seafood processing industry},
  author={Renaud, Isabelle and Yacout, Soumaya},
  journal={Computers \& Industrial Engineering},
  volume={29},
  number={1},
  pages={31--35},
  year={1995},
  publisher={Elsevier}
}
@article{korrubel1998forecasting,
  title={Forecasting in South African pelagic fisheries management: the use of expert and decision support systems},
  author={Korr{\^u}bel, JL and Bloomer, SF and Cochrane, KL and Hutchings, L and Field, JG},
  journal={South African Journal of Marine Science},
  volume={19},
  number={1},
  pages={415--423},
  year={1998},
  publisher={Taylor \& Francis}
}
@article{mardle1999review,
  title={A review of applications of multiple-criteria decision-making techniques to fisheries},
  author={Mardle, Simon and Pascoe, Sean},
  journal={Marine Resource Economics},
  pages={41--63},
  year={1999},
  publisher={JSTOR}
}
@article{bolte2000development,
  title={Development of decision support tools for aquaculture: the POND experience},
  author={Bolte, John and Nath, Shree and Ernst, Doug},
  journal={Aquacultural engineering},
  volume={23},
  number={1},
  pages={103--119},
  year={2000},
  publisher={Elsevier}
}
@article{el2000addss,
  title={ADDSS: a tool for regional aquaculture development},
  author={El-Gayar, Omar F and Leung, PingSun},
  journal={Aquacultural Engineering},
  volume={23},
  number={1},
  pages={181--202},
  year={2000},
  publisher={Elsevier}
}
@article{nath2000applications,
  title={Applications of geographical information systems (GIS) for spatial decision support in aquaculture},
  author={Nath, Shree S and Bolte, John P and Ross, Lindsay G and Aguilar-Manjarrez, Jose},
  journal={Aquacultural Engineering},
  volume={23},
  number={1},
  pages={233--278},
  year={2000},
  publisher={Elsevier}
}
@book{coppola2001decision,
  title={Decision-support Systems for Fisheries the" ITAFISH" Case Study},
  author={Coppola, Salvatore R and Crosetti, Donatella},
  number={72},
  year={2001},
  publisher={Food \& Agriculture Org.}
}

@article{ernst2000aquafarm,
  title={AquaFarm: simulation and decision support for aquaculture facility design and management planning},
  author={Ernst, Douglas H and Bolte, John P and Nath, Shree S},
  journal={Aquacultural Engineering},
  volume={23},
  number={1},
  pages={121--179},
  year={2000},
  publisher={Elsevier}
}
@article{pastres2001managing,
  title={Managing the rearing of Tapes philippinarum in the lagoon of Venice: a decision support system},
  author={Pastres, R and Solidoro, C and Cossarini, G and Canu, D Melaku and Dejak, C},
  journal={Ecological Modelling},
  volume={138},
  number={1},
  pages={231--245},
  year={2001},
  publisher={Elsevier}
}
@article{gundersen2012real,
	Author = {Gundersen, Odd Erik and S{\o}rmo, Frode and Aamodt, Agnar and Skalle, P{\aa}l},
	Date-Added = {2015-07-07 19:57:36 +0000},
	Date-Modified = {2015-07-07 19:57:36 +0000},
	Journal = {AI Magazine},
	Number = {1},
	Pages = {21},
	Title = {A real-time decision support system for high cost oil-well drilling operations},
	Volume = {34},
	Year = {2012}}

@incollection{tidemann2012operational,
	Author = {Tidemann, Axel and Bj{\o}rnson, Finn Olav and Aamodt, Agnar},
	Booktitle = {Advanced Research in Applied Artificial Intelligence},
	Date-Added = {2015-07-07 19:56:05 +0000},
	Date-Modified = {2015-07-07 19:56:05 +0000},
	Pages = {104--113},
	Publisher = {Springer},
	Title = {Operational support in fish farming through case-based reasoning},
	Year = {2012}}

@article{de1975analysis,
	Author = {De Jong, Kenneth Alan},
	Date-Added = {2015-07-07 13:46:20 +0000},
	Date-Modified = {2015-07-07 13:46:20 +0000},
	Title = {Analysis of the behavior of a class of genetic adaptive systems},
	Year = {1975}}

@book{john1992adaptation,
	Author = {John Henry Holland},
	Date-Added = {2015-07-07 13:45:04 +0000},
	Date-Modified = {2015-07-07 13:45:04 +0000},
	Publisher = {MIT press},
	Title = {Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence},
	Year = {1992}}

@article{golberg1989genetic,
	Author = {Golberg, David E},
	Date-Added = {2015-07-07 13:43:28 +0000},
	Date-Modified = {2015-07-07 13:43:28 +0000},
	Journal = {Addion wesley},
	Title = {Genetic algorithms in search, optimization, and machine learning},
	Volume = {1989},
	Year = {1989}}
@article{vinu2009prioritization,
  title={Prioritization of satellite-derived potential fishery grounds: an analytical hierarchical approach-based model using spatial and non-spatial data},
  author={Vinu Chandran, R and Jeyaram, A and Jayaraman, V and Manoj, S and Rajitha, K and Mukherjee, CK},
  journal={International Journal of Remote Sensing},
  volume={30},
  number={17},
  pages={4479--4491},
  year={2009},
  publisher={Taylor \& Francis}
}
@article{halide2009developing,
	Author = {Halide, Halmar and Stigebrandt, A and Rehbein, M and McKinnon, AD},
	Date-Added = {2015-07-06 22:13:27 +0000},
	Date-Modified = {2015-07-06 22:13:27 +0000},
	Journal = {Environmental Modelling \& Software},
	Number = {6},
	Pages = {694--702},
	Publisher = {Elsevier},
	Title = {Developing a decision support system for sustainable cage aquaculture},
	Volume = {24},
	Year = {2009}}
@article{Sun20091339,
author={Sun, L. and Xiao, H. and Yang, D. and Li, S.},
title={Intelligent decision support system for fisheries management},
journal={Journal of Computational Information Systems},
year={2009},
volume={5},
number={3},
pages={1339-1347},
note={cited By 2},
url={http://www.scopus.com/inward/record.url?eid=2-s2.0-70350227284&partnerID=40&md5=66349cd69ac262ff6f61d1ee22d83140},
document_type={Article},
source={Scopus},
}
@article{xiaoshuan2009applying,
	Author = {Xiaoshuan, Zhang and Zetian, Fu and Wengui, Cai and Dong, Tian and Jian, Zhang},
	Date-Added = {2015-07-06 22:11:33 +0000},
	Date-Modified = {2015-07-06 22:11:33 +0000},
	Journal = {Expert Systems with Applications},
	Number = {2},
	Pages = {3901--3913},
	Publisher = {Elsevier},
	Title = {Applying evolutionary prototyping model in developing FIDSS: An intelligent decision support system for fish disease/health management},
	Volume = {36},
	Year = {2009}}

@Article{hughey2001developing,
  author    = {Hughey, Ken and Cullen, Ross and Memon, Ali and Kerr, Geoff and Wyatt, Nick},
  title     = {Developing a Decision Support system to manage fisheries externalities in New Zealand's Exclusive Economic Zone},
  year      = {2001},
  abstract  = {New Zealand marine fishing activities create many types of
environmental externalities. Legislation requires that the
externalities be internalised and fisheries management agencies must
choose from a wide range of instruments which are best suited to the
task. Selection of best instruments can be aided by following a
hierarchical decision process, which first screens the universe of
instruments to produce a likely set, then tests that list against
implementation criteria to establish the feasible set. Instruments in
the feasible set can be evaluated against a range of environmental,
Treaty of Waitangi, economic, socio-cultural and management criteria.
This approach to selection can be formalised in decision support
software to provide a useful tool for fisheries management agencies.
Key words - New Zealand, fisheries, internalising externalities,
Decision Support System},
  citations = {5},
  citedbyid = {14596061272296023531},
  file      = {file:/Users/epic/research/papers/DSS in Fisheries and Aquaculture -Systematic Survey/papers/11-Hughey2001.pdf:pdf},
  md5sum    = {423e3ad339f2a19d19c6531e81d6a700},
  pdfmeat   = {timestamp: 2015-09-16 21:54:29; queries: 1; inode: 77088164},
  publisher = {International Institute of Fisheries Economics and Trade},
  url       = {http://ir.library.oregonstate.edu/xmlui/handle/1957/31023},
}

@Article{mackinson2001integrating,
  author    = {Mackinson, Steven},
  journal   = {Environmental Management},
  title     = {Integrating local and scientific knowledge: an example in fisheries science},
  year      = {2001},
  number    = {4},
  pages     = {533--545},
  volume    = {27},
  citations = {162},
  citedbyid = {12572027237678557406},
  doi       = {10.1007/s0026702366},
  file      = {file:/Users/epic/research/papers/DSS in Fisheries and Aquaculture -Systematic Survey/papers/12-Mackinson2001.pdf:pdf},
  md5sum    = {af97b2ccabc006b8520300ed095c7325},
  pdfmeat   = {timestamp: 2015-09-16 21:54:31; queries: 1; inode: 77088247},
  publisher = {Springer},
}
@article{pan2001decision,
	Author = {Pan, Minling and Leung, Ping Sun and Pooley, Samuel G},
	Date-Added = {2015-07-06 22:08:46 +0000},
	Date-Modified = {2015-07-06 22:08:46 +0000},
	Journal = {North American Journal of Fisheries Management},
	Number = {2},
	Pages = {293--309},
	Publisher = {Taylor \& Francis},
	Title = {A decision support model for fisheries management in Hawaii: a multilevel and multiobjective programming approach},
	Volume = {21},
	Year = {2001}}

@article{Spiegelhalter:1993aa,
	Author = {Spiegelhalter, David J and Dawid, A Philip and Lauritzen, Steffen L and Cowell, Robert G},
	Date-Added = {2015-07-06 21:32:02 +0000},
	Date-Modified = {2015-07-06 21:32:09 +0000},
	Journal = {Statistical science},
	Pages = {219--247},
	Publisher = {JSTOR},
	Title = {Bayesian analysis in expert systems},
	Year = {1993}}

@unpublished{sfisoknad,
	Author = {SFI-consortium},
	Date-Added = {2015-07-06 20:23:23 +0000},
	Date-Modified = {2015-07-06 21:28:40 +0000},
	Title = {Exposed aquaculture operations: center for research-based innovation}}

@article{aamodt1994case,
	Author = {Aamodt, Agnar and Plaza, Enric},
	Date-Added = {2015-07-06 20:12:09 +0000},
	Date-Modified = {2015-07-06 20:12:09 +0000},
	Journal = {AI communications},
	Number = {1},
	Pages = {39--59},
	Title = {Case-based reasoning: Foundational issues, methodological variations, and system approaches},
	Volume = {7},
	Year = {1994},
    publisher={IOS press}}

@Misc{aamodt01,
  author = {Aamodt, Agnar},
  title  = {Modeling the knowledge contents of {CBR} systems},
  year   = {2001},
  pages  = {32--37},
  type   = {Conference Paper},
  volume = {Naval Research Lab Technical Note AIC-01-003},
}
@inproceedings{mathisen2020fishnet,
  title={FishNet: A unified embedding for salmon recognition},
  author={Mathisen, Bj{\o}rn Magnus and Bach, Kerstin and Meidell, Espen and M{\aa}l{\o}y, H{\aa}kon and Sj{\o}blom, Edvard Schreiner},
  booktitle={Proceedings of the Twenty-fourth European Conference on Artificial Intelligence},
  pages={3001--3008},
  year={2020},
  publisher={IOS Press}
}

@Misc{cordier07,
  author    = {Cordier, A. and Fuchs, B. and Lieber, J. and Mille, A.},
  title     = {Failure analysis for domain knowledge acquisition in a knowledge-intensive {CBR} system},
  year      = {2007},
  pages     = {448--462},
  publisher = {Springer LNCS},
  rating    = {Rating},
  type      = {Conference Paper},
  volume    = {4626},
}
@phdthesis{cordier08,
   author={Cordier, Am{\'e}lie},
   year={2008},
   school={Universit{\'e} Claude Bernard-Lyon I},
   title = {Interactive and opportunistic knowledge acquisition in case-based reasoning},
   DOI = {Theses},
   url={https://tel.archives-ouvertes.fr/tel-00364368},
   year = {2008},
   type = {Thesis}
}
@book{watson03,
   author = {Watson, Ian},
   title = {Applying Knowledge Management: Techniques for Building Corporate Memories},
   publisher = {Morgan Kaufmann},
   keywords = {Business \& Economics / Entrepreneurship
Business \& Economics / Management
Computers / Intelligence (AI) \& Semantics},
   year = {2003},
   type = {Book}
}
@conference{maddison2015iclr,
	Author = {Maddison, Chris J. and Huang, Aja and Sutskever, Ilya and Silver, David},
	Booktitle = {Under review as a conference paper at ICLR 2015},
	Date-Added = {2014-12-25 22:06:53 +0000},
	Date-Modified = {2014-12-26 11:21:00 +0000},
	Title = {MOVE EVALUATION IN GO USING DEEP CONVOLUTIONAL NEURAL NETWORKS},
	Year = {2015},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QIy4uLy4uLy4uLy4uLy4uL0Rvd25sb2Fkcy9kZWVwZ28ucGRm0hcLGBlXTlMuZGF0YU8RAWwAAAAAAWwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM+zZ/tIKwAAADNbCQpkZWVwZ28ucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABb64H0MJKxQAAAAAAAAAAAAUAAgAACSAAAAAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAAQAAgAAM+zS9sAAAARAAgAANDCPLUAAAABAAwAM1sJABD6GgAQ6PEAAgAvTWFjaW50b3NoIEhEOlVzZXJzOgBlcGljOgBEb3dubG9hZHM6AGRlZXBnby5wZGYAAA4AFgAKAGQAZQBlAHAAZwBvAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAfVXNlcnMvZXBpYy9Eb3dubG9hZHMvZGVlcGdvLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgC0ALkAwQIxAjMCOAJDAkwCWgJeAmUCbgJzAoACgwKVApgCnQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKf}}
@article{silveralphazero2017,
	Author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabi, Demis},
	Date-Added = {2014-03-31 23:05:34 +0000},
	Date-Modified = {2014-03-31 23:05:34 +0000},
	Journal = {arXiv preprint arXiv:1712.01815v1 [cs.AI]},
	Title = {Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm},
	Year = {2017}}

@article{mellone2012smartphone,
	Author = {Mellone, S and Tacconi, C and Schwickert, L and Klenk, J and Becker, C and Chiari, L},
	Date-Added = {2014-04-11 13:49:32 +0000},
	Date-Modified = {2014-04-11 13:49:32 +0000},
	Journal = {Zeitschrift F{\"u}r Gerontologie Und Geriatrie},
	Number = {8},
	Pages = {722--727},
	Publisher = {Springer},
	Title = {Smartphone-based solutions for fall detection and prevention: the FARSEEING approach},
	Volume = {45},
	Year = {2012}}

@incollection{huang-a,
	Author = {Huang, G. B. and Ramesh, M. and Berg, T. and Learned-miller, E.},
	Date-Added = {2014-04-11 13:41:03 +0000},
	Date-Modified = {2014-04-11 13:41:03 +0000},
	Source = {ECCV Workshop on Faces in Real-life},
	Title = {Labeled faces in the wild: A database for studying face recognition in un- constrained environments},
	Unknown = {In},
	Unmatched-Author = {Images, 2008. 1, 6}}

@article{stanley:ec02,
	Author = {Kenneth O. Stanley and Risto Miikkulainen},
	Date-Added = {2014-04-11 10:30:27 +0000},
	Date-Modified = {2014-04-11 10:30:27 +0000},
	Journal = {Evolutionary Computation},
	Number = {2},
	Pages = {99-127},
	Title = {Evolving Neural Networks Through Augmenting Topologies},
	Url = {http://nn.cs.utexas.edu/?stanley:ec02},
	Volume = {10},
	Year = {2002},
	Bdsk-Url-1 = {http://nn.cs.utexas.edu/?stanley:ec02}}

@incollection{q2012a,
	Author = {Q.V. Le, M.A. Ranzato and Monga, R. and Devin, M. and Chen, K. and G.S. Corrado, J. Dean and Ng, A.Y.},
	Booktitle = {ICML},
	Date-Added = {2014-04-10 23:41:55 +0000},
	Date-Modified = {2014-04-10 23:41:55 +0000},
	Title = {Building high-level features using large scale unsupervised learning},
	Year = {2012}}

@InCollection{Doucette:2010aa,
  author        = {Doucette, John and Heywood, MalcolmI.},
  booktitle     = {Genetic Programming},
  publisher     = {Springer Berlin Heidelberg},
  title         = {Novelty-Based Fitness: An Evaluation under the Santa Fe Trail},
  year          = {2010},
  editor        = {Esparcia-Alc√$\,^{\circ}$zar, AnnaIsabel and Ek√$\,^{\circ}$rt, Anik√≥ and Silva, Sara and Dignum, Stephen and Uyar, A.≈{\^u}ima},
  isbn          = {978-3-642-12147-0},
  pages         = {50-61},
  series        = {Lecture Notes in Computer Science},
  volume        = {6021},
  bdsk-url-1    = {http://dx.doi.org/10.1007/978-3-642-12148-7_5},
  date-added    = {2014-04-10 23:35:19 +0000},
  date-modified = {2014-04-10 23:35:21 +0000},
  doi           = {10.1007/978-3-642-12148-7_5},
}

@inproceedings{gauci2007generating,
	Author = {Gauci, Jason and Stanley, Kenneth},
	Booktitle = {Proceedings of the 9th annual conference on Genetic and evolutionary computation},
	Date-Added = {2014-04-09 00:05:05 +0000},
	Date-Modified = {2014-04-09 00:05:05 +0000},
	Organization = {ACM},
	Pages = {997--1004},
	Title = {Generating large-scale neural networks through discovering geometric regularities},
	Year = {2007}}

@inproceedings{glorot2010understanding,
	Author = {Glorot, Xavier and Bengio, Yoshua},
	Booktitle = {International Conference on Artificial Intelligence and Statistics},
	Date-Added = {2014-04-02 22:30:25 +0000},
	Date-Modified = {2014-04-02 22:30:25 +0000},
	Pages = {249--256},
	Title = {Understanding the difficulty of training deep feedforward neural networks},
	Year = {2010}}

@inproceedings{montanadavis,
	Author = {D. J. Montana, L. D. Davis},
	Booktitle = {Proceedings of the Eleventh International Joint Conference on Artificial Intelligence},
	Date-Added = {2014-04-02 22:24:27 +0000},
	Date-Modified = {2014-04-02 22:24:27 +0000},
	Key = {montanadavis},
	Pages = {762-767},
	Title = {Training feedforward networks using genetic algorithms},
	Year = 1989}

@article{esp,
	Author = {Faustino Gomez, Risto Miikulainen},
	Date-Added = {2014-04-02 22:23:40 +0000},
	Date-Modified = {2014-04-02 22:23:40 +0000},
	Journal = {Adaptive Behavior},
	Key = {esp},
	Number = {5},
	Pages = {317-342},
	Title = {Incremental Evolution of Complex General Behavior},
	Volume = {5},
	Year = {1997}}

@article{sane,
	Author = {David E. Moriarty, Risto Miikulainen},
	Date-Added = {2014-04-02 22:23:28 +0000},
	Date-Modified = {2014-04-02 22:23:28 +0000},
	Journal = {Machine Learning},
	Key = {sane},
	Number = {22},
	Pages = {11-33},
	Title = {Efficient Reinforcement Learning through Symbiotic Evolution},
	Volume = {22},
	Year = {1996}}

@article{kitano,
	Author = {Hiroaki Kitano},
	Date-Added = {2014-04-02 22:23:06 +0000},
	Date-Modified = {2014-04-02 22:23:06 +0000},
	Journal = {Complex Systems},
	Key = {kitano},
	Number = {4},
	Pages = {461-476},
	Title = {Designing neural networks using genetic algorithms with graph generation system},
	Volume = {4},
	Year = {1990}}

@inproceedings{bottou1991a,
	Author = {Bottou, L.},
	Booktitle = {Proceedings of Neuro-Nˆımes 91},
	Date-Added = {2014-04-01 18:58:41 +0000},
	Date-Modified = {2014-04-01 18:58:41 +0000},
	Title = {Stochastic gradient learning in neural networks},
	Unknown = {In},
	Year = {1991}}

@article{gauci2010autonomous,
	Author = {Gauci, Jason and Stanley, Kenneth O},
	Date-Added = {2014-04-01 11:52:54 +0000},
	Date-Modified = {2014-04-01 11:52:54 +0000},
	Journal = {Neural computation},
	Number = {7},
	Pages = {1860--1898},
	Publisher = {MIT Press},
	Title = {Autonomous evolution of topographic regularities in artificial neural networks},
	Volume = {22},
	Year = {2010}}

@misc{dean2008a,
	Author = {Dean, J. and Ghemawat, S.},
	Date-Added = {2014-04-01 11:04:43 +0000},
	Date-Modified = {2014-04-01 11:04:43 +0000},
	Note = {CACM},
	Title = {Map-Reduce: simplified data processing on large clusters},
	Year = {2008}}

@incollection{deng2012a,
	Author = {Deng, L. and Yu, D. and Platt, J.},
	Booktitle = {ICASSP},
	Date-Added = {2014-04-01 10:49:44 +0000},
	Date-Modified = {2014-04-01 10:49:44 +0000},
	Title = {Scalable stacking and learning for building deep architectures},
	Year = {2012}}

@article{deepface,
	Author = {Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
	Date-Added = {2014-03-31 23:39:16 +0000},
	Date-Modified = {2014-03-31 23:40:37 +0000},
	Journal = {Conference on Computer Vision and Pattern Recognition (CVPR)},
	Title = {DeepFace: Closing the Gap to Human-Level Performance in Face Verification},
	Year = {2014}}

@inproceedings{dean2012large,
	Author = {Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Le, Quoc V and Mao, Mark Z and Marc'Aurelio Ranzato and Senior, Andrew W and Tucker, Paul A and others},
	Booktitle = {NIPS},
	Date-Added = {2014-03-31 23:35:31 +0000},
	Date-Modified = {2014-03-31 23:35:31 +0000},
	Pages = {1232--1240},
	Title = {Large Scale Distributed Deep Networks.},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPWxpdGVyYXR1cmUvRE5OLzQ2ODctbGFyZ2Utc2NhbGUtZGlzdHJpYnV0ZWQtZGVlcC1uZXR3b3Jrcy5wZGbSFwsYGVdOUy5kYXRhTxECgAAAAAACgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAz7Nn+0grAAACe/pOHzQ2ODctbGFyZ2Utc2NhbGUtZGkjMjdCRkE1MC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJ7+lDPX53uAAAAAAAAAAAAAQAEAAAJIAAAAAAAAAAAAAAAAAAAAANETk4AABAACAAAz7NL2wAAABEACAAAz1+BzgAAAAEAJAJ7+k4Ce/pNAnv6MwJ7+akCe/mnABqIZQAUAdcAEPoaABDo8QACAIhNYWNpbnRvc2ggSEQ6VXNlcnM6AGVwaWM6AERvY3VtZW50czoAc2ludGVmOgBwaGQyMDE1OgBhcHBsaWNhdGlvbjoAcHJvamVjdC1kZWNzcmlwdGlvbjoAbGl0ZXJhdHVyZToARE5OOgA0Njg3LWxhcmdlLXNjYWxlLWRpIzI3QkZBNTAucGRmAA4AXgAuADQANgA4ADcALQBsAGEAcgBnAGUALQBzAGMAYQBsAGUALQBkAGkAcwB0AHIAaQBiAHUAdABlAGQALQBkAGUAZQBwAC0AbgBlAHQAdwBvAHIAawBzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgCBVXNlcnMvZXBpYy9Eb2N1bWVudHMvc2ludGVmL3BoZDIwMTUvYXBwbGljYXRpb24vcHJvamVjdC1kZWNzcmlwdGlvbi9saXRlcmF0dXJlL0ROTi80Njg3LWxhcmdlLXNjYWxlLWRpc3RyaWJ1dGVkLWRlZXAtbmV0d29ya3MucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAM4A0wDbA18DYQNmA3EDegOIA4wDkwOcA6EDrgOxA8MDxgPLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAA80=}}

@inproceedings{martens2010deep,
	Author = {Martens, James},
	Booktitle = {Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
	Date-Added = {2014-03-31 23:19:43 +0000},
	Date-Modified = {2014-03-31 23:19:43 +0000},
	Pages = {735--742},
	Title = {Deep learning via Hessian-free optimization},
	Year = {2010}}

@inproceedings{raina2009large,
	Author = {Raina, Rajat and Madhavan, Anand and Ng, Andrew Y},
	Booktitle = {ICML},
	Date-Added = {2014-03-31 23:17:55 +0000},
	Date-Modified = {2014-03-31 23:17:55 +0000},
	Pages = {873--880},
	Title = {Large-scale deep unsupervised learning using graphics processors.},
	Volume = {9},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QU2xpdGVyYXR1cmUvRE5OL0xhcmdlLXNjYWxlIERlZXAgVW5zdXBlcnZpc2VkIExlYXJuaW5nIHVzaW5nIEdyYXBoaWNzIFByb2Nlc3NvcnMucGRm0hcLGBlXTlMuZGF0YU8RAsIAAAAAAsIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM+zZ/tIKwAAAnv6Th9MYXJnZS1zY2FsZSBEZWVwIFVuIzI3QkZBNUIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACe/pbz1/EVQAAAAAAAAAAAAEABAAACSAAAAAAAAAAAAAAAAAAAAADRE5OAAAQAAgAAM+zS9sAAAARAAgAAM9fqDUAAAABACQCe/pOAnv6TQJ7+jMCe/mpAnv5pwAaiGUAFAHXABD6GgAQ6PEAAgCITWFjaW50b3NoIEhEOlVzZXJzOgBlcGljOgBEb2N1bWVudHM6AHNpbnRlZjoAcGhkMjAxNToAYXBwbGljYXRpb246AHByb2plY3QtZGVjc3JpcHRpb246AGxpdGVyYXR1cmU6AEROTjoATGFyZ2Utc2NhbGUgRGVlcCBVbiMyN0JGQTVCLnBkZgAOAIoARABMAGEAcgBnAGUALQBzAGMAYQBsAGUAIABEAGUAZQBwACAAVQBuAHMAdQBwAGUAcgB2AGkAcwBlAGQAIABMAGUAYQByAG4AaQBuAGcAIAB1AHMAaQBuAGcAIABHAHIAYQBwAGgAaQBjAHMAIABQAHIAbwBjAGUAcwBzAG8AcgBzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgCXVXNlcnMvZXBpYy9Eb2N1bWVudHMvc2ludGVmL3BoZDIwMTUvYXBwbGljYXRpb24vcHJvamVjdC1kZWNzcmlwdGlvbi9saXRlcmF0dXJlL0ROTi9MYXJnZS1zY2FsZSBEZWVwIFVuc3VwZXJ2aXNlZCBMZWFybmluZyB1c2luZyBHcmFwaGljcyBQcm9jZXNzb3JzLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDkAOkA8QO3A7kDvgPJA9ID4APkA+sD9AP5BAYECQQbBB4EIwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAQl}}

@inproceedings{ngiam2011optimization,
	Author = {Ngiam, Jiquan and Coates, Adam and Lahiri, Ahbik and Prochnow, Bobby and Le, Quoc V and Ng, Andrew Y},
	Booktitle = {Proceedings of the 28th International Conference on Machine Learning (ICML-11)},
	Date-Added = {2014-03-31 23:16:58 +0000},
	Date-Modified = {2014-03-31 23:16:58 +0000},
	Pages = {265--272},
	Title = {On optimization methods for deep learning},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPGxpdGVyYXR1cmUvRE5OL09uIE9wdGltaXphdGlvbiBNZXRob2RzIGZvciBEZWVwIExlYXJuaW5nLnBkZtIXCxgZV05TLmRhdGFPEQJ8AAAAAAJ8AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADPs2f7SCsAAAJ7+k4fT24gT3B0aW1pemF0aW9uIE1ldCMyN0JGQTVDLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAnv6XM9fxBcAAAAAAAAAAAABAAQAAAkgAAAAAAAAAAAAAAAAAAAAA0ROTgAAEAAIAADPs0vbAAAAEQAIAADPX6f3AAAAAQAkAnv6TgJ7+k0Ce/ozAnv5qQJ7+acAGohlABQB1wAQ+hoAEOjxAAIAiE1hY2ludG9zaCBIRDpVc2VyczoAZXBpYzoARG9jdW1lbnRzOgBzaW50ZWY6AHBoZDIwMTU6AGFwcGxpY2F0aW9uOgBwcm9qZWN0LWRlY3NyaXB0aW9uOgBsaXRlcmF0dXJlOgBETk46AE9uIE9wdGltaXphdGlvbiBNZXQjMjdCRkE1Qy5wZGYADgBcAC0ATwBuACAATwBwAHQAaQBtAGkAegBhAHQAaQBvAG4AIABNAGUAdABoAG8AZABzACAAZgBvAHIAIABEAGUAZQBwACAATABlAGEAcgBuAGkAbgBnAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgCAVXNlcnMvZXBpYy9Eb2N1bWVudHMvc2ludGVmL3BoZDIwMTUvYXBwbGljYXRpb24vcHJvamVjdC1kZWNzcmlwdGlvbi9saXRlcmF0dXJlL0ROTi9PbiBPcHRpbWl6YXRpb24gTWV0aG9kcyBmb3IgRGVlcCBMZWFybmluZy5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDNANIA2gNaA1wDYQNsA3UDgwOHA44DlwOcA6kDrAO+A8EDxgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAPI}}

@inproceedings{collobert2008unified,
	Author = {Collobert, Ronan and Weston, Jason},
	Booktitle = {Proceedings of the 25th international conference on Machine learning},
	Date-Added = {2014-03-31 23:09:55 +0000},
	Date-Modified = {2014-03-31 23:09:55 +0000},
	Organization = {ACM},
	Pages = {160--167},
	Title = {A unified architecture for natural language processing: Deep neural networks with multitask learning},
	Year = {2008}}

@incollection{bengio2006neural,
	Author = {Bengio, Yoshua and Schwenk, Holger and Sen{\'e}cal, Jean-S{\'e}bastien and Morin, Fr{\'e}deric and Gauvain, Jean-Luc},
	Booktitle = {Innovations in Machine Learning},
	Date-Added = {2014-03-31 23:07:56 +0000},
	Date-Modified = {2014-03-31 23:26:54 +0000},
	Pages = {137--186},
	Publisher = {Springer},
	Title = {A neural probabilistic language model},
	Year = {2006}}

@inproceedings{coates2011analysis,
	Author = {Coates, Adam and Ng, Andrew Y and Lee, Honglak},
	Booktitle = {International Conference on Artificial Intelligence and Statistics},
	Date-Added = {2014-03-31 23:06:13 +0000},
	Date-Modified = {2014-03-31 23:06:13 +0000},
	Pages = {215--223},
	Title = {An analysis of single-layer networks in unsupervised feature learning},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QWGxpdGVyYXR1cmUvRE5OL0FuIEFuYWx5c2lzIG9mIFNpbmdsZS1MYXllciBOZXR3b3JrcyBpbiBVbnN1cGVydmlzZWQgRmVhdHVyZSBMZWFybmluZy5wZGbSFwsYGVdOUy5kYXRhTxEC0AAAAAAC0AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAz7Nn+0grAAACe/pOH0FuIEFuYWx5c2lzIG9mIFNpbmcjMjdCRkE1MS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJ7+lHPX8GbAAAAAAAAAAAAAQAEAAAJIAAAAAAAAAAAAAAAAAAAAANETk4AABAACAAAz7NL2wAAABEACAAAz1+lewAAAAEAJAJ7+k4Ce/pNAnv6MwJ7+akCe/mnABqIZQAUAdcAEPoaABDo8QACAIhNYWNpbnRvc2ggSEQ6VXNlcnM6AGVwaWM6AERvY3VtZW50czoAc2ludGVmOgBwaGQyMDE1OgBhcHBsaWNhdGlvbjoAcHJvamVjdC1kZWNzcmlwdGlvbjoAbGl0ZXJhdHVyZToARE5OOgBBbiBBbmFseXNpcyBvZiBTaW5nIzI3QkZBNTEucGRmAA4AlABJAEEAbgAgAEEAbgBhAGwAeQBzAGkAcwAgAG8AZgAgAFMAaQBuAGcAbABlAC0ATABhAHkAZQByACAATgBlAHQAdwBvAHIAawBzACAAaQBuACAAVQBuAHMAdQBwAGUAcgB2AGkAcwBlAGQAIABGAGUAYQB0AHUAcgBlACAATABlAGEAcgBuAGkAbgBnAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgCcVXNlcnMvZXBpYy9Eb2N1bWVudHMvc2ludGVmL3BoZDIwMTUvYXBwbGljYXRpb24vcHJvamVjdC1kZWNzcmlwdGlvbi9saXRlcmF0dXJlL0ROTi9BbiBBbmFseXNpcyBvZiBTaW5nbGUtTGF5ZXIgTmV0d29ya3MgaW4gVW5zdXBlcnZpc2VkIEZlYXR1cmUgTGVhcm5pbmcucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A6QDuAPYDygPMA9ED3APlA/MD9wP+BAcEDAQZBBwELgQxBDYAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAEOA==}}

@article{claudiu2010deep,
	Author = {Claudiu Ciresan, Dan and Meier, Ueli and Gambardella, Luca Maria and Schmidhuber, Juergen},
	Date-Added = {2014-03-31 23:05:34 +0000},
	Date-Modified = {2014-03-31 23:05:34 +0000},
	Journal = {arXiv preprint arXiv:1003.0358},
	Title = {Deep Big Simple Neural Nets Excel on Handwritten Digit Recognition},
	Year = {2010}}

@article{hinton2012deep,
	Author = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N and others},
	Date-Added = {2014-03-31 23:04:11 +0000},
	Date-Modified = {2014-03-31 23:04:11 +0000},
	Journal = {Signal Processing Magazine, IEEE},
	Number = {6},
	Pages = {82--97},
	Publisher = {IEEE},
	Title = {Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups},
	Volume = {29},
	Year = {2012}}

@article{Dahl:2012aa,
	Abstract = {We propose a novel context-dependent (CD) model for large-vocabulary speech recognition (LVSR) that leverages recent advances in using deep belief networks for phone recognition. We describe a pre-trained deep neural network hidden Markov model (DNN-HMM) hybrid architecture that trains the DNN to produce a distribution over senones (tied triphone states) as its output. The deep belief network pre-training algorithm is a robust and often helpful way to initialize deep neural networks generatively that can aid in optimization and reduce generalization error. We illustrate the key components of our model, describe the procedure for applying CD-DNN-HMMs to LVSR, and analyze the effects of various modeling choices on performance. Experiments on a challenging business search dataset demonstrate that CD-DNN-HMMs can significantly outperform the conventional context-dependent Gaussian mixture model (GMM)-HMMs, with an absolute sentence accuracy improvement of 5.8\% and 9.2\% (or relative error reduction of 16.0\% and 23.2\%) over the CD-GMM-HMMs trained using the minimum phone error rate (MPE) and maximum-likelihood (ML) criteria, respectively.},
	Author = {Dahl, George E. and Yu, Dong and Deng, Li and Acero, Alex},
	Date-Added = {2014-03-31 22:56:00 +0000},
	Date-Modified = {2014-03-31 22:56:00 +0000},
	Doi = {DOI 10.1109/TASL.2011.2134090},
	Isi = {000298325600007},
	Isi-Recid = {202739063},
	Isi-Ref-Recids = {171479212 181601752 179700980 195406090 202739064 192948229 162220431 188509324 202739065 202739066 86339987 128644917 184186459 202739067 202204205 117832591 148816680 151861993 106592384 185330705 202739068 198024997 88906400 98612184 171478530 170205225 154054556 172828344 202739069 119251210 135327141 176230373 150372276 151296061 125419823 97401657 195525208 175952247 100021185 85912688 117304118 179681152 170603530 202739070 154054549 202739071 201610286 193318509 202204209 202739072 146034608 79225989 160709622 195302468 119251226 164113696 171477671 151862314 193318468 195810842 91703401 124387471 60421737 189491550 169731898 65501907 202739074 119251193 202739075 201832341 184186470 202739076 113180072 158738134 183552900 202739077 182281022 202204210 183552901 175952245 172148893 149754683 200394999 202739078},
	Iso-Source-Abbreviation = {Ieee T Audio Speech},
	Journal = {Ieee Transactions On Audio Speech and Language Processing},
	Keywords = {Artificial neural network-hidden Markov model (ANN-HMM); context-dependent phone; deep belief network; deep neural network hidden Markov model (DNN-HMM); speech recognition; large-vocabulary speech recognition (LVSR)},
	Pages = {30--42},
	Times-Cited = {64},
	Title = {Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition},
	Volume = {20},
	Year = {2012},
	Bdsk-Url-1 = {http://ws.isiknowledge.com/cps/openurl/service?url_ver=Z39.88-2004&rft_id=info:ut/000298325600007}}

@Article{Coates2012,
  author = {Coates, Adam and Huval, Brody and Wang, Tao and Wu, David J and Ng, Andrew Y},
  title  = {{Deep learning with COTS HPC systems}},
  year   = {2012},
  file   = {:Users/epic/Documents/Mendeley Desktop/Coates et al/Unknown/CoatesHuvalWangWuNgCatanzaro_icml2013.pdf:pdf},
}

@article{stanleycppn,
	Author = {Stanley, Kenneth O},
	Journal = {Genetic Programming and Evolvable Machines Special Issue on Developmental Systems},
	Publisher = {New York, NY: Springer},
	Title = {{Compositional Pattern Producing Networks: A Novel Abstraction of Development}},
	Url = {http://eplex.cs.ucf.edu/papers/stanley\_gpem07.pdf},
	Year = {2007},
	Bdsk-Url-1 = {http://eplex.cs.ucf.edu/papers/stanley%5C_gpem07.pdf}}

@phdthesis{phdneat,
	Author = {Stanley, Kenneth O},
	Date-Modified = {2014-04-12 23:59:20 +0000},
	File = {::},
	School = {The University of Texas at Austin},
	Title = {{Efficient evolution of neural networks through complexification}},
	Url = {http://nn.cs.utexas.edu/downloads/papers/stanley.phd04.pdf},
	Year = {2004},
	Bdsk-Url-1 = {http://nn.cs.utexas.edu/$%5Cbackslash$$%5Cbackslash$downloads/papers/stanley.phd04.pdf}}

@proceedings{rovingeye,
	Author = {Stanley, Kenneth O},
	Booktitle = {Genetic and Evolutionary Computation Conference},
	Organization = {The University of Texas at Austin},
	Publisher = {Springer-Verlag},
	Title = {{Evolving a Roving Eye for Go}},
	Url = {http://nn.cs.utexas.edu/downloads/papers/stanley.gecco04.pdf},
	Year = {2004},
	Bdsk-Url-1 = {http://nn.cs.utexas.edu/downloads/papers/stanley.gecco04.pdf}}

@techreport{stanley:utcstr01,
	Author = {Stanley, Kenneth and Miikkulainen, Risto},
	Number = {AI2001-290},
	Title = {{Evolving Neural Networks through Augmenting Topologies}},
	Url = {http://www.cs.utexas.edu/users/nn/pages/publications/abstracts.html\#stanley.utcstr01.ps.gz},
	Year = {2001},
	Bdsk-Url-1 = {http://www.cs.utexas.edu/users/nn/pages/publications/abstracts.html%5C#stanley.utcstr01.ps.gz}}
@article{power2008understanding,
  title={Understanding data-driven decision support systems},
  author={Power, Daniel J},
  journal={Information Systems Management},
  volume={25},
  number={2},
  pages={149--154},
  year={2008},
  publisher={Taylor \& Francis}
}
        @article{inmon1981database,
  title={Database machines and decision support systems},
  author={Inmon, WH},
  journal={Third Wave Processing, QED Technical PublishingGroup},
  year={1981}
}
@Article{arnott2014critical,
  author    = {Arnott, David and Pervan, Graham},
  title     = {A critical analysis of decision support systems research revisited: the rise of design science},
  journal   = {Journal of Information Technology},
  year      = {2014},
  volume    = {29},
  number    = {4},
  pages     = {269--293},
  publisher = {Nature Publishing Group},
}
@Article{richter05,
  author  = {Richter, Michael M. and Aamodt, Agnar},
  title   = {Case-based reasoning foundations},
  journal = {The Knowledge Engineering Review},
  year    = {2005},
  volume  = {20},
  number  = {03},
  pages   = {203--207},
  type    = {Journal Article},
  url     = {http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=435273&fileId=S0269888906000695},
}
@article{maaloy2019spatio,
  title={A spatio-temporal recurrent network for salmon feeding action recognition from underwater videos in aquaculture},
  author={M{\aa}l{\o}y, H{\aa}kon and Aamodt, Agnar and Misimi, Ekrem},
  journal={Computers and Electronics in Agriculture},
  volume={167},
  pages={105087},
  year={2019},
  publisher={Elsevier}
}
@article{arnott2007methodological,
  title={The Methodological and Theoretical Foundations of Decision Support Systems Research},
  author={Arnott, David and Pervan, Graham},
  journal={Information Systems Foundations},
  pages={247},
  year={2007}
}
@article{arnott2005critical,
  title={A critical analysis of decision support systems research},
  author={Arnott, David and Pervan, Graham},
  journal={Journal of information technology},
  volume={20},
  number={2},
  pages={67--87},
  year={2005},
  publisher={Springer}
}
        @article{pervan2005descriptive,
  title={A descriptive analysis of decision support systems research between 1990 and 2003},
  author={Pervan, Graham and Arnott, David and Dodson, Gemma},
  journal={Australasian Journal of Information Systems},
  volume={12},
  pages={178--191},
  year={2005},
  publisher={AJIS}
}
@article{arnott2012design,
  title={Design science in decision support systems research: An assessment using the Hevner, March, Park, and Ram Guidelines},
  author={Arnott, David and Pervan, Graham},
  journal={Journal of the Association for Information Systems},
  volume={13},
  number={11},
  pages={923},
  year={2012},
  publisher={Association for Information Systems}
}

@Article{azadivar2009decision,
  author    = {Azadivar, Farhad and Truong, Tu and Jiao, Yue},
  title     = {A decision support system for fisheries management using operations research and systems science approach},
  journal   = {Expert Systems with Applications},
  year      = {2009},
  volume    = {36},
  number    = {2},
  pages     = {2971--2978},
  publisher = {Elsevier},
}

@InProceedings{budgen2008using,
  author       = {Budgen, David and Turner, Mark and Brereton, Pearl and Kitchenham, Barbara},
  title        = {Using mapping studies in software engineering},
  booktitle    = {Proceedings of PPIG},
  year         = {2008},
  volume       = {8},
  pages        = {195--204},
  organization = {Lancaster University},
}

@Article{hargrave2002traffic,
  author    = {Hargrave, Barry T},
  journal   = {Ocean \& coastal management},
  title     = {A traffic light decision system for marine finfish aquaculture siting},
  year      = {2002},
  number    = {4},
  pages     = {215--235},
  volume    = {45},
  citations = {22},
  citedbyid = {7457347378299076190},
  file      = {file:/Users/epic/research/papers/DSS in Fisheries and Aquaculture -Systematic Survey/papers/15-Hargrave2002.pdf:pdf},
  md5sum    = {72e398c689a83f182bb514646dade6e7},
  pdfmeat   = {timestamp: 2015-09-16 21:54:45; queries: 1; inode: 77091528},
  publisher = {Elsevier},
  url       = {http://www.sciencedirect.com/science/article/pii/S096456910200056X},
}
@article{delen2010comparative,
  title={A comparative analysis of machine learning techniques for student retention management},
  author={Delen, Dursun},
  journal={Decision Support Systems},
  volume={49},
  number={4},
  pages={498--506},
  year={2010},
  publisher={Elsevier}
}
        @article{etheridge2000comparison,
  title={A comparison of selected artificial neural networks that help auditors evaluate client financial viability},
  author={Etheridge, Harlan L and Sriram, Ram S and Hsu, HY},
  journal={Decision Sciences},
  volume={31},
  number={2},
  pages={531--550},
  year={2000},
  publisher={Wiley Online Library}
}
@article{hill1994neural,
  title={Neural network models for intelligent support of managerial decision making},
  author={Hill, Tim and Remus, William},
  journal={Decision Support Systems},
  volume={11},
  number={5},
  pages={449--459},
  year={1994},
  publisher={Elsevier}
}
@article{sinha2008incorporating,
  title={Incorporating domain knowledge into data mining classifiers: An application in indirect lending},
  author={Sinha, Atish P and Zhao, Huimin},
  journal={Decision Support Systems},
  volume={46},
  number={1},
  pages={287--299},
  year={2008},
  publisher={Elsevier}
}

@Article{kemp2002visualization,
  author    = {Kemp, Z and Meaden, G},
  journal   = {ICES Journal of Marine Science: Journal du Conseil},
  title     = {Visualization for fisheries management from a spatiotemporal perspective},
  year      = {2002},
  number    = {1},
  pages     = {190--202},
  volume    = {59},
  citations = {18},
  citedbyid = {3725156684161027778},
  file      = {file:/Users/epic/research/papers/DSS in Fisheries and Aquaculture -Systematic Survey/papers/16-Kemp2002.pdf:pdf},
  md5sum    = {81232816884f60edc063aa47924a0ec9},
  pdfmeat   = {timestamp: 2015-09-16 21:54:47; queries: 1; inode: 77091883},
  publisher = {Oxford University Press},
  url       = {http://icesjms.oxfordjournals.org/content/59/1/190.short},
}
@inproceedings{iglesias2005support,
  title={A Support System for Fisheries Based on Neural Networks.},
  author={Iglesias, Alfonso and Varela, Bernardino Arcay and Rodr{\'\i}guez, Alejandra and Cotos, Jos{\'e} Manuel},
  booktitle={Proceedings of the 1st International Workshop on Artificial Neural Networks and Intelligent Information},
  pages={112--121},
  year={2005}
}
@article{koutroumanidis2006time,
  title={Time-series modeling of fishery landings using ARIMA models and Fuzzy Expected Intervals software},
  author={Koutroumanidis, Theodoros and Iliadis, Lazaros and Sylaios, Georgios K},
  journal={Environmental Modelling \& Software},
  volume={21},
  number={12},
  pages={1711--1721},
  year={2006},
  publisher={Elsevier}
}
@article{carrick2007development,
  title={Development of a spatial Decision Support System (DSS) for the Spencer Gulf penaeid prawn fishery, South Australia},
  author={Carrick, NA and Ostendorf, Bertram},
  journal={Environmental Modelling \& Software},
  volume={22},
  number={2},
  pages={137--148},
  year={2007},
  publisher={Elsevier}
}
@article{iglesias2007integration,
  title={Integration of remote sensing techniques and connectionist models for decision support in fishing catches},
  author={Iglesias, Alfonso and Dafonte, Carlos and Arcay, Bernardino and Cotos, J Manuel},
  journal={Environmental Modelling \& Software},
  volume={22},
  number={6},
  pages={862--870},
  year={2007},
  publisher={Elsevier}
}
@InProceedings{wang2006awqee,
  author       = {Wang, Ruimei and Chen, DaQing and Fu, Zetian},
  title        = {AWQEE-DSS: A decision support system for aquaculture water quality evaluation and early-warning},
  booktitle    = {Computational Intelligence and Security, 2006 International Conference on},
  year         = {2006},
  volume       = {2},
  pages        = {959--962},
  organization = {IEEE},
}

@InProceedings{teniwut2013decision,
  author       = {Teniwut, Yuliana K and others},
  title        = {Decision support system for increasing sustainable productivity on fishery agroindustry supply chain},
  booktitle    = {Advanced Computer Science and Information Systems (ICACSIS), 2013 International Conference on},
  year         = {2013},
  pages        = {297--302},
  organization = {IEEE},
}
@article{zopounidis1997use,
  title={On the use of knowledge-based decision support systems in financial management: A survey},
  author={Zopounidis, Constantin and Doumpos, Michael and Matsatsinis, Nikolaos F},
  journal={Decision Support Systems},
  volume={20},
  number={3},
  pages={259--277},
  year={1997},
  publisher={Elsevier}
}
@article{eom2006survey,
  title={A survey of decision support system applications (1995--2001)},
  author={Eom, S and Kim, E},
  journal={Journal of the Operational Research Society},
  volume={57},
  number={11},
  pages={1264--1278},
  year={2006},
  publisher={Springer}
}
        @article{eom1990decision,
  title={Decision support systems applications research: A bibliography (1971--1988)},
  author={Eom, Hyun B and Lee, Sang M},
  journal={European Journal of Operational Research},
  volume={46},
  number={3},
  pages={333--342},
  year={1990},
  publisher={Elsevier}
}

@Article{Mora2005,
  author    = {Manuel Mora and Guisseppi Forgionne and Jatinder N. D. Gupta and Francisco Cervantes and Ovsei Gelman},
  journal   = {Journal of Decision Systems},
  title     = {A Strategic Research Agenda},
  year      = {2005},
  number    = {1-2},
  pages     = {179-196},
  volume    = {14},
  doi       = {10.3166/jds.14.179-196},
  eprint    = {https://doi.org/10.3166/jds.14.179-196},
  publisher = {Taylor \& Francis},
}

@InProceedings{merkert2015survey,
  author    = {Merkert, Johannes and Mueller, Marcus and Hubl, Marvin},
  title     = {A Survey of the Application of Machine Learning in Decision Support Systems.},
  booktitle = {ECIS},
  year      = {2015},
}
@incollection{eom2008reference,
  title={Reference disciplines of decision support systems},
  author={Eom, Sean B},
  booktitle={Handbook on Decision Support Systems 1},
  pages={141--159},
  year={2008},
  publisher={Springer}
}
@article{eom1999decision,
  title={Decision support systems research: current state and trends},
  author={Eom, Sean B},
  journal={Industrial Management \& Data Systems},
  volume={99},
  number={5},
  pages={213--221},
  year={1999},
  publisher={MCB UP Ltd}
}
@article{eom1996mapping,
  title={Mapping the intellectual structure of research in decision support systems through author cocitation analysis (1971--1993)},
  author={Eom, Sean B},
  journal={Decision Support Systems},
  volume={16},
  number={4},
  pages={315--338},
  year={1996},
  publisher={Elsevier}
}

@Inbook{mathisenWS2017,
  title="Data driven case base construction for prediction of success of marine operations",
  author="Mathisen, Bj{\o}rn Magnus and Aamodt, Agnar and Langseth, Helge",
  booktitle={Proceedings of ICCBR 2017 Workshops (CAW, CBRDL, PO-CBR), Doctoral Consortium, and Competitions
co-located with the 25th International Conference on Case-Based Reasoning (ICCBR 2017) },
  pages={102--111},
  howpublished={\url{https://www.idi.ntnu.no/~bjornmm/iccbr2017-ws.pdf}},
        notes={\url{https://www.idi.ntnu.no/~bjornmm/iccbr2017-ws.pdf}},
  url={https://www.idi.ntnu.no/~bjornmm/iccbr2017-ws.pdf},

  year={2017}
}
@article{mathisen2016decision,
          title={Decision support systems in fisheries and aquaculture: A systematic review},
          author={Mathisen, Bj{\o}rn Magnus and Haro, Peter and Hanssen, B{\aa}rd and Bj{\"o}rk, Sara and Walderhaug, St{\aa}le},
          journal={arXiv preprint arXiv:1611.08374},
          year={2016}
        }

@Article{mathisen2015empirical,
  author       = {Mathisen, Bj{\o}rn Magnus and Wienhofen, Leendert and Roman, Dumitru},
  journal      = {arXiv preprint arXiv:1509.03045v2},
  title        = {Empirical Big Data Research: A Systematic Literature Mapping},
  year         = {2015},
  eprint       = {1509.03045},
  eprinttype   = {arxiv},
  howpublished = {\url{https://arxiv.org/pdf/1509.03045}},
  notes        = {\url{https://arxiv.org/pdf/1509.03045}},
}
@Unpublished{bjornmmphdplan,
  author = {Bj{\o}rn Magnus Mathisen},
  title  = {PhD project plan - Exploiting data to support operations of EXPOSED aquaculture installations},
  notes={\url{https://www.idi.ntnu.no/~bjornmm/exposed-aquaculture.pdf}},
  url={https://www.idi.ntnu.no/~bjornmm/exposed-aquaculture.pdf},
  howpublished={\url{https://www.idi.ntnu.no/~bjornmm/exposed-aquaculture.pdf}}
}
@InBook{roth-berghofer04,
  pages     = {389--403},
  title     = {Explanations and case-based reasoning: Foundational issues},
  publisher = {Springer-Verlag},
  author    = {Roth-Berghofer, Thomas R.},
  type      = {Book Section},
  address   = {September 2004},
  booktitle = {Advances in Case-Based Reasoning (In Peter Funk and Pedro A. Gonz{\'a}lez-Calero, editors)},
}

@InBook{Wienhofen2016,
  author    = {Wienhofen, Leendert W. M. and Mathisen, Bj{\o}rn Magnus},
  editor    = {Goel, Ashok and D{\'i}az-Agudo, M Bel{\'e}n and Roth-Berghofer, Thomas},
  pages     = {430--444},
  publisher = {Springer International Publishing},
  title     = {Defining the initial case-base for a cbr operator support system in digital finishing},
  year      = {2016},
  address   = {Cham},
  isbn      = {978-3-319-47096-2},
  abstract  = {Case-based reasoning (CBR) literature defines the process of defining a case-base as a hard and time-demanding task though the same literature does not report in detail on how to build your initial case base. The main contribution of this paper is the description of the methods that we used in order to build the initial case-base including the steps taken in order to make sure that the quality of the initial case set is appropriate. We first present the domain and argue why CBR is an appropriate solution for our application. Then we detail how we created the case base and show how the cases are validated.},
  booktitle = {Case-Based Reasoning Research and Development: 24th International Conference, ICCBR 2016, Atlanta, GA, USA, October 31 - November 2, 2016, Proceedings},
  doi       = {10.1007/978-3-319-47096-2_29},
}
@article{mujtaba2008software,
  author = {Mujtaba, Shahid and Petersen, Kai and Feldt, Robert and Mattsson,
	Michael},
  title = {Software product line variability: A systematic mapping study},
  journal = {School of Engineering, Blekinge Inst. of Technology},
  year = {2008},
  date-added = {2014-06-15 06:05:07 +0000},
  date-modified = {2014-06-15 06:05:07 +0000},
  owner = {epic}
}

@InProceedings{Petersen2007,
  author    = {Petersen, Kai and Feldt, Robert},
  booktitle = {Proceedings of the 12th International Conference on Evaluation and Assessment in Software Engineering},
  title     = {Systematic mapping studies in software engineering},
  year      = {2008},
  pages     = {71--80},
  file      = {:Users/epic/Documents/Mendeley Desktop/Petersen, Feldt/Proceedings of the 12th International Conference on Evaluation and Assessment in Software Engineering/petersen_ease08_sysmap_studies_in_se.pdf:pdf},
  keywords  = {evidence based software engineering,systematic mapping studies,systematic reviews},
  owner     = {epic},
  url       = {http://robertfeldt.net/publications/petersen\_ease08\_sysmap\_studies\_in\_se.pdf},
}
@techreport{kitchenham2007,
  author = {Kitchenham, Barbara A and Charters, Stuart},
  title = {Guidelines for performing systematic literature reviews in software engineering},
  year = 2007,
  owner = {epic},
  timestamp = {2014.02.17},
  institution = {Keele University},
  booktitle={Technical report, Ver. 2.3 EBSE Technical Report. EBSE}
}
@article{kitchenham2007cross,
  title={Cross versus within-company cost estimation studies: A systematic review},
  author={Kitchenham, Barbara A and Mendes, Emilia and Travassos, Guilherme H},
  journal={Software Engineering, IEEE Transactions on},
  volume={33},
  number={5},
  pages={316--329},
  year={2007},
  publisher={IEEE}
}
@article{torgo1997regression,
  title={Regression using classification algorithms},
  author={Torgo, Luis and Gama, Joao},
  journal={Intelligent Data Analysis},
  volume={1},
  number={1-4},
  pages={275--292},
  year={1997},
  publisher={Elsevier}
}
@inproceedings{ludl2000relative,
  title={Relative unsupervised discretization for regression problems},
  author={Ludl, Marcus-Christopher and Widmer, Gerhard},
  booktitle={European Conference on Machine Learning},
  pages={246--254},
  year={2000},
  organization={Springer}
}

% ICCBR2018
@book{bach12-2,
   author = {Bach, Kerstin},
   title = {Knowledge Acquisition for Case-Based Reasoning Systems},
   publisher = {Verlag Dr Hut},
   ISBN = {ISBN 978-3-8439-1357-7},
   year = {2012},
   type = {Book}
}
@inproceedings{bach2012developing,
  author="Bach, Kerstin
and Althoff, Klaus-Dieter",
editor="Agudo, Bel{\'e}n D{\'i}az
and Watson, Ian",
title="Developing case-based reasoning applications using myCBR 3",
booktitle="Case-Based Reasoning Research and Development",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="17--31",
isbn="978-3-642-32986-9"
}
@inproceedings{roth2008explanation,
  title={Explanation capabilities of the open source case-based reasoning tool mycbr},
  author={Roth-Berghofer, Thomas R and Bahls, Daniel},
  booktitle={Proceedings of the thirteenth UK workshop on Case-Based Reasoning UKCBR},
  pages={23--34},
  year={2008}
}
@incollection{roth2009code,
  title={Code tagging and similarity-based retrieval with mycbr},
  author={Roth-Berghofer, Thomas R and Bahls, Daniel},
  booktitle={Research and Development in Intelligent Systems XXV},
  pages={19--32},
  year={2009},
  publisher={Springer}
}
@article{hornik1989multilayer,
  title={Multilayer feedforward networks are universal approximators},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal={Neural networks},
  volume={2},
  number={5},
  pages={359--366},
  year={1989},
  publisher={Elsevier}
}
@inproceedings{langseth1999learning,
  title={Learning retrieval knowledge from data},
  author={Langseth, Helge and Aamodt, Agnar and Winnem, Ole Martin},
  booktitle={Sixteenth International Joint Conference on Artificial Intelligence, Workshop ML-5: Automating the Construction of Case-Based Reasoners. Stockholm},
  pages={77--82},
  year={1999},
  organization={Citeseer}
}
@inproceedings{nikpour2018bayesian,
  title={Bayesian-supported retrieval in BNCreek: A knowledge-intensive case-based reasoning system},
  author={Nikpour, Hoda and Aamodt, Agnar and Bach, Kerstin},
  booktitle={International Conference on Case-Based Reasoning},
  pages={323--338},
  year={2018},
  organization={Springer}
}
@article{tversky1977features,
  title={Features of similarity.},
  author={Tversky, Amos},
  journal={Psychological review},
  volume={84},
  number={4},
  pages={327},
  year={1977},
  publisher={American Psychological Association}
}

@inproceedings{gabel2004exploiting,
  title={Exploiting background knowledge when learning similarity measures},
  author={Gabel, Thomas and Stahl, Armin},
  booktitle={European Conference on Case-Based Reasoning},
  pages={169--183},
  year={2004},
  organization={Springer}
}
@InProceedings{gabel2015ann,
author="Gabel, Thomas
and Godehardt, Eicke",
editor="H{\"u}llermeier, Eyke
and Minor, Mirjam",
title="Top-down induction of similarity measures using similarity clouds",
booktitle="Case-Based Reasoning Research and Development",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="149--164",
abstract="The automatic acquisition of a similarity measure for a CBR system is appealing as it frees the system designer from the tedious task of defining it manually. However, acquiring similarity measures with some machine learning approach typically results in some black box representation of similarity whose magic-like combination of high precision and low explainability may decrease a human user's trust in the system. In this paper, we target this problem by suggesting a method to induce a human-readable and easily understandable -- and thus potentially trustworthy -- representation of similarity from a previously learned black box-like representation of similarity measures. Our experimental evaluations support the claim that, given some highly precise learned similarity measure, we can induce a less powerful, but human-understandable representation of it while its corresponding level of accuracy is only marginally impaired.",
isbn="978-3-319-24586-7"
}
@inproceedings{hullermeier2011preference,
  title={Preference-based CBR: First steps toward a methodological framework},
  author={H{\"u}llermeier, Eyke and Schlegel, Patrice},
  booktitle={International Conference on Case-Based Reasoning},
  pages={77--91},
  year={2011},
  organization={Springer}
}
@inproceedings{hullermeier2013preference,
  title={Preference-based CBR: General ideas and basic principles},
  author={H{\"u}llermeier, Eyke and Cheng, Weiwei},
  booktitle={IJCAI},
  pages={3012--3016},
  year={2013}
}
@inproceedings{stahl2001learning,
  title={Learning feature weights from case order feedback},
  author={Stahl, Armin},
  booktitle={Proceedings of the 4th International Conference on Case-Based Reasoning (ICCBR 2001)},
  pages={502--516},
  year={2001},
  Location={Vancouver},
  organization={Springer}
}
@inproceedings{stahl2006optimizing,
  title={Optimizing similarity assessment in case-based reasoning},
  author={Stahl, Armin and Gabel, Thomas},
  booktitle={Proceedings of the National Conference on Artificial Intelligence},
  volume={21},
  number={2},
  pages={1667},
  year={2006},
  organization={Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999}
}
@inproceedings{stahl2003using,
  title={Using evolution programs to learn local similarity measures},
  author={Stahl, Armin and Gabel, Thomas},
  booktitle={Proceedings of the 5th International Conference on Case-Based Reasoning (ICCBR 2003)},
  pages={537--551},
  year={2003},
  Location={Trondheim},
  Publisher={Springer}
}
@article{hevner04,
   author = {Hevner, Alan R. and March, Salvatore T. and Park, Jinsoo and Ram, Sudha},
   title = {Design science in information systems research},
   journal = {MIS Quarterly},
   volume = {28},
   number = {1},
   year = {2004},
   type = {Journal Article}
}
@book{carsten00,
   author = {Tautz, Carsten},
   title = {Costumizing Software Engineering Experience Management Systems to Organizational Needs},
   publisher = {Fraunhofer-IRB-Verlag},
   year = {2000},
   type = {Book}
}
@Book{bergmann03,
  title     = {Developing industrial case-based reasoning applications: The INRECA methodology},
  publisher = {Springer},
  year      = {2003},
  author    = {Bergmann, Ralph, et al.},
  rating    = {Rating},
  type      = {Book},
}
@Book{bergmann02,
  title     = {Experience Management Foundations, Development Methodology, and Internet-Based Applications},
  publisher = {Springer-Verlag Berlin Heidelberg},
  year      = {2002},
  author    = {Bergmann, Ralph},
  doi       = {10.1007/3-540-45759-3},
  type      = {Book},
}
@book{leake1996case,
  title={Case-Based Reasoning: Experiences, lessons and future directions},
  author={Leake, David B},
  year={1996},
  publisher={MIT press}
}

@Article{Tversky1977,
  author    = {Tversky, Amos},
  title     = {Features of similarity.},
  journal   = {Psychological review},
  year      = {1977},
  volume    = {84},
  number    = {4},
  pages     = {327},
  publisher = {American Psychological Association},
}
@article{kezunovic1996detect,
  title={Detect and classify faults using neural nets},
  author={Kezunovic, Mladen and Rikalo, Igor},
  journal={IEEE Computer Applications in Power},
  volume={9},
  number={4},
  pages={42--47},
  year={1996},
  publisher={IEEE}
}
@inbook{kubie,
author={Kubie, J. and Melkus, L. A. and Johnson, R. C. and Flanagan, G. a.},
title={User-centred design},
booktitle={IS Management Handbook: 7th Edition},
editor = {Brown, Carol V. and Topi, Heikki},
publisher = {CRC Press, Inc.},
 isbn = {0849398207},
 edition = {7th},
 address = {Boca Raton, FL, USA},
year={1999}
}
@incollection{shluzas2014user,
  title={User-centered innovation for the design and development of complex products and systems},
  author={Shluzas, Lauren Aquino and Steinert, Martin and Katila, Riitta},
  booktitle={Design Thinking Research},
  pages={135--149},
  year={2014},
  publisher={Springer}
}

@Article{MorkBach2018,
    author="Mork, Paul Jarle and Bach, Kerstin",
    title="A decision support system to enhance self-management of low back pain: Protocol for the selfBACK project",
    journal="JMIR Res Protoc",
    year="2018",
    month="7",
    day="20",
    volume="7",
    number="7",
    pages="e167",
    issn="1929-0748"
}

@inproceedings{EnginEtAl18,
  author    = {Harun Kursat Engin and Farrokh Nadim and Pasquale Carotenuto and Kerstin Bach},
  title     = {Estimation of pile capacities using case-based reasoning (CBR) method},
  booktitle = {Proceedings of 4th International Symposium on Computational Geomechanics},
  year      = {2018}
}

@Article{Musen2015,
  author     = {Musen, Mark A.},
  journal    = {AI Matters},
  title      = {The Prot{\'e}g{\'e} project: A look back and a look forward},
  year       = {2015},
  issn       = {2372-3483},
  month      = jun,
  number     = {4},
  pages      = {4--12},
  volume     = {1},
  acmid      = {2757003},
  address    = {New York, NY, USA},
  doi        = {10.1145/2757001.2757003},
  issue_date = {June 2015},
  numpages   = {9},
  publisher  = {ACM},
}
@article{Jalali2016,
 author = {Jalali, Vahid and Leake, David},
 title = {Enhancing case-based regression with automatically-generated ensembles of adaptations},
 journal = {J. Intell. Inf. Syst.},
 issue_date = {April     2016},
 volume = {46},
 number = {2},
 month = apr,
 year = {2016},
 issn = {0925-9902},
 pages = {237--258},
 numpages = {22},
 acmid = {2904280},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA}
}

@InProceedings{Jalali2015,
author="Jalali, Vahid and Leake, David",
editor="H{\"u}llermeier, Eyke and Minor, Mirjam",
title="CBR meets big data: A case study of large-scale adaptation rule generation",
booktitle="Case-Based Reasoning Research and Development",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="181--196"
}
@inproceedings{Aamodt04,
  author    = {Agnar Aamodt},
  title     = {Knowledge-intensive case-based reasoning in {CREEK}},
  booktitle = {Advances in Case-Based Reasoning, 7th European Conference, {ECCBR}
               2004, Madrid, Spain, August 30 - September 2, 2004, Proceedings},
  pages     = {1--15},
  year      = {2004}
}
@inproceedings{JaiswalEtAl2019,
  author    = {Amar Jaiswal and Kerstin Bach and Ingebrigt Meisingset and Ottar Vasseljen},
  title     = {Case representation and similarity modeling for non-specific musculoskeletal disorders - a case-based reasoning approach},
  booktitle = {{FLAIRS}-32 Conference},
  publisher = {{AAAI} Press},
  year      = {2019}
}
@InProceedings{VermaEtAl2018,
author="Verma, Deepika
and Bach, Kerstin
and Mork, Paul Jarle",
editor="Cox, Michael T.
and Funk, Peter
and Begum, Shahina",
title="Modelling similarity for comparing physical activity profiles - a data-driven approach",
booktitle="Case-Based Reasoning Research and Development",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="415--430",
isbn="978-3-030-01081-2"
}

@inproceedings{bergmanncollaborative2014,
	address = {New York, {NY}, {USA}},
	series = {{GROUP} 14},
	title = {The collaborative agile knowledge engine {CAKE}},
	isbn = {978-1-4503-3043-5},
	abstract = {The Collaborative Agile Knowledge Engine ({CAKE}) is a prototypical generic software system for integrated process and knowledge management. {CAKE} integrates recent research results on agile workflows, process-oriented case-based reasoning, and web technologies into a common platform that can be configured to different application domains and needs. We describe the main concepts and the architecture of {CAKE} and sketch three example applications.},
	urldate = {2014-12-11},
	booktitle = {Proceedings of the 18th International Conference on Supporting Group Work},
	publisher = {{ACM}},
	author = {Bergmann, Ralph and Gessinger, Sarah and G{\"o}rg, Sebastian and M{\"u}ller, Gilbert},
	year = {2014},
	keywords = {agile workflows, case-based reasoning, knowledge management, process management},
	pages = {281--284}
}
@inproceedings{Schulz99cbr-works,
    author = {Stefan Schulz},
    title = {CBR-Works - A state-of-the-art shell for case-based application building},
    booktitle = {Proceedings of the 7th German Workshop on Case-Based Reasoning, GWCBR'99, Wrzburg},
    year = {1999},
    pages = {3--5},
    publisher = {Springer-Verlag}
}

@inproceedings{bergmann2001utility,
  title={Utility-oriented matching: A new research direction for case-based reasoning},
  author={Bergmann, Ralph and Richter, M Michael and Schmitt, Sascha and Stahl, Armin and Vollrath, Ivo},
  booktitle={Professionelles Wissensmanagement: Erfahrungen und Visionen. Proceedings of the 1st Conference on Professional Knowledge Management. Shaker},
  year={2001}
}
@article{costello2009global,
  title={The global economic cost of sea lice to the salmonid farming industry},
  author={Costello, Mark J},
  journal={Journal of fish diseases},
  volume={32},
  number={1},
  pages={115--118},
  year={2009},
  publisher={Wiley Online Library}
}
@article{jensen2010escapes,
  title={Escapes of fishes from Norwegian sea-cage aquaculture: causes, consequences and prevention},
  author={Jensen, {\O}sten and Dempster, T and Thorstad, EB and Uglem, I and Fredheim, A},
  journal={Aquaculture Environment Interactions},
  volume={1},
  number={1},
  pages={71--83},
  year={2010}
}
@misc{Prasad95,
   author = {Nagendra Prasad, M. V. and Lander, S. E. and Lesser, V. R.},
   title = {On retrieval and reasoning in distributed case bases},
   volume = {1},
   pages = {351-356 vol.1},
   year = {1995},
   type = {Generic}
}
@Article{Plaza05,
  author  = {Plaza, Enric and McGinty, Lorraine},
  title   = {Distributed case-based reasoning},
  journal = {The Knowledge Engineering Review},
  year    = {2005},
  volume  = {20},
  number  = {03},
  pages   = {261--265},
  type    = {Journal Article},
  url     = {http://journals.cambridge.org/article\_S0269888906000683},
}
@Misc{Leake01,
  author    = {Leake, David B. and Sooriamurthi, Raja},
  title     = {When Two Case Bases Are Better than One: Exploiting Multiple Case Bases},
  year      = {2001},
  doi       = {10.1007/3-540-44593-5\_23},
  pages     = {321--335},
  publisher = {Springer Berlin Heidelberg},
  type      = {Conference Paper},
  volume    = {2080},
}
@article{holmen2017organisational,
  title={Organisational safety indicators in aquaculture--a preliminary study},
  author={Holmen, Ingunn Marie and Utne, Ingrid Bouwer and Haugen, Stein},
  journal={Risk, Reliability and Safety: Innovating Theory and Practice: Proceedings of ESREL 2016 (Glasgow, Scotland, 25-29 September 2016)},
  year={2017},
  publisher={CRC press}
}
@inproceedings{amin2019cases,
  title={Cases without Borders: Automating Knowledge Acquisition Approach using Deep Autoencoders and Siamese Networks in Case-Based Reasoning},
  author={Amin, Kareem},
  booktitle={2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)},
  pages={133--140},
  year={2019},
  organization={IEEE}
}
@inproceedings{amin2019advanced,
  title={Advanced similarity measures using word embeddings and siamese networks in CBR},
  author={Amin, Kareem and Lancaster, George and Kapetanakis, Stelios and Althoff, Klaus-Dieter and Dengel, Andreas and Petridis, Miltos},
  booktitle={Proceedings of SAI Intelligent Systems Conference},
  pages={449--462},
  year={2019},
  organization={Springer}
}
@article{holmer2010environmental,
  title={Environmental issues of fish farming in offshore waters: perspectives, concerns and research needs},
  author={Holmer, Marianne},
  journal={Aquaculture Environment Interactions},
  volume={1},
  number={1},
  pages={57--70},
  year={2010}
}
@article{holen2018occupationala,
  title={Occupational safety in aquaculture--Part 1: Injuries in Norway},
  author={Holen, Siri Mariane and Utne, Ingrid Bouwer and Holmen, Ingunn Marie and Aasjord, Halvard},
  journal={Marine Policy},
  volume={96},
  pages={184--192},
  year={2018},
  publisher={Elsevier}
}
@article{holen2018occupationalb,
  title={Occupational safety in aquaculture--Part 2: Fatalities in Norway 1982--2015},
  author={Holen, Siri Mariane and Utne, Ingrid Bouwer and Holmen, Ingunn Marie and Aasjord, Halvard},
  journal={Marine Policy},
  volume={96},
  pages={193--199},
  year={2018},
  publisher={Elsevier}
}
@article{olafsen2012value,
  title={Value created from productive oceans in 2050},
  author={Olafsen, Trude and Winther, Ulf and Olsen, Yngvar and Skjermo, Jorunn},
  journal={SINTEF Fisheries and Aquaculture},
  pages={83},
  url={https://www.sintef.no/globalassets/upload/fiskeri\_og\_havbruk/publikasjoner/verdiskaping-basert-pa-produktive-hav-i-2050.pdf},
  year={2012}
}
@inproceedings{martin2017convolutional,
  title={A convolutional siamese network for developing similarity knowledge in the SelfBACK dataset},
  author={Martin, Kyle and Wiratunga, Nirmalie and Sani, Sadiq and Massie, Stewart and Clos, Jeremie},
  year={2017},
  booktitle={Proceedings of the 25th International Conference on Case-Based Reasoning Workshops (CBRDL 2017)},
  pages={85–94},
  Location={Trondheim},
  publisher={ICCBR (Organisers)},
  organization={CEUR Workshop Proceedings}
}
@article{martin2018explainability,
  title={Explainability through transparency and user control: a case-based recommender for engineering workers.},
  author={Martin, Kyle and Liret, Anne and Wiratunga, Nirmalie and Owusu, Gilbert and Kern, Mathias},
  year={2018}
}

@inproceedings{martin2019human,
  title={Human activity recognition with deep metric learners.},
  author={Martin, Kyle and Wijekoon, Anjana and Wiratunga, Nirmalie},
  year={2019},
  organization={CEUR Workshop Proceedings}
}
@inproceedings{abdel2014learning,
  title={Learning solution similarity in preference-based CBR},
  author={Abdel-Aziz, Amira and Strickert, Marc and H{\"u}llermeier, Eyke},
  booktitle={Proceedings of the 22nd International Conference on Case-Based Reasoning (ICCBR 2014)},
  pages={17--31},
  year={2014},
  organization={Springer}
}
@article{maggini2012learning,
  title={Learning from pairwise constraints by similarity neural networks},
  author={Maggini, Marco and Melacci, Stefano and Sarti, Lorenzo},
  journal={Neural Networks},
  volume={26},
  pages={141--158},
  year={2012},
  publisher={Elsevier}
}
@inproceedings{arandjelovic2017look,
  title={Look, listen and learn},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
  pages={609--617},
  year={2017},
  organization={IEEE}
}
@inproceedings{dieterle2014hybrid,
  title={A hybrid CBR-ANN approach to the appraisal of internet domain names},
  author={Dieterle, Sebastian and Bergmann, Ralph},
  booktitle={International Conference on Case-Based Reasoning},
  pages={95--109},
  year={2014},
  organization={Springer}
}
@inproceedings{nikpour2017diagnosing,
  title={Diagnosing root causes and generating graphical explanations by integrating temporal causal reasoning and CBR},
  author={Nikpour, Hoda and Aamodt, Agnar and Skalle, P{\aa}l},
  year={2017},
  organization={CEUR Workshop Proceedings}
}
@article{reategui1997combining,
  title={Combining a neural network with case-based reasoning in a diagnostic system},
  author={Reategui, Eliseo Berni and Campbell, John A. and Leao, Beatriz F.},
  journal={Artificial Intelligence in Medicine},
  volume={9},
  number={1},
  pages={5--27},
  year={1997},
  publisher={Elsevier}
}
@article{li2009predicting,
  title={Predicting business failure using multiple case-based reasoning combined with support vector machine},
  author={Li, Hui and Sun, Jie},
  journal={Expert Systems with Applications},
  volume={36},
  number={6},
  pages={10085--10096},
  year={2009},
  publisher={Elsevier}
}
@inproceedings{stahl2005learning,
  title={Learning similarity measures: A formal view based on a generalized CBR model},
  author={Stahl, Armin},
  booktitle={International Conference on Case-Based Reasoning},
  pages={507--521},
  year={2005},
  organization={Springer}
}
@inproceedings{stahl2002optimizing,
  title={Optimizing retrieval in CBR by introducing solution similarity},
  author={Stahl, Armin and Schmitt, Sascha},
  booktitle={Proceedings of the International Conference on Artificial Intelligence (IC-AI’02), Las Vegas, USA},
  year={2002}
}
@inproceedings{stahl2008rapid,
  title={Rapid prototyping of CBR applications with the open source tool myCBR},
  author={Stahl, Armin and Roth-Berghofer, Thomas R},
  booktitle={European conference on case-based reasoning},
  pages={615--629},
  year={2008},
  organization={Springer}
}
@article{DIAZAGUDO200768,
title = "Building CBR systems with jcolibri",
journal = "Science of Computer Programming",
volume = "69",
number = "1",
pages = "68 - 75",
year = "2007",
note = "Special issue on Experimental Software and Toolkits",
issn = "0167-6423",
author = "Bel{\'e}n D{\'i}az-Agudo and Pedro A. Gonz{\'a}lez-Calero and Juan A. Recio-Garc{\'i}a and Antonio A. S{\'a}nchez-Ruiz-Granados"
}
% CINELDI SOTA
@article{rafinia2014new,
  title={A new approach to fault location in three-phase underground distribution system using combination of wavelet analysis with ANN and FLS},
  author={Rafinia, Ali and Moshtagh, Jamal},
  journal={International Journal of Electrical Power \& Energy Systems},
  volume={55},
  pages={261--274},
  year={2014},
  publisher={Elsevier}
}
@article{thukaram2005artificial,
  title={Artificial neural network and support vector machine approach for locating faults in radial distribution systems},
  author={Thukaram, D and Khincha, HP and Vijaynarasimha, HP},
  journal={IEEE Transactions on Power Delivery},
  volume={20},
  number={2},
  pages={710--721},
  year={2005},
  publisher={IEEE}
}
@article{wei2015novel,
  title={A novel dual iterative $ Q $-learning method for optimal battery management in smart residential environments},
  author={Wei, Qinglai and Liu, Derong and Shi, Guang},
  journal={IEEE Transactions on Industrial Electronics},
  volume={62},
  number={4},
  pages={2509--2518},
  year={2015},
  publisher={IEEE}
}
@article{florescu2018resilient,
  title={Resilient backpropagation (Rprop) for batch-learning in TensorFlow},
  author={Florescu, Ciprian and Igel, Christian},
  journal={ICLR 2018 workshop permission},
  pages={To appear in},
  year={2018},
}
@inproceedings{riedmiller1993direct,
  title={A direct adaptive method for faster backpropagation learning: The RPROP algorithm},
  author={Riedmiller, Martin and Braun, Heinrich},
  booktitle={Neural Networks, 1993., IEEE International Conference on},
  pages={586--591},
  year={1993},
  organization={IEEE}
}
@inproceedings{aha1997case,
  title={Case-based learning: Beyond classification of feature vectors},
  author={Aha, David W and Wettschereck, Dietrich},
  booktitle={European Conference on Machine Learning},
  pages={327--336},
  year={1997},
  organization={Springer}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@misc{dua2017,
author = "Dheeru, Dua and Karra Taniskidou, Efi",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences"
}
@incollection{neal1998view,
  title={A view of the EM algorithm that justifies incremental, sparse, and other variants},
  author={Neal, Radford M and Hinton, Geoffrey E},
  booktitle={Learning in graphical models},
  pages={355--368},
  year={1998},
  publisher={Springer}
}
@article{jordan1999introduction,
  title={An introduction to variational methods for graphical models},
  author={Jordan, Michael I and Ghahramani, Zoubin and Jaakkola, Tommi S and Saul, Lawrence K},
  journal={Machine learning},
  volume={37},
  number={2},
  pages={183--233},
  year={1999},
  publisher={Springer}
}

% Siamese networks (distance/similarity metrics)
@inproceedings{koch2015siamese,
  title={Siamese neural networks for one-shot image recognition},
  author={Koch, Gregory and Zemel, Richard and Salakhutdinov, Ruslan},
  booktitle={ICML Deep Learning Workshop},
  volume={2},
  year={2015}
}
@inproceedings{bromley1994signature,
  title={Signature verification using a" siamese" time delay neural network},
  author={Bromley, Jane and Guyon, Isabelle and LeCun, Yann and S{\"a}ckinger, Eduard and Shah, Roopak},
  booktitle={Advances in neural information processing systems},
  pages={737--744},
  year={1994}
}
@inproceedings{hadsell2006dimensionality,
  title={Dimensionality reduction by learning an invariant mapping},
  author={Hadsell, Raia and Chopra, Sumit and LeCun, Yann},
  booktitle={2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)},
  pages={1735--1742},
  year={2006},
  organization={IEEE}
}
@inproceedings{schroff2015facenet,
  title={Facenet: A unified embedding for face recognition and clustering},
  author={Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={815--823},
  year={2015}
}
@article{lake2015human,
  title={Human-level concept learning through probabilistic program induction},
  author={Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B},
  journal={Science},
  volume={350},
  number={6266},
  pages={1332--1338},
  year={2015},
  publisher={American Association for the Advancement of Science}
}
@inproceedings{zagoruyko2015learning,
  title={Learning to compare image patches via convolutional neural networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4353--4361},
  year={2015}
}
@inproceedings{hoffer2015deep,
  title={Deep metric learning using triplet network},
  author={Hoffer, Elad and Ailon, Nir},
  booktitle={International Workshop on Similarity-Based Pattern Recognition},
  pages={84--92},
  year={2015},
  organization={Springer}
}
@inproceedings{chopra2005learning,
  title={Learning a similarity metric discriminatively, with application to face verification},
  author={Chopra, Sumit and Hadsell, Raia and LeCun, Yann},
  booktitle={Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on},
  volume={1},
  pages={539--546},
  year={2005},
  organization={IEEE}
}
@article{weinberger2009distance,
  title={Distance metric learning for large margin nearest neighbor classification},
  author={Weinberger, Kilian Q and Saul, Lawrence K},
  journal={Journal of Machine Learning Research},
  volume={10},
  number={Feb},
  pages={207--244},
  year={2009},
  note={Cites chopra for a good reason}
}
@inproceedings{lefebvre2013learning,
  title={Learning a bag of features based nonlinear metric for facial similarity},
  author={Lefebvre, Gr{\'e}goire and Garcia, Christophe},
  booktitle={Advanced Video and Signal Based Surveillance (AVSS), 2013 10th IEEE International Conference on},
  pages={238--243},
  year={2013},
  organization={IEEE}
}
@inproceedings{berlemont2015siamese,
  title={Siamese neural network based similarity metric for inertial gesture classification and rejection},
  author={Berlemont, Samuel and Lefebvre, Gr{\'e}goire and Duffner, Stefan and Garcia, Christophe},
  booktitle={Automatic Face and Gesture Recognition (FG), 2015 11th IEEE International Conference and Workshops on},
  volume={1},
  pages={1--6},
  year={2015},
  organization={IEEE}
}

% metric learning

@inproceedings{xing2003distance,
  title={Distance metric learning with application to clustering with side-information},
  author={Xing, Eric P and Jordan, Michael I and Russell, Stuart J and Ng, Andrew Y},
  booktitle={Advances in neural information processing systems},
  pages={521--528},
  year={2003}
}
@inproceedings{SkjoldOBA17,
  author    = {Kari Skjold and
               Marthe {\O}ynes and
               Kerstin Bach and
               Agnar Aamodt},
  title     = {IntelliMeal - Enhancing creativity by reusing domain knowledge in
               the adaptation process},
  booktitle = {{ICCBR} 2017 Workshops Proceedings, Trondheim, Norway,
               June 26-28, 2017.},
  pages     = {277--284},
  year      = {2017}
}

@phdthesis{Fielding2000,
 author = {Fielding, Roy Thomas},
 title = {Architectural styles and the design of network-based software architectures},
 year = {2000},
 isbn = {0-599-87118-0},
 note = {AAI9980887},
 school = {University of California, Irvine},
}

@inproceedings{davis2007information,
  title={Information-theoretic metric learning},
  author={Davis, Jason V and Kulis, Brian and Jain, Prateek and Sra, Suvrit and Dhillon, Inderjit S},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={209--216},
  year={2007},
  organization={ACM}
}
@inproceedings{becker2010learning,
  title={Learning similarity metrics for event identification in social media},
  author={Becker, Hila and Naaman, Mor and Gravano, Luis},
  booktitle={Proceedings of the third ACM international conference on Web search and data mining},
  pages={291--300},
  year={2010},
  organization={ACM}
}

@article{christopher1997locally,
  title={Locally weighted learning},
  author={Christopher, A and Andrew, M and Stefan, S},
  journal={Artif Intell Rev},
  volume={11},
  number={1-5},
  pages={11--73},
  year={1997}
}
@article{kolodner1983reconstructive,
  title={Reconstructive memory: A computer model},
  author={Kolodner, Janet L},
  journal={Cognitive science},
  volume={7},
  number={4},
  pages={281--328},
  year={1983},
  publisher={Elsevier}
}
@article{kolodner1992introduction,
  title={An introduction to case-based reasoning},
  author={Kolodner, Janet L},
  journal={Artificial intelligence review},
  volume={6},
  number={1},
  pages={3--34},
  year={1992},
  publisher={Springer}
}
@inproceedings{vinyals2016matching,
  title={Matching networks for one shot learning},
  author={Vinyals, Oriol and Blundell, Charles and Lillicrap, Tim and Wierstra, Daan and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3630--3638},
  year={2016}
}

@article{shawe1993symmetries,
  title={Symmetries and discriminability in feedforward network architectures},
  author={Shawe-Taylor, John},
  journal={IEEE Transactions on Neural Networks},
  volume={4},
  number={5},
  pages={816--826},
  year={1993},
  publisher={IEEE}
}

@inproceedings{domeniconi2002adaptive,
  title={Adaptive nearest neighbor classification using support vector machines},
  author={Domeniconi, Carlotta and Gunopulos, Dimitrios},
  booktitle={Advances in Neural Information Processing Systems},
  pages={665--672},
  year={2002}
}


@comment{BibDesk Static Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>group name</key>
		<string>data</string>
		<key>keys</key>
		<string>huang-a,mellone2012smartphone</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Deep Neural Networks</string>
		<key>keys</key>
		<string>raina2009large,q2012a,collobert2008unified,dean2012large,claudiu2010deep,martens2010deep,maddison2015iclr,deng2012a,Dahl:2012aa,Coates2012,hinton2012deep,deepface,glorot2010understanding,bengio2006neural,coates2011analysis,dean2008a,ngiam2011optimization</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>HyperNEAT</string>
		<key>keys</key>
		<string>stanleycppn,phdneat,rovingeye,stanley:utcstr01,gauci2010autonomous,gauci2007generating</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>NeuroEvolution</string>
		<key>keys</key>
		<string>sane,esp,kitano,Doucette:2010aa,montanadavis</string>
	</dict>
</array>
</plist>
}}

@Article{li-2019-random-searc,
  author        = {Li, Liam and Talwalkar, Ameet},
  journal       = {CoRR},
  title         = {Random Search and Reproducibility for Neural Architecture Search},
  year          = {2019},
  abstract      = {Neural architecture search (NAS) is a promising research
                  direction that has the potential to replace expert-designed
                  networks with learned, task-specific architectures. In this
                  work, in order to help ground the empirical results in this
                  field, we propose new NAS baselines that build off the
                  following observations: (i) NAS is a specialized
                  hyperparameter optimization problem; and (ii) random search is
                  a competitive baseline for hyperparameter optimization.
                  Leveraging these observations, we evaluate both random search
                  with early-stopping and a novel random search with
                  weight-sharing algorithm on two standard NAS benchmarks---PTB
                  and CIFAR-10. Our results show that random search with
                  early-stopping is a competitive NAS baseline, e.g., it
                  performs at least as well as ENAS, a leading NAS method, on
                  both benchmarks. Additionally, random search with
                  weight-sharing outperforms random search with early-stopping,
                  achieving a state-of-the-art NAS result on PTB and a highly
                  competitive result on CIFAR-10. Finally, we explore the
                  existing reproducibility issues of published NAS results. We
                  note the lack of source material needed to exactly reproduce
                  these results, and further discuss the robustness of published
                  results given the various sources of variability in NAS
                  experimental setups. Relatedly, we provide all information
                  (code, random seeds, documentation) needed to exactly
                  reproduce our results, and report our random search with
                  weight-sharing results for each benchmark on two independent
                  experimental runs.},
  archiveprefix = {arXiv},
  eprint        = {1902.07638v1},
  eprinttype    = {arxiv},
  primaryclass  = {cs.LG},
}

@Article{vaswani-2017-atten-is,
  author        = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  journal       = {CoRR},
  title         = {Attention Is All You Need},
  year          = {2017},
  abstract      = {The dominant sequence transduction models are based on complex
                  recurrent or convolutional neural networks in an
                  encoder-decoder configuration. The best performing models also
                  connect the encoder and decoder through an attention
                  mechanism. We propose a new simple network architecture, the
                  Transformer, based solely on attention mechanisms, dispensing
                  with recurrence and convolutions entirely. Experiments on two
                  machine translation tasks show these models to be superior in
                  quality while being more parallelizable and requiring
                  significantly less time to train. Our model achieves 28.4 BLEU
                  on the WMT 2014 English-to-German translation task, improving
                  over the existing best results, including ensembles by over 2
                  BLEU. On the WMT 2014 English-to-French translation task, our
                  model establishes a new single-model state-of-the-art BLEU
                  score of 41.8 after training for 3.5 days on eight GPUs, a
                  small fraction of the training costs of the best models from
                  the literature. We show that the Transformer generalizes well
                  to other tasks by applying it successfully to English
                  constituency parsing both with large and limited training
                  data.},
  archiveprefix = {arXiv},
  eprint        = {1706.03762v5},
  eprinttype    = {arxiv},
  primaryclass  = {cs.CL},
}

@Article{cirecsan2012multi,
  author        = {Cire{\c{s}}an, Dan and Meier, Ueli and Schmidhuber, Juergen},
  journal       = {CoRR},
  title         = {Multi-column Deep Neural Networks for Image Classification},
  year          = {2012},
  abstract      = {Traditional methods of computer vision and machine learning cannot match
human performance on tasks such as the recognition of handwritten digits or
traffic signs. Our biologically plausible deep artificial neural network
architectures can. Small (often minimal) receptive fields of convolutional
winner-take-all neurons yield large network depth, resulting in roughly as many
sparsely connected neural layers as found in mammals between retina and visual
cortex. Only winner neurons are trained. Several deep neural columns become
experts on inputs preprocessed in different ways; their predictions are
averaged. Graphics cards allow for fast training. On the very competitive MNIST
handwriting benchmark, our method is the first to achieve near-human
performance. On a traffic sign recognition benchmark it outperforms humans by a
factor of two. We also improve the state-of-the-art on a plethora of common
image classification benchmarks.},
  archiveprefix = {arXiv},
  eprint        = {1202.2745v1},
  eprinttype    = {arxiv},
  primaryclass  = {cs.CV},
}

@Article{caron-2018-deep-clust,
  author        = {Caron, Mathilde and Bojanowski, Piotr and Joulin, Armand and Douze, Matthijs},
  journal       = {CoRR},
  title         = {Deep Clustering for Unsupervised Learning of Visual Features},
  year          = {2018},
  abstract      = {Clustering is a class of unsupervised learning methods that
                  has been extensively applied and studied in computer vision.
                  Little work has been done to adapt it to the end-to-end
                  training of visual features on large scale datasets. In this
                  work, we present DeepCluster, a clustering method that jointly
                  learns the parameters of a neural network and the cluster
                  assignments of the resulting features. DeepCluster iteratively
                  groups the features with a standard clustering algorithm,
                  k-means, and uses the subsequent assignments as supervision to
                  update the weights of the network. We apply DeepCluster to the
                  unsupervised training of convolutional neural networks on
                  large datasets like ImageNet and YFCC100M. The resulting model
                  outperforms the current state of the art by a significant
                  margin on all the standard benchmarks.},
  archiveprefix = {arXiv},
  eprint        = {1807.05520v2},
  eprinttype    = {arxiv},
  primaryclass  = {cs.CV},
}

@Article{sedov-2018-word-embed,
  author        = {Sedov, Denis and Yang, Zhirong},
  journal       = {CoRR},
  title         = {Word Embedding Based on Low-Rank Doubly Stochastic Matrix Decomposition},
  year          = {2018},
  abstract      = {Word embedding, which encodes words into vectors, is an
                  important starting point in natural language processing and
                  commonly used in many text-based machine learning tasks.
                  However, in most current word embedding approaches, the
                  similarity in embedding space is not optimized in the
                  learning. In this paper we propose a novel neighbor embedding
                  method which directly learns an embedding simplex where the
                  similarities between the mapped words are optimal in terms of
                  minimal discrepancy to the input neighborhoods. Our method is
                  built upon two-step random walks between words via topics and
                  thus able to better reveal the topics among the words.
                  Experiment results indicate that our method, compared with
                  another existing word embedding approach, is more favorable
                  for various queries.},
  archiveprefix = {arXiv},
  eprint        = {1812.10401v1},
  eprinttype    = {arxiv},
  primaryclass  = {cs.CL},
}

@Article{yang-2012-clust-by,
  author        = {Yang, Zhirong and Oja, Erkki},
  journal       = {CoRR},
  title         = {Clustering By Low-Rank Doubly Stochastic Matrix Decomposition},
  year          = {2012},
  abstract      = {Clustering analysis by nonnegative low-rank approximations has
                  achieved remarkable progress in the past decade. However, most
                  approximation approaches in this direction are still
                  restricted to matrix factorization. We propose a new low-rank
                  learning method to improve the clustering performance, which
                  is beyond matrix factorization. The approximation is based on
                  a two-step bipartite random walk through virtual cluster
                  nodes, where the approximation is formed by only cluster
                  assigning probabilities. Minimizing the approximation error
                  measured by Kullback-Leibler divergence is equivalent to
                  maximizing the likelihood of a discriminative model, which
                  endows our method with a solid probabilistic interpretation.
                  The optimization is implemented by a relaxed
                  Majorization-Minimization algorithm that is advantageous in
                  finding good local minima. Furthermore, we point out that the
                  regularized algorithm with Dirichlet prior only serves as
                  initialization. Experimental results show that the new method
                  has strong performance in clustering purity for various
                  datasets, especially for large-scale manifold data.},
  archiveprefix = {arXiv},
  eprint        = {1206.4676v1},
  eprinttype    = {arxiv},
  primaryclass  = {cs.LG},
}

@Article{miech18_learn_text_video_embed_from,
  author        = {Miech, Antoine and Laptev, Ivan and Sivic, Josef},
  journal       = {CoRR},
  title         = {Learning a Text-Video Embedding From Incomplete and Heterogeneous Data},
  year          = {2018},
  abstract      = {Joint understanding of video and language is an active
                  research area with many applications. Prior work in this
                  domain typically relies on learning text-video embeddings. One
                  difficulty with this approach, however, is the lack of
                  large-scale annotated video-caption datasets for training. To
                  address this issue, we aim at learning text-video embeddings
                  from heterogeneous data sources. To this end, we propose a
                  Mixture-of-Embedding-Experts (MEE) model with ability to
                  handle missing input modalities during training. As a result,
                  our framework can learn improved text-video embeddings
                  simultaneously from image and video datasets. We also show the
                  generalization of MEE to other input modalities such as face
                  descriptors. We evaluate our method on the task of video
                  retrieval and report results for the MPII Movie Description
                  and MSR-VTT datasets. The proposed MEE model demonstrates
                  significant improvements and outperforms previously reported
                  methods on both text-to-video and video-to-text retrieval
                  tasks. Code is available at:
                  https://github.com/antoine77340/Mixture-of-Embedding-Experts},
  archiveprefix = {arXiv},
  eprint        = {1804.02516v1},
  eprinttype    = {arxiv},
  primaryclass  = {cs.CV},
}

@Article{fawaz-2018-deep-learn,
  author        = {Fawaz, H. Ismail and Forestier, G. and Weber, J. and Idoumghar, L. and Muller, P.},
  journal       = {CoRR},
  title         = {Deep Learning for Time Series Classification: a Review},
  year          = {2018},
  abstract      = {Time Series Classification (TSC) is an important and
                  challenging problem in data mining. With the increase of time
                  series data availability, hundreds of TSC algorithms have been
                  proposed. Among these methods, only a few have considered Deep
                  Neural Networks (DNNs) to perform this task. This is
                  surprising as deep learning has seen very successful
                  applications in the last years. DNNs have indeed
                  revolutionized the field of computer vision especially with
                  the advent of novel deeper architectures such as Residual and
                  Convolutional Neural Networks. Apart from images, sequential
                  data such as text and audio can also be processed with DNNs to
                  reach state-of-the-art performance for document classification
                  and speech recognition. In this article, we study the current
                  state-of-the-art performance of deep learning algorithms for
                  TSC by presenting an empirical study of the most recent DNN
                  architectures for TSC. We give an overview of the most
                  successful deep learning applications in various time series
                  domains under a unified taxonomy of DNNs for TSC. We also
                  provide an open source deep learning framework to the TSC
                  community where we implemented each of the compared approaches
                  and evaluated them on a univariate TSC benchmark (the UCR/UEA
                  archive) and 12 multivariate time series datasets. By training
                  8,730 deep learning models on 97 time series datasets, we
                  propose the most exhaustive study of DNNs for TSC to date.},
  archiveprefix = {arXiv},
  eprint        = {1809.04356v3},
  eprinttype    = {arxiv},
  primaryclass  = {cs.LG},
}

@Article{he-2015-deep-resid,
  author        = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  journal       = {CoRR},
  title         = {Deep Residual Learning for Image Recognition},
  year          = {2015},
  abstract      = {Deeper neural networks are more difficult to train. We present
                  a residual learning framework to ease the training of networks
                  that are substantially deeper than those used previously. We
                  explicitly reformulate the layers as learning residual
                  functions with reference to the layer inputs, instead of
                  learning unreferenced functions. We provide comprehensive
                  empirical evidence showing that these residual networks are
                  easier to optimize, and can gain accuracy from considerably
                  increased depth. On the ImageNet dataset we evaluate residual
                  nets with a depth of up to 152 layers---8x deeper than VGG
                  nets but still having lower complexity. An ensemble of these
                  residual nets achieves 3.57 \% error on the ImageNet test set.
                  This result won the 1st place on the ILSVRC 2015
                  classification task. We also present analysis on CIFAR-10 with
                  100 and 1000 layers. The depth of representations is of
                  central importance for many visual recognition tasks. Solely
                  due to our extremely deep representations, we obtain a 28 \%
                  relative improvement on the COCO object detection dataset.
                  Deep residual nets are foundations of our submissions to
                  ILSVRC \& COCO 2015 competitions, where we also won the 1st
                  places on the tasks of ImageNet detection, ImageNet
                  localization, COCO detection, and COCO segmentation.},
  archiveprefix = {arXiv},
  eprint        = {1512.03385v1},
  eprinttype    = {arxiv},
  primaryclass  = {cs.CV},
}
@techreport{acemoglu2019wrong,
  title={The Wrong Kind of AI? Artificial Intelligence and the Future of Labor Demand},
  author={Acemoglu, Daron and Restrepo, Pascual},
  year={2019},
  institution={National Bureau of Economic Research}
}

@Article{bagnall-2018-uea-multiv,
  author        = {Bagnall, Anthony and Dau, Hoang Anh and Lines, Jason and Flynn, Michael and Large, James and Bostrom, Aaron and Southam, Paul and Keogh, Eamonn},
  journal       = {CoRR},
  title         = {The Uea Multivariate Time Series Classification Archive, 2018},
  year          = {2018},
  abstract      = {In 2002, the UCR time series classification archive was first
                  released with sixteen datasets. It gradually expanded, until
                  2015 when it increased in size from 45 datasets to 85
                  datasets. In October 2018 more datasets were added, bringing
                  the total to 128. The new archive contains a wide range of
                  problems, including variable length series, but it still only
                  contains univariate time series classification problems. One
                  of the motivations for introducing the archive was to
                  encourage researchers to perform a more rigorous evaluation of
                  newly proposed time series classification (TSC) algorithms. It
                  has worked: most recent research into TSC uses all 85 datasets
                  to evaluate algorithmic advances. Research into multivariate
                  time series classification, where more than one series are
                  associated with each class label, is in a position where
                  univariate TSC research was a decade ago. Algorithms are
                  evaluated using very few datasets and claims of improvement
                  are not based on statistical comparisons. We aim to address
                  this problem by forming the first iteration of the MTSC
                  archive, to be hosted at the website
                  www.timeseriesclassification.com. Like the univariate archive,
                  this formulation was a collaborative effort between
                  researchers at the University of East Anglia (UEA) and the
                  University of California, Riverside (UCR). The 2018 vintage
                  consists of 30 datasets with a wide range of cases, dimensions
                  and series lengths. For this first iteration of the archive we
                  format all data to be of equal length, include no series with
                  missing data and provide train/test splits.},
  archiveprefix = {arXiv},
  eprint        = {1811.00075v1},
  eprinttype    = {arxiv},
  primaryclass  = {cs.LG},
}

@Article{byrd-2018-what-is,
  author        = {Byrd, Jonathon and Lipton, Zachary C.},
  journal       = {CoRR},
  title         = {What Is the Effect of Importance Weighting in Deep Learning?},
  year          = {2018},
  abstract      = {Importance-weighted risk minimization is a key ingredient in
                  many machine learning algorithms for causal inference, domain
                  adaptation, class imbalance, and off-policy reinforcement
                  learning. While the effect of importance weighting is
                  well-characterized for low-capacity misspecified models,
                  little is known about how it impacts over-parameterized, deep
                  neural networks. This work is inspired by recent theoretical
                  results showing that on (linearly) separable data, deep linear
                  networks optimized by SGD learn weight-agnostic solutions,
                  prompting us to ask, for realistic deep networks, for which
                  many practical datasets are separable, what is the effect of
                  importance weighting? We present the surprising finding that
                  while importance weighting impacts models early in training,
                  its effect diminishes over successive epochs. Moreover, while
                  L2 regularization and batch normalization (but not dropout),
                  restore some of the impact of importance weighting, they
                  express the effect via (seemingly) the wrong abstraction: why
                  should practitioners tweak the L2 regularization, and by how
                  much, to produce the correct weighting effect? Our experiments
                  confirm these findings across a range of architectures and
                  datasets.},
  archiveprefix = {arXiv},
  eprint        = {1812.03372v2},
  eprinttype    = {arxiv},
  primaryclass  = {cs.LG},
}

@Article{hu-2019-local-relat,
  author        = {Hu, Han and Zhang, Zheng and Xie, Zhenda and Lin, Stephen},
  journal       = {CoRR},
  title         = {Local Relation Networks for Image Recognition},
  year          = {2019},
  abstract      = {The convolution layer has been the dominant feature extractor
                  in computer vision for years. However, the spatial aggregation
                  in convolution is basically a pattern matching process that
                  applies fixed filters which are inefficient at modeling visual
                  elements with varying spatial distributions. This paper
                  presents a new image feature extractor, called the local
                  relation layer, that adaptively determines aggregation weights
                  based on the compositional relationship of local pixel pairs.
                  With this relational approach, it can composite visual
                  elements into higher-level entities in a more efficient manner
                  that benefits semantic inference. A network built with local
                  relation layers, called the Local Relation Network (LR-Net),
                  is found to provide greater modeling capacity than its
                  counterpart built with regular convolution on large-scale
                  recognition tasks such as ImageNet classification.},
  archiveprefix = {arXiv},
  eprint        = {1904.11491v1},
  eprinttype    = {arxiv},
  primaryclass  = {cs.CV},
}

@Article{hukkelaas-2019-deepp,
  author        = {Hukkel{\aa}s, H{\aa}kon and Mester, Rudolf and Lindseth, Frank},
  journal       = {CoRR},
  title         = {DeepPrivacy: A Generative Adversarial Network for Face Anonymization},
  year          = {2019},
  abstract      = {We propose a novel architecture which is able to automatically anonymize
faces in images while retaining the original data distribution. We ensure total
anonymization of all faces in an image by generating images exclusively on
privacy-safe information. Our model is based on a conditional generative
adversarial network, generating images considering the original pose and image
background. The conditional information enables us to generate highly realistic
faces with a seamless transition between the generated face and the existing
background. Furthermore, we introduce a diverse dataset of human faces,
including unconventional poses, occluded faces, and a vast variability in
backgrounds. Finally, we present experimental results reflecting the capability
of our model to anonymize images while preserving the data distribution, making
the data suitable for further training of deep learning models. As far as we
know, no other solution has been proposed that guarantees the anonymization of
faces while generating realistic images.},
  archiveprefix = {arXiv},
  eprint        = {1909.04538v1},
  eprinttype    = {arxiv},
  primaryclass  = {cs.CV},
}

@Article{lake-2019-omnig-chall,
  author        = {Lake, Brenden M. and Salakhutdinov, Ruslan and Tenenbaum, Joshua B.},
  journal       = {CoRR},
  title         = {The Omniglot Challenge: a 3-year Progress Report},
  year          = {2019},
  abstract      = {Three years ago, we released the Omniglot dataset for one-shot
                  learning, along with five challenge tasks and a computational
                  model that addresses these tasks. The model was not meant to
                  be the final word on Omniglot; we hoped that the community
                  would build on our work and develop new approaches. In the
                  time since, we have been pleased to see wide adoption of the
                  dataset. There has been notable progress on one-shot
                  classification, but researchers have adopted new splits and
                  procedures that make the task easier. There has been less
                  progress on the other four tasks. We conclude that recent
                  approaches are still far from human-like concept learning on
                  Omniglot, a challenge that requires performing many tasks with
                  a single model.},
  archiveprefix = {arXiv},
  eprint        = {1902.03477v2},
  eprinttype    = {arxiv},
  primaryclass  = {cs.AI},
}

@article{hung2019optimizing,
  title={Optimizing agent behavior over long time scales by transporting value},
  author={Hung, Chia-Chun and Lillicrap, Timothy and Abramson, Josh and Wu, Yan and Mirza, Mehdi and Carnevale, Federico and Ahuja, Arun and Wayne, Greg},
  journal={Nature communications},
  volume={10},
  number={1},
  pages={1--12},
  year={2019},
  publisher={Nature Publishing Group}
}

@Article{soomro-2012-ucf10,
  author        = {Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal       = {CoRR},
  title         = {Ucf101: a Dataset of 101 Human Actions Classes From Videos in the Wild},
  year          = {2012},
  abstract      = {We introduce UCF101 which is currently the largest dataset of
                  human actions. It consists of 101 action classes, over 13k
                  clips and 27 hours of video data. The database consists of
                  realistic user uploaded videos containing camera motion and
                  cluttered background. Additionally, we provide baseline action
                  recognition results on this new dataset using standard bag of
                  words approach with overall performance of 44.5 \%. To the
                  best of our knowledge, UCF101 is currently the most
                  challenging dataset of actions due to its large number of
                  classes, large number of clips and also unconstrained nature
                  of such clips.},
  archiveprefix = {arXiv},
  eprint        = {1212.0402v1},
  eprinttype    = {arxiv},
  primaryclass  = {cs.CV},
}

@Article{zhu-2014-recov-canon,
  author        = {Zhu, Zhenyao and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  journal       = {CoRR},
  title         = {Recover Canonical-View Faces in the Wild With Deep Neural Networks},
  year          = {2014},
  abstract      = {Face images in the wild undergo large intra-personal
                  variations, such as poses, illuminations, occlusions, and low
                  resolutions, which cause great challenges to face-related
                  applications. This paper addresses this challenge by proposing
                  a new deep learning framework that can recover the canonical
                  view of face images. It dramatically reduces the intra-person
                  variances, while maintaining the inter-person
                  discriminativeness. Unlike the existing face reconstruction
                  methods that were either evaluated in controlled 2D
                  environment or employed 3D information, our approach directly
                  learns the transformation from the face images with a complex
                  set of variations to their canonical views. At the training
                  stage, to avoid the costly process of labeling canonical-view
                  images from the training set by hand, we have devised a new
                  measurement to automatically select or synthesize a
                  canonical-view image for each identity. As an application,
                  this face recovery approach is used for face verification.
                  Facial features are learned from the recovered canonical-view
                  face images by using a facial component-based convolutional
                  neural network. Our approach achieves the state-of-the-art
                  performance on the LFW dataset.},
  archiveprefix = {arXiv},
  eprint        = {1404.3543v2},
  eprinttype    = {arxiv},
  primaryclass  = {cs.CV},
}

@Article{yu-2019-meta-world,
  author        = {Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  journal       = {CoRR},
  title         = {Meta-World: a Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning},
  year          = {2019},
  abstract      = {Meta-reinforcement learning algorithms can enable robots to
                  acquire new skills much more quickly, by leveraging prior
                  experience to learn how to learn. However, much of the current
                  research on meta-reinforcement learning focuses on task
                  distributions that are very narrow. For example, a commonly
                  used meta-reinforcement learning benchmark uses different
                  running velocities for a simulated robot as different tasks.
                  When policies are meta-trained on such narrow task
                  distributions, they cannot possibly generalize to more quickly
                  acquire entirely new tasks. Therefore, if the aim of these
                  methods is to enable faster acquisition of entirely new
                  behaviors, we must evaluate them on task distributions that
                  are sufficiently broad to enable generalization to new
                  behaviors. In this paper, we propose an open-source simulated
                  benchmark for meta-reinforcement learning and multi-task
                  learning consisting of 50 distinct robotic manipulation tasks.
                  Our aim is to make it possible to develop algorithms that
                  generalize to accelerate the acquisition of entirely new,
                  held-out tasks. We evaluate 6 state-of-the-art
                  meta-reinforcement learning and multi-task learning algorithms
                  on these tasks. Surprisingly, while each task and its
                  variations (e.g., with different object positions) can be
                  learned with reasonable success, these algorithms struggle to
                  learn with multiple tasks at the same time, even with as few
                  as ten distinct training tasks. Our analysis and open-source
                  environments pave the way for future research in multi-task
                  learning and meta-learning that can enable meaningful
                  generalization, thereby unlocking the full potential of these
                  methods.},
  archiveprefix = {arXiv},
  eprint        = {1910.10897v1},
  eprinttype    = {arxiv},
  primaryclass  = {cs.LG},
}

@Article{kuśmierczyk-2019-variat-bayes,
  author        = {Kuśmierczyk, Tomasz and Sakaya, Joseph and Klami, Arto},
  journal       = {CoRR},
  title         = {Variational Bayesian Decision-Making for Continuous Utilities},
  year          = {2019},
  abstract      = {Bayesian decision theory outlines a rigorous framework for
                  making optimal decisions based on maximizing expected utility
                  over a model posterior. However, practitioners often do not
                  have access to the full posterior and resort to approximate
                  inference strategies. In such cases, taking the eventual
                  decision-making task into account while performing the
                  inference allows for calibrating the posterior approximation
                  to maximize the utility. We present an automatic pipeline that
                  co-opts continuous utilities into variational inference
                  algorithms to account for decision-making. We provide
                  practical strategies for approximating and maximizing the
                  gain, and empirically demonstrate consistent improvement when
                  calibrating approximations for specific utilities.},
  archiveprefix = {arXiv},
  eprint        = {1902.00792v3},
  eprinttype    = {arxiv},
  primaryclass  = {stat.ML},
}

@Article{requeima-2019-fast-flexib,
  author        = {Requeima, James and Gordon, Jonathan and Bronskill, John and Nowozin, Sebastian and Turner, Richard E.},
  journal       = {CoRR},
  title         = {Fast and Flexible Multi-Task Classification Using Conditional Neural Adaptive Processes},
  year          = {2019},
  abstract      = {The goal of this paper is to design image classification
                  systems that, after an initial multi-task training phase, can
                  automatically adapt to new tasks encountered at test time. We
                  introduce a conditional neural process based approach to the
                  multi-task classification setting for this purpose, and
                  establish connections to the meta-learning and few-shot
                  learning literature. The resulting approach, called CNAPs,
                  comprises a classifier whose parameters are modulated by an
                  adaptation network that takes the current task's dataset as
                  input. We demonstrate that CNAPs achieves state-of-the-art
                  results on the challenging Meta-Dataset benchmark indicating
                  high-quality transfer-learning. We show that the approach is
                  robust, avoiding both over-fitting in low-shot regimes and
                  under-fitting in high-shot regimes. Timing experiments reveal
                  that CNAPs is computationally efficient at test-time as it
                  does not involve gradient based adaptation. Finally, we show
                  that trained models are immediately deployable to continual
                  learning and active learning where they can outperform
                  existing approaches that do not leverage transfer learning.},
  archiveprefix = {arXiv},
  eprint        = {1906.07697v1},
  eprinttype    = {arxiv},
  primaryclass  = {stat.ML},
}

@inproceedings{nguyen2010cosine,
  title={Cosine similarity metric learning for face verification},
  author={Nguyen, Hieu V and Bai, Li},
  booktitle={Asian conference on computer vision},
  pages={709--720},
  year={2010},
  organization={Springer}
}

@inproceedings{eigenfaces,
  title={Face recognition using eigenfaces},
  author={Turk, Matthew A and Pentland, Alex P},
  booktitle={Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  pages={586--591},
  year={1991},
  organization={IEEE}
}

@Article{frankle-2018-lotter-ticket-hypot,
  author        = {Frankle, Jonathan and Carbin, Michael},
  journal       = {CoRR},
  title         = {The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
  year          = {2018},
  abstract      = {Neural network pruning techniques can reduce the parameter
                  counts of trained networks by over 90 \%, decreasing storage
                  requirements and improving computational performance of
                  inference without compromising accuracy. However, contemporary
                  experience is that the sparse architectures produced by
                  pruning are difficult to train from the start, which would
                  similarly improve training performance. We find that a
                  standard pruning technique naturally uncovers subnetworks
                  whose initializations made them capable of training
                  effectively. Based on these results, we articulate the
                  "lottery ticket hypothesis:" dense, randomly-initialized,
                  feed-forward networks contain subnetworks ("winning tickets")
                  that - when trained in isolation - reach test accuracy
                  comparable to the original network in a similar number of
                  iterations. The winning tickets we find have won the
                  initialization lottery: their connections have initial weights
                  that make training particularly effective. We present an
                  algorithm to identify winning tickets and a series of
                  experiments that support the lottery ticket hypothesis and the
                  importance of these fortuitous initializations. We
                  consistently find winning tickets that are less than 10-20 \%
                  of the size of several fully-connected and convolutional
                  feed-forward architectures for MNIST and CIFAR10. Above this
                  size, the winning tickets that we find learn faster than the
                  original network and reach higher test accuracy.},
  archiveprefix = {arXiv},
  eprint        = {1803.03635v5},
  eprinttype    = {arxiv},
  primaryclass  = {cs.LG},
}

@Article{szegedy-2013-intrig-proper,
  author        = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal       = {CoRR},
  title         = {Intriguing Properties of Neural Networks},
  year          = {2013},
  abstract      = {Deep neural networks are highly expressive models that have
                  recently achieved state of the art performance on speech and
                  visual recognition tasks. While their expressiveness is the
                  reason they succeed, it also causes them to learn
                  uninterpretable solutions that could have counter-intuitive
                  properties. In this paper we report two such properties.
                  First, we find that there is no distinction between individual
                  high level units and random linear combinations of high level
                  units, according to various methods of unit analysis. It
                  suggests that it is the space, rather than the individual
                  units, that contains of the semantic information in the high
                  layers of neural networks. Second, we find that deep neural
                  networks learn input-output mappings that are fairly
                  discontinuous to a significant extend. We can cause the
                  network to misclassify an image by applying a certain
                  imperceptible perturbation, which is found by maximizing the
                  network's prediction error. In addition, the specific nature
                  of these perturbations is not a random artifact of learning:
                  the same perturbation can cause a different network, that was
                  trained on a different subset of the dataset, to misclassify
                  the same input.},
  archiveprefix = {arXiv},
  eprint        = {1312.6199v4},
  eprinttype    = {arxiv},
  primaryclass  = {cs.CV},
}
@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  number={2},
  year={2016},
  publisher={MIT press Cambridge}
}
@inproceedings{goodfellow2009measuring,
  title={Measuring invariances in deep networks},
  author={Goodfellow, Ian and Lee, Honglak and Le, Quoc V and Saxe, Andrew and Ng, Andrew Y},
  booktitle={Advances in neural information processing systems},
  pages={646--654},
  year={2009}
}

@article{fallon2016classification,
  title={Classification of Southern Ocean krill and icefish echoes using random forests},
  author={Fallon, Niall G and Fielding, Sophie and Fernandes, Paul G},
  journal={ICES Journal of Marine Science},
  volume={73},
  number={8},
  pages={1998--2008},
  year={2016},
  publisher={Oxford University Press}
}
@article{charef2010classification,
  title={Classification of fish schools based on evaluation of acoustic descriptor characteristics},
  author={Charef, Aymen and Ohshimo, Seiji and Aoki, Ichiro and Al Absi, Natheer},
  journal={Fisheries Science},
  volume={76},
  number={1},
  pages={1--11},
  year={2010},
  publisher={Springer}
}
@inproceedings{hirama2017discriminating,
  title={Discriminating fish species by an Echo sounder in a set-net using a CNN},
  author={Hirama, Yudai and Yokoyama, Soichiro and Yamashita, Tomohisa and Kawamura, Hidenori and Suzuki, Keiji and Wada, Masaaki},
  booktitle={2017 21st Asia Pacific Symposium on Intelligent and Evolutionary Systems (IES)},
  pages={112--115},
  year={2017},
  organization={IEEE}
}

@inproceedings{valmadre2017end,
  title={End-to-end representation learning for correlation filter based tracking},
  author={Valmadre, Jack and Bertinetto, Luca and Henriques, Joao and Vedaldi, Andrea and Torr, Philip HS},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2805--2813},
  year={2017}
}
@INPROCEEDINGS{li2018tracking,
  author={B. {Li} and J. {Yan} and W. {Wu} and Z. {Zhu} and X. {Hu}},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  title={High Performance Visual Tracking with Siamese Region Proposal Network},
  year={2018},
  volume={},
  number={},
  pages={8971-8980},
  doi={10.1109/CVPR.2018.00935}}

@Article{GAO2020105448,
  author   = {Peng Gao and Ruyue Yuan and Fei Wang and Liyi Xiao and Hamido Fujita and Yan Zhang},
  journal  = {Knowledge-Based Systems},
  title    = {Siamese attentional keypoint network for high performance visual tracking},
  year     = {2020},
  issn     = {0950-7051},
  pages    = {105448},
  volume   = {193},
  abstract = {Visual tracking is one of the most fundamental topics in computer vision. Numerous tracking approaches based on discriminative correlation filters or Siamese convolutional networks have attained remarkable performance over the past decade. However, it is still commonly recognized as an open research problem to develop robust and effective trackers which can achieve satisfying performance with high computational and memory storage efficiency in real-world scenarios. In this paper, we investigate the impacts of three main aspects of visual tracking, i.e., the backbone network, the attentional mechanism, and the detection component, and propose a Siamese Attentional Keypoint Network, dubbed SATIN, for efficient tracking and accurate localization. Firstly, a new Siamese lightweight hourglass network is specially designed for visual tracking. It takes advantage of the benefits of the repeated bottom-up and top-down inference to capture more global and local contextual information at multiple scales. Secondly, a novel cross-attentional module is utilized to leverage both channel-wise and spatial intermediate attentional information, which can enhance both discriminative and localization capabilities of feature maps. Thirdly, a keypoints detection approach is invented to trace any target object by detecting the top-left corner point, the centroid point, and the bottom-right corner point of its bounding box. Therefore, our SATIN tracker not only has a strong capability to learn more effective object representations, but also is computational and memory storage efficiency, either during the training or testing stages. To the best of our knowledge, we are the first to propose this approach. Without bells and whistles, experimental results demonstrate that our approach achieves state-of-the-art performance on several recent benchmark datasets, at a speed far exceeding 27 frames per second.},
  doi      = {10.1016/j.knosys.2019.105448},
  keywords = {Visual tracking, Siamese hourglass networks, Cross-attentional module, Keypoint detection},
  url      = {http://www.sciencedirect.com/science/article/pii/S0950705119306665},
}

@Article{GAO202052,
  author   = {Peng Gao and Qiquan Zhang and Fei Wang and Liyi Xiao and Hamido Fujita and Yan Zhang},
  journal  = {Information Sciences},
  title    = {Learning reinforced attentional representation for end-to-end visual tracking},
  year     = {2020},
  issn     = {0020-0255},
  pages    = {52 - 67},
  volume   = {517},
  abstract = {Although numerous recent tracking approaches have made tremendous advances in the last decade, achieving high-performance visual tracking remains a challenge. In this paper, we propose an end-to-end network model to learn reinforced attentional representation for accurate target object discrimination and localization. We utilize a novel hierarchical attentional module with long short-term memory and multi-layer perceptrons to leverage both inter- and intra-frame attention to effectively facilitate visual pattern emphasis. Moreover, we incorporate a contextual attentional correlation filter into the backbone network to make our model trainable in an end-to-end fashion. Our proposed approach not only takes full advantage of informative geometries and semantics but also updates correlation filters online without fine-tuning the backbone network to enable the adaptation of variations in the target object’s appearance. Extensive experiments conducted on several popular benchmark datasets demonstrate that our proposed approach is effective and computationally efficient.},
  doi      = {10.1016/j.ins.2019.12.084},
  keywords = {Visual tracking, Reinforced representation, Attentive learning, Correlation filter},
  url      = {http://www.sciencedirect.com/science/article/pii/S0020025519312095},
}
@article{nasjonalsjomat,
  title={Nasjonal betydning av sjømatnæringen},
  author={Richardsen, Roger and Stoud Myhre, Magnus and Bull-Berg, Heidi and T. Grindvoll, Inger Lise},
  journal={Publikasjoner fra CRIStin - SINTEF Ocean},
  year={2018}
}
@article{Assesing_swim,
author = {Hvas, Malthe and Folkedal, Ole and Solstorm, David and V{\aa}gseth, Tone and Fosse, Jan and Gansel, Lars and Oppedal, Frode},
year = {2017},
month = {03},
pages = {},
title = {Assessing swimming capacity and schooling behaviour in farmed Atlantic salmon Salmo salar with experimental push-cages},
volume = {473},
journal = {Aquaculture},
doi = {10.1016/j.aquaculture.2017.03.013}
}

@Article{CUBITT2008529,
  author   = {K. Fiona Cubitt and Svante Winberg and Felicity A. Huntingford and Sunil Kadri and Vivian O. Crampton and {\O}yvind {\O}verli},
  journal  = {Physiology \& Behavior},
  title    = {Social hierarchies, growth and brain serotonin metabolism in Atlantic salmon (Salmo salar) kept under commercial rearing conditions},
  year     = {2008},
  issn     = {0031-9384},
  number   = {4},
  pages    = {529 - 535},
  volume   = {94},
  abstract = {Monitoring social interactions between individuals in large, high-density groups poses several challenges. Here we demonstrate that relative concentrations of serotonin (5-Hydroxytryptamine, 5-HT) and its principal catabolite 5-Hydroxyindoleacetic acid (5-HIAA) in brain tissue of individual fish reflect social organisation in large groups of farmed Atlantic salmon. In the central nervous system of vertebrates, the monoamine neurotransmitter/neuromodulator 5-HT is critical for maintaining adaptive physiological, cognitive and emotional processes. In both teleost fish and mammals it has previously been shown that social interactions in small groups lead to elevated 5-HT release and/or metabolism in subordinate individuals, as indicated by the 5-HIAA/5-HT concentration ratio. In the current study, evidence is presented of non-linear dominance hierarchies in farmed Atlantic salmon (Salmo salar) kept at high rearing densities. The physiological effect of these hierarchies was decreased when food resources were abundant, although some subordinate fish still showed altered brain serotonergic activity and failed to grow even feed was available in excess. The largest effect of decreased feed rations was seen in fish of intermediate size, where competition appeared to increase with reduced access to feed. The largest individuals in each rearing unit showed low 5-HIAA/5-HT ratios independent of feeding regime. A novel observation, with respect to previous studies, was that elevated brain 5-HIAA/5-HT ratios resulted from decreased 5-HT concentrations rather than elevated 5-HIAA in small fish. Thus, in light of the serotonin deficit hypothesis of depression, it cannot be excluded that social stress is important for animal welfare even in large, relatively homogenous groups of animals reared in captivity.},
  doi      = {10.1016/j.physbeh.2008.03.009},
  keywords = {Brain, Dominance, Growth, Hierarchy, 5-HT, Stress, Salmon, , Social groups},
  url      = {http://www.sciencedirect.com/science/article/pii/S0031938408000826},
}
@article{merz,
    title={Onset of melanophore patterns in the head region of Chinook salmon: A natural marker for the reidentification of individual fish},
    volume={32},
    DOI={10.1080/02755947.2012.681014},
    number={4},
    journal={North American Journal of Fisheries Management},
    author={Merz, Joseph E. and Skvorc, Paul and Sogard, Susan M. and Watry, Clark and Blankenship, Scott M. and Nieuwenhuyse, Erwin E. Van},
    year={2012},
    pages={806–816}}

@article{Hansen2012,
doi = {10.1111/j.1750-3841.2011.02513.x},
issn = {1750-3841 (Electronic)},
  title={The effect of crowding stress on bacterial growth and sensory properties of chilled Atlantic salmon fillets},
  author={{\AA}dland Hansen, Anlaug and R{\o}dbotten, Marit and Eie, Thomas and Lea, Per and Rudi, Knut and M{\o}rk{\o}re, Turid},
  journal={Journal of food science},
  volume={77},
  number={1},
  pages={S84--S90},
  year={2012},
  publisher={Wiley Online Library}
}

@inproceedings{taigman2014deepface,
  title={Deepface: Closing the gap to human-level performance in face verification},
  author={Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1701--1708},
  year={2014}
}
@article{sintefsalmid,
  title={Identifikasjon av lakseindivider — Biometri fase 1 (SalmID)},
  author={Eilertsen, Aleksander B{\o}rresen},
  journal={Publikasjoner fra CRIStin - SINTEF Ocean},
  year={2017}
}

@MastersThesis{ivarhammerset,
  author    = {Hammerset, Ivar},
  school    = {Norwegian University of Science and Technology},
  title     = {Biometric recognition and individual tracking of salmon in large-scale sea cages.},
  year      = {2018},
  address   = {Norway},
  booktitle = {Master thesis at the Norwegian University of Science and Technology},
  language  = {eng},
  publisher = {Norwegian University of Science and Technology},
  url       = {http://hdl.handle.net/11250/2616147},
}
@article{belhumeur1997eigenfaces,
  title={Eigenfaces vs. fisherfaces: Recognition using class specific linear projection},
  author={Belhumeur, Peter N. and Hespanha, Jo{\~a}o P and Kriegman, David J.},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={19},
  number={7},
  pages={711--720},
  year={1997},
  publisher={IEEE}
}
@article{he2005face,
  title={Face recognition using laplacianfaces},
  author={He, Xiaofei and Yan, Shuicheng and Hu, Yuxiao and Niyogi, Partha and Zhang, Hong-Jiang},
  journal={IEEE Transactions on Pattern Analysis \& Machine Intelligence},
  number={3},
  pages={328--340},
  year={2005},
  publisher={IEEE}
}
@inproceedings{imagenet_cvpr09,
        author = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
        title = {{ImageNet: A large-scale hierarchical image database}},
        booktitle = {CVPR09},
        year = {2009}
}
@article{yolov3,
  title={Yolov3: An incremental improvement},
  author={Redmon, Joseph and Farhadi, Ali},
  journal={arXiv preprint arXiv:1804.02767},
  year={2018}
}

@InProceedings{dbscan,
  author={Xu, Xiaowei and Ester, Martin and Kriegel, H-P and Sander, J{\"o}rg},
  booktitle = {Proceedings 14th International Conference on Data Engineering},
  title     = {A distribution-based clustering algorithm for mining in large spatial databases},
  year      = {1998},
  month     = {2},
  pages     = {324-331},
  doi       = {10.1109/ICDE.1998.655795},
  issn      = {1063-6382},
  keywords  = {visual databases;distribution-based clustering algorithm;data mining;large spatial databases;point cluster detection;spatial point process;DBCLASD;partitioning algorithms;CLARANS;randomized search;arbitrary shaped clusters;DBSCAN;density-based spatial clustering;noise;input parameters;efficiency;nonparametric nature;quality;Clustering algorithms;Spatial databases;Partitioning algorithms;Iterative algorithms;Noise shaping;Shape;Nearest neighbor searches;Gravity;Electrical capacitance tomography;Clustering methods},
}
@ARTICLE{adversarial_regularization,
author={S. {Sun} and P. {Guo} and L. {Xie} and M. {Hwang}},
journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
title={Adversarial regularization for attention based end-to-end robust speech recognition},
year={2019},
volume={27},
number={11},
pages={1826-1838},
keywords={error statistics;gradient methods;interference suppression;learning (artificial intelligence);linguistics;natural language processing;speech recognition;statistical distributions;adversarial regularization;end-to-end robust speech recognition;acoustic-linguistic information integration model;real application environments;fast gradient-sign method;local distributional smoothness method;noise robustness;Chinese Mandarin corpora;AISHELL- 1;AISHELL-2;relative character error rate;sequence-to-sequence speech recognition;attention based recognition;Hidden Markov models;Speech recognition;Training;Acoustics;Perturbation methods;Robustness;Task analysis;Sequence-to-sequence;attention;adversarial training;virtual adversarial training;Listen Attend and Spell;cross entropy},
doi={10.1109/TASLP.2019.2933146},
ISSN={2329-9304},
month={11},}
@inproceedings{bertinetto2016fully,
  title={Fully-convolutional siamese networks for object tracking},
  author={Bertinetto, Luca and Valmadre, Jack and Henriques, Joao F and Vedaldi, Andrea and Torr, Philip HS},
  booktitle={European conference on computer vision},
  pages={850--865},
  year={2016},
  organization={Springer}
}
@misc{2018Akvakultur,
    author = {SSB},
    title = {Akvakultur - {\aa}rlig, endelige tall - SSB, retrived from https://www.ssb.no/fiskeoppdrett 23.05.2019},
    year = 2018,
    url = {https://www.ssb.no/fiskeoppdrett},
    urldate = {2019-05-23}
}

@Article{goyal-2020-induc-biases,
  author        = {Goyal, Anirudh and Bengio, Yoshua},
  journal       = {CoRR},
  title         = {Inductive Biases for Deep Learning of Higher-Level Cognition},
  year          = {2020},
  abstract      = {A fascinating hypothesis is that human and animal intelligence
                  could be explained by a few principles (rather than an
                  encyclopedic list of heuristics). If that hypothesis was
                  correct, we could more easily both understand our own
                  intelligence and build intelligent machines. Just like in
                  physics, the principles themselves would not be sufficient to
                  predict the behavior of complex systems like brains, and
                  substantial computation might be needed to simulate human-like
                  intelligence. This hypothesis would suggest that studying the
                  kind of inductive biases that humans and animals exploit could
                  help both clarify these principles and provide inspiration for
                  AI research and neuroscience theories. Deep learning already
                  exploits several key inductive biases, and this work considers
                  a larger list, focusing on those which concern mostly
                  higher-level and sequential conscious processing. The
                  objective of clarifying these particular principles is that
                  they could potentially help us build AI systems benefiting
                  from humans' abilities in terms of flexible
                  out-of-distribution and systematic generalization, which is
                  currently an area where a large gap exists between
                  state-of-the-art machine learning and human intelligence.},
  archiveprefix = {arXiv},
  eprint        = {2011.15091v1},
  eprinttype    = {arxiv},
  primaryclass  = {cs.LG},
}

@Article{Vergara-Solana2019,
  author    = {Vergara-Solana, Francisco and Araneda, Marcelo E. and Ponce-Diaz, German},
  journal   = {{REVIEWS IN AQUACULTURE}},
  title     = {{Opportunities for strengthening aquaculture industry through multicriteria decision-making}},
  year      = {2019},
  issn      = {{1753-5123}},
  month     = {2},
  number    = {{1}},
  pages     = {{105-118}},
  volume    = {{11}},
  abstract  = {{In operations research, there are methodological tools included in
   decision theory that can help decision-makers understand and systematize
   the decision-making process. Decisions can be classified either as
   mono-criterial, when only one criterion or goal is considered to
   evaluate its performance or multicriterial, which takes into account the
   interaction between two or more goals or criteria that can be in
   conflict. Natural resource management and finance are some important
   examples where the implementation of this type of tools has benefited
   the decision-making process because they allow a number of criteria or
   objectives to be weighted in a transparent manner to assist when one or
   more decision-makers are involved. Despite this, its application was not
   common in aquaculture; however, in recent years, efforts have increased
   exponentially. This work seeks to identify opportunity areas for
   development of new aquaculture-related research through the
   implementation of multicriterial decision-making methods (MCDM). To
   achieve this, a comprehensive bibliometric analysis was performed to
   detect MCDM applications that have been implemented in aquaculture
   industry (24 documents that were grouped into eight applications).
   Later, this information was complemented through the analysis of
   selected applications in natural resources management, specifically in
   fisheries, animal husbandry and agriculture. We propose 23 research
   topics relevant to the aquaculture industry that can be addressed by the
   methodologies in MCDM.}},
  doi       = {{10.1111/raq.12228}},
  eissn     = {{1753-5131}},
  groups    = {[epic:]},
  unique-id = {{ISI:000458688100006}},
}

@Article{Leung2006,
  author    = {Leung, P.S.},
  title     = {Multiple-criteria decision-making (MCDM) applications in fishery management},
  journal   = {International Journal of Environmental Technology and Management},
  year      = 2006,
  volume    = 6,
  number    = {1-2},
  pages     = {96 - 110},
  issn      = {1466-2132},
  note      = {multiple-criteria decision-making;fishery management;analytic hierarchy process;decision support system;},
  abstract  = {This paper provides an up-to-date review of multiple-criteria decision-making (MCDM) applications in fishery management since the last review conducted by Mardle and Pascoe in 1999. The review primarily draws on the published literature in the English language. This review also includes the author's experience in developing MCDM models to assist policy decision making in fishery management both in Hawaii and Norway. Two multi-objective programming models and two applications of the analytic hierarchy process (AHP) - separately developed for Hawaii and Norway - are highlighted.},
  address   = {Switzerland},
  copyright = {Copyright 2006, IEE},
  doi       = {10.1504/IJETM.2006.008255},
  keywords  = {aquaculture;decision making;decision support systems;fishing industry;},
  language  = {English},
}
@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Markings\;2\;1\;\;\;\;;
2 StaticGroup:[epic:]\;2\;1\;\;\;\;;
}

@InProceedings{Yuan2010,
  author    = {H. {Yuan} and Z. {Mao} and B. {Zhao}},
  title     = {Research of vannamei expert system based on CBR and Grey AHP},
  booktitle = {2010 International Conference on Intelligent Computation Technology and Automation},
  year      = {2010},
  volume    = {2},
  pages     = {1065-1068},
  month     = {5},
  abstract  = {Although the CBR(Case-based reasoning) model has been successfully adopted in various fields and well demonstrated in practice, its performance could still be further improved. This paper proposes a new method that combines CBR with Grey AHP to design the inference engine, which has been implemented in vannamei expert system. The method makes use of the groups method to calculate the synthetical weights of symptoms, then the hybrid reasoning is adopted to work out the diseases suffered and their probabilities, after that, backward reasoning is activated to obtain the details of the diseases and send them back to users. Finally, the cases satisfied by users would be recorded in the temporary case database automatically, waiting for the experts' checking later. The experimental results show that the proposed method not only has a scientific theoretical foundation, but also a high practical value.},
  doi       = {10.1109/ICICTA.2010.736},
  file      = {:Yuan2010 - Research of Vannamei Expert System Based on CBR and Grey AHP.pdf:PDF},
  keywords  = {aquaculture;case-based reasoning;decision making;diseases;expert systems;grey systems;vannamei expert system;case based reasoning;grey AHP;analytic hierarchy process;inference engine;group method;disease;Expert systems;Diseases;Diagnostic expert systems;Marine technology;Automation;Educational institutions;Information technology;Oceans;Electronic mail;Engines;Grey AHP;CBR;Groups method;Expert System},
}
@Article{Zhou2018,
  author    = {Zhou, Chao and Lin, Kai and Xu, Daming and Chen, Lan and Guo, Qiang and Sun, Chuanheng and Yang, Xinting},
  title     = {Near infrared computer vision and neuro-fuzzy model-based feeding decision system for fish in aquaculture},
  journal   = {Computers and Electronics in Agriculture},
  year      = {2018},
  volume    = {146},
  pages     = {114 - 124},
  issn      = {0168-1699},
  note      = {Adaptive network based fuzzy inference system;Automatic adjustment;Delau-nay triangulations;Feeding behavior;Implementation process;Near- infrared images;Theoretical foundations;Water quality parameters;},
  abstract  = {In aquaculture, the feeding efficiency of fish is of great significance for improving production and reducing costs. In recent years, automatic adjustments of the feeding amount based on the needs of the fish have become a developing trend. The purpose of this study was to achieve automatic feeding decision making based on the appetite of fish. In this study, a feeding control method based on near infrared computer vision and neuro-fuzzy model was proposed. The specific objectives of this study were as follows: (1) to develop an algorithm to extract an index that can describe and quantify the feeding behavior of fish in near infrared images, (2) to design an algorithm to realize feeding decision (continue or stop) during the feeding process, and (3) to evaluate the performance of the method. The specific implementation process of this study was as follows: (1) the quantitative index of feeding behavior (flocking level and snatching strength) was extracted by Delaunay Triangulation and image texture; (2) the adaptive network-based fuzzy inference system (ANFIS) was established based on fuzzy control rules and used to achieve automatically on-demand feeding; and (3) the performance of the method was evaluated by the specific growth rate, weight gain rate, feed conversion rate and water quality parameters. The results indicated that the feeding decision accuracy of the ANFIS model was 98\%. In addition, compared with the feeding table, although this method did not present significant differences in promoting fish growth, the feed conversion rate (FCR) can be reduced by 10.77\% and water pollution can also be reduced. This system provides an important contribution to realizing the real-time control of fish feeding processes and feeding decision on demand, and it lays a theoretical foundation for developing fine feeding equipment and guiding practice.},
  copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
  doi       = {10.1016/j.compag.2018.02.006},
  key       = {Feeding},
  keywords  = {Adaptive control systems;Aquaculture;Computer vision;Decision making;Fish;Fuzzy control;Fuzzy inference;Fuzzy logic;Fuzzy neural networks;Fuzzy systems;Image processing;Image texture;Infrared devices;Infrared imaging;Intelligent control;Process control;Real time control;Water pollution;Water quality;},
  language  = {English},
}

@Article{OMara2015,
  author    = {O'Mara, Aidan and Shahriar, Md Sumon},
  title     = {Short-term prediction of marine sensor data with fuzzy clustering},
  journal   = {International Journal of Pattern Recognition and Artificial Intelligence},
  year      = {2015},
  volume    = {29},
  number    = {3},
  issn      = {02180014},
  note      = {Conductivity data;Environmental Monitoring;Fuzzy pattern;Marine sensors;Novel techniques;Short term;Short term prediction;Water quality variables;},
  abstract  = {In predicting water quality variables in the short term, a novel technique using fuzzy pattern similarity-based fuzzy clustering has been proposed. The experimental results show that the proposed method outperforms than existing similar methods for sea water temperature and conductivity data sets from a marine sensor network for environmental monitoring. The short-term prediction of water quality variables has immense benefit in aquaculture and fisheries industries for decision-making purposes.<br/> &copy; 2015 World Scientific Publishing Company.},
  copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
  key       = {Forecasting},
  keywords  = {Decision making;Fuzzy clustering;Pattern recognition;Seawater;Sensor networks;Water quality;},
  language  = {English},
  url       = {http://dx.doi.org/10.1142/S0218001415500159},
}
@Article{Duan2018,
  author    = {Duan, Qingling and Liu, Yiran and Zhang, Lu and Li, Daoliang},
  title     = {State-of-the-art review for application of big data technology in aquaculture},
  journal   = {Nongye Jixie Xuebao/Transactions of the Chinese Society for Agricultural Machinery},
  year      = {2018},
  volume    = {49},
  number    = {6},
  pages     = {1 - 16},
  issn      = {10001298},
  note      = {Analysis techniques;Aquaculture industry;Automatic decision;Big data platforms;Big data technologies;Development trends;Intelligent analysis;State-of-the art reviews;},
  abstract  = {It has many difficulties in monitoring and detection accurately and optimal control in aquaculture because the targets are so special and environment is so sophisticated that contributes too many impact factors. Big data technology, as well as mathematical models are used to process and analyze the large scale of data producing in aquaculture industry and the useful results are presented to producers and decision makers in intuitive form, which is the fundamental way to solve the above problems. The research progress and development trend of the applications of big data technology in aquaculture were deeply discussed. Firstly, the overall architecture of applying big data technology in aquaculture was proposed and the data sources and data acquisition tools were listed. Then, several kinds of analysis techniques, which had been well applied to deal with the existing problems in aquaculture, were mainly summarized and the several current big data platforms and the services they provided for aquaculture were introduced. Finally, in view of solving the difficulties and challenges faced in the process of applying big data technologies in aquaculture, the research future in this field was proposed form the aspects of comprehensive awareness, intelligent analysis, automatic decision-making, and big data standard system construction of aquaculture. In the applications of big data technology in aquaculture, data is the basis and analysis is the core. The ultimate goal is to take advantage of big data technology to improve the comprehensive productivity and efficiency of aquaculture. In order to achieve it, the actual demands in aquaculture should be greatly concerned. In addition, data of the whole industry chain in aquaculture should be integrated and the basic theories and core key technologies should be studied intensively and thoroughly. In this way, the application of big data technology in aquaculture will be deeper and the integration of the two will be closer, which will support the complete transformation and upgrading of China aquaculture industry.<br/> &copy; 2018, Chinese Society of Agricultural Machinery. All right reserved.},
  copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
  key       = {Big data},
  keywords  = {Aquaculture;Data acquisition;Data mining;Decision making;Metadata;},
  language  = {Chinese},
  url       = {http://dx.doi.org/10.6041/j.issn.1000-1298.2018.06.001},
}

@article{linnainmaa1970representation,
  title={The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors},
  author={Linnainmaa, Seppo},
  journal={Master's Thesis (in Finnish), Univ. Helsinki},
  pages={6--7},
  year={1970}
}

@article{kelley1960gradient,
  title={Gradient theory of optimal flight paths},
  author={Kelley, Henry J},
  journal={Ars Journal},
  volume={30},
  number={10},
  pages={947--954},
  year={1960}
}
@inproceedings{lime,
  author    = {Marco Tulio Ribeiro and
               Sameer Singh and
               Carlos Guestrin},
  title     = {"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
  booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on
               Knowledge Discovery and Data Mining, San Francisco, CA, USA, August
               13-17, 2016},
  pages     = {1135--1144},
  year      = {2016},
}
@article{shap,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott and Lee, Su-In},
  journal={arXiv preprint arXiv:1705.07874},
  year={2017}
}
@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of control, signals and systems},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}
}
@article{ZHOU2020787,
title = {Universality of deep convolutional neural networks},
journal = {Applied and Computational Harmonic Analysis},
volume = {48},
number = {2},
pages = {787-794},
year = {2020},
issn = {1063-5203},
doi = {https://doi.org/10.1016/j.acha.2019.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S1063520318302045},
author = {Ding-Xuan Zhou},
keywords = {Deep learning, Convolutional neural network, Universality, Approximation theory},
abstract = {Deep learning has been widely applied and brought breakthroughs in speech recognition, computer vision, and many other domains. Deep neural network architectures and computational issues have been well studied in machine learning. But there lacks a theoretical foundation for understanding the approximation or generalization ability of deep learning methods generated by the network architectures such as deep convolutional neural networks. Here we show that a deep convolutional neural network (CNN) is universal, meaning that it can be used to approximate any continuous function to an arbitrary accuracy when the depth of the neural network is large enough. This answers an open question in learning theory. Our quantitative estimate, given tightly in terms of the number of free parameters to be computed, verifies the efficiency of deep CNNs in dealing with large dimensional data. Our study also demonstrates the role of convolutions in deep CNNs.}
}
@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}
@article{lecun1989backpropagation,
  title={Backpropagation applied to handwritten zip code recognition},
  author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  journal={Neural computation},
  volume={1},
  number={4},
  pages={541--551},
  year={1989},
  publisher={MIT Press}
}
@article{fukushima1979neural,
  title={Neural network model for a mechanism of pattern recognition unaffected by shift in position-Neocognitron},
  author={Fukushima, Kunihiko},
  journal={IEICE Technical Report, A},
  volume={62},
  number={10},
  pages={658--665},
  year={1979}
}
@inproceedings{ye2020applying,
  title={Applying class-to-class siamese networks to explain classifications with supportive and contrastive cases},
  author={Ye, Xiaomeng and Leake, David and Huibregtse, William and Dalkilic, Mehmet},
  booktitle={International Conference on Case-Based Reasoning},
  pages={245--260},
  year={2020},
  organization={Springer}
}
@article{mathisen2021using,
  title={Using extended siamese networks to provide decision support in aquaculture operations},
  author={Mathisen, Bj{\o}rn Magnus and Bach, Kerstin and Aamodt, Agnar},
  journal={Applied Intelligence},
  pages={1--12},
  year={2021},
  publisher={Springer}
}
@article{khan-2021-bayes-learn-rule,
  author =       {Khan, Mohammad Emtiyaz and Rue, H{\aa}vard},
  title =        {The Bayesian Learning Rule},
  journal =      {CoRR},
  year =         2021,
  url =          {http://arxiv.org/abs/2107.04562v1},
  abstract =     {We show that many machine-learning algorithms are specific
                  instances of a single algorithm called the Bayesian learning
                  rule. The rule, derived from Bayesian principles, yields a
                  wide-range of algorithms from fields such as optimization,
                  deep learning, and graphical models. This includes classical
                  algorithms such as ridge regression, Newton's method, and
                  Kalman filter, as well as modern deep-learning algorithms such
                  as stochastic-gradient descent, RMSprop, and Dropout. The key
                  idea in deriving such algorithms is to approximate the
                  posterior using candidate distributions estimated by using
                  natural gradients. Different candidate distributions result in
                  different algorithms and further approximations to natural
                  gradients give rise to variants of those algorithms. Our work
                  not only unifies, generalizes, and improves existing
                  algorithms, but also helps us design new ones.},
  archivePrefix ={arXiv},
  eprint =       {2107.04562},
  primaryClass = {stat.ML},
}
@article{chen-2020-explor-simpl,
  author =       {Chen, Xinlei and He, Kaiming},
  title =        {Exploring Simple Siamese Representation Learning},
  journal =      {CoRR},
  year =         2020,
  url =          {http://arxiv.org/abs/2011.10566v1},
  abstract =     {Siamese networks have become a common structure in various
                  recent models for unsupervised visual representation learning.
                  These models maximize the similarity between two augmentations
                  of one image, subject to certain conditions for avoiding
                  collapsing solutions. In this paper, we report surprising
                  empirical results that simple Siamese networks can learn
                  meaningful representations even using none of the following:
                  (i) negative sample pairs, (ii) large batches, (iii) momentum
                  encoders. Our experiments show that collapsing solutions do
                  exist for the loss and structure, but a stop-gradient
                  operation plays an essential role in preventing collapsing. We
                  provide a hypothesis on the implication of stop-gradient, and
                  further show proof-of-concept experiments verifying it. Our
                  "SimSiam" method achieves competitive results on ImageNet and
                  downstream tasks. We hope this simple baseline will motivate
                  people to rethink the roles of Siamese architectures for
                  unsupervised representation learning. Code will be made
                  available.},
  archivePrefix ={arXiv},
  eprint =       {2011.10566},
  primaryClass = {cs.CV},
}
@article{mukherjee2019,
  author={Mukherjee1, Sudipto and Asnani1, Himanshu and Lin1, Eugene and Kannan1, Sreeram},
  title={ClusterGAN : Latent Space Clustering in Generative Adversarial Networks},
  archivePrefix ={arXiv},
  url =          {http://arxiv.org/abs/2011.03627},
  eprint =       {1809.03627},
  primaryClass = {cs.CV},
  journal={CoRR}
}
@article{long-2014-fully-convol,
  author          = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  title           = {Fully Convolutional Networks for Semantic Segmentation},
  journal         = {CoRR},
  year            = 2014,
  url             = {http://arxiv.org/abs/1411.4038v2},
  abstract        = {Convolutional networks are powerful visual models that
                  yield hierarchies of features. We show that convolutional
                  networks by themselves, trained end-to-end, pixels-to-pixels,
                  exceed the state-of-the-art in semantic segmentation. Our key
                  insight is to build "fully convolutional" networks that take
                  input of arbitrary size and produce correspondingly-sized
                  output with efficient inference and learning. We define and
                  detail the space of fully convolutional networks, explain
                  their application to spatially dense prediction tasks, and
                  draw connections to prior models. We adapt contemporary
                  classification networks (AlexNet, the VGG net, and GoogLeNet)
                  into fully convolutional networks and transfer their learned
                  representations by fine-tuning to the segmentation task. We
                  then define a novel architecture that combines semantic
                  information from a deep, coarse layer with appearance
                  information from a shallow, fine layer to produce accurate and
                  detailed segmentations. Our fully convolutional network
                  achieves state-of-the-art segmentation of PASCAL VOC (20 \%
                  relative improvement to 62.2 \% mean IU on 2012), NYUDv2, and
                  SIFT Flow, while inference takes one third of a second for a
                  typical image.},
  archivePrefix   = {arXiv},
  eprint          = {1411.4038},
  primaryClass    = {cs.CV},
}
@article{xie-2017-adver-examp,
  author          = {Xie, Cihang and Wang, Jianyu and Zhang, Zhishuai and Zhou,
                  Yuyin and Xie, Lingxi and Yuille, Alan},
  title           = {Adversarial Examples for Semantic Segmentation and Object
                  Detection},
  journal         = {CoRR},
  year            = 2017,
  url             = {http://arxiv.org/abs/1703.08603v3},
  abstract        = {It has been well demonstrated that adversarial examples,
                  i.e., natural images with visually imperceptible perturbations
                  added, generally exist for deep networks to fail on image
                  classification. In this paper, we extend adversarial examples
                  to semantic segmentation and object detection which are much
                  more difficult. Our observation is that both segmentation and
                  detection are based on classifying multiple targets on an
                  image (e.g., the basic target is a pixel or a receptive field
                  in segmentation, and an object proposal in detection), which
                  inspires us to optimize a loss function over a set of
                  pixels/proposals for generating adversarial perturbations.
                  Based on this idea, we propose a novel algorithm named Dense
                  Adversary Generation (DAG), which generates a large family of
                  adversarial examples, and applies to a wide range of
                  state-of-the-art deep networks for segmentation and detection.
                  We also find that the adversarial perturbations can be
                  transferred across networks with different training data,
                  based on different architectures, and even for different
                  recognition tasks. In particular, the transferability across
                  networks with the same architecture is more significant than
                  in other cases. Besides, summing up heterogeneous
                  perturbations often leads to better transfer performance,
                  which provides an effective method of black-box adversarial
                  attack.},
  archivePrefix   = {arXiv},
  eprint          = {1703.08603},
  primaryClass    = {cs.CV},
}
@inproceedings{katole-2015-hierar-deep,
  author          = {Atul Laxman Katole and Krishna Prasad Yellapragada and
                  Amish Kumar Bedi and Sehaj Singh Kalra and Mynepalli Siva
                  Chaitanya},
  title           = {Hierarchical Deep Learning Architecture for 10K Objects
                  Classification},
  booktitle       = {Computer Science \& Information Technology ( CS \& IT )},
  year            = 2015,
  pages           = {nil},
  doi             = {10.5121/csit.2015.51408},
  url             = {https://doi.org/10.5121/csit.2015.51408},
  month           = 8,
}
@article{olmo-2020-not-all,
  author          = {Olmo, Alberto and Sengupta, Sailik and Kambhampati,
                  Subbarao},
  title           = {Not All Failure Modes Are Created Equal: Training Deep
                  Neural Networks for Explicable (Mis)Classification},
  journal         = {CoRR},
  year            = 2020,
  url             = {http://arxiv.org/abs/2006.14841v1},
  abstract        = {Deep Neural Networks are often brittle on image
                  classification tasks and known to misclassify inputs. While
                  these misclassifications may be inevitable, all failure modes
                  cannot be considered equal. Certain misclassifications (eg.
                  classifying the image of a dog to an airplane) can create
                  surprise and result in the loss of human trust in the system.
                  Even worse, certain errors (eg. a person misclassified as a
                  primate) can have societal impacts. Thus, in this work, we aim
                  to reduce inexplicable errors. To address this challenge, we
                  first discuss how to obtain the class-level semantics that
                  captures the human's expectation ($M^h$) regarding which
                  classes are semantically close vs. ones that are far away. We
                  show that for data-sets like CIFAR-10 and CIFAR-100,
                  class-level semantics can be obtained by leveraging human
                  subject studies (significantly inexpensive compared to
                  existing works) and, whenever possible, by utilizing publicly
                  available human-curated knowledge. Second, we propose the use
                  of Weighted Loss Functions to penalize misclassifications by
                  the weight of their inexplicability. Finally, we show that
                  training (or even fine-tuning) existing classifiers with the
                  two proposed methods lead to Deep Neural Networks that have
                  (1) comparable top-1 accuracy, an important metric in
                  operational contexts, (2) more explicable failure modes and
                  (3) require significantly less cost in teams of additional
                  human labels compared to existing work.},
  archivePrefix   = {arXiv},
  eprint          = {2006.14841},
  primaryClass    = {cs.LG},
}
@article{peterson-2019-human-uncer,
  author          = {Peterson, Joshua C. and Battleday, Ruairidh M. and
                  Griffiths, Thomas L. and Russakovsky, Olga},
  title           = {Human Uncertainty Makes Classification More Robust},
  journal         = {CoRR},
  year            = 2019,
  url             = {http://arxiv.org/abs/1908.07086v1},
  abstract        = {The classification performance of deep neural networks has
                  begun to asymptote at near-perfect levels. However, their
                  ability to generalize outside the training set and their
                  robustness to adversarial attacks have not. In this paper, we
                  make progress on this problem by training with full label
                  distributions that reflect human perceptual uncertainty. We
                  first present a new benchmark dataset which we call CIFAR10H,
                  containing a full distribution of human labels for each image
                  of the CIFAR10 test set. We then show that, while contemporary
                  classifiers fail to exhibit human-like uncertainty on their
                  own, explicit training on our dataset closes this gap,
                  supports improved generalization to increasingly
                  out-of-training-distribution test datasets, and confers
                  robustness to adversarial attacks.},
  archivePrefix   = {arXiv},
  eprint          = {1908.07086},
  primaryClass    = {cs.CV},
}
@article{li-2017-deep-learn,
  author          = {Li, Oscar and Liu, Hao and Chen, Chaofan and Rudin,
                  Cynthia},
  title           = {Deep Learning for Case-Based Reasoning Through Prototypes:
                  a Neural Network That Explains Its Predictions},
  journal         = {CoRR},
  year            = 2017,
  url             = {http://arxiv.org/abs/1710.04806v2},
  abstract        = {Deep neural networks are widely used for classification.
                  These deep models often suffer from a lack of interpretability
                  -- they are particularly difficult to understand because of
                  their non-linear nature. As a result, neural networks are
                  often treated as "black box" models, and in the past, have
                  been trained purely to optimize the accuracy of predictions.
                  In this work, we create a novel network architecture for deep
                  learning that naturally explains its own reasoning for each
                  prediction. This architecture contains an autoencoder and a
                  special prototype layer, where each unit of that layer stores
                  a weight vector that resembles an encoded training input. The
                  encoder of the autoencoder allows us to do comparisons within
                  the latent space, while the decoder allows us to visualize the
                  learned prototypes. The training objective has four terms: an
                  accuracy term, a term that encourages every prototype to be
                  similar to at least one encoded input, a term that encourages
                  every encoded input to be close to at least one prototype, and
                  a term that encourages faithful reconstruction by the
                  autoencoder. The distances computed in the prototype layer are
                  used as part of the classification process. Since the
                  prototypes are learned during training, the learned network
                  naturally comes with explanations for each prediction, and the
                  explanations are loyal to what the network actually computes.},
  archivePrefix   = {arXiv},
  eprint          = {1710.04806},
  primaryClass    = {cs.AI},
}
@article{ribeiro-2016-why-shoul,
  author          = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin,
                  Carlos},
  title           = {"Why Should I Trust You?": Explaining the Predictions of
                  Any Classifier},
  journal         = {CoRR},
  year            = 2016,
  url             = {http://arxiv.org/abs/1602.04938v3},
  abstract        = {Despite widespread adoption, machine learning models remain
                  mostly black boxes. Understanding the reasons behind
                  predictions is, however, quite important in assessing trust,
                  which is fundamental if one plans to take action based on a
                  prediction, or when choosing whether to deploy a new model.
                  Such understanding also provides insights into the model,
                  which can be used to transform an untrustworthy model or
                  prediction into a trustworthy one. In this work, we propose
                  LIME, a novel explanation technique that explains the
                  predictions of any classifier in an interpretable and faithful
                  manner, by learning an interpretable model locally around the
                  prediction. We also propose a method to explain models by
                  presenting representative individual predictions and their
                  explanations in a non-redundant way, framing the task as a
                  submodular optimization problem. We demonstrate the
                  flexibility of these methods by explaining different models
                  for text (e.g. random forests) and image classification (e.g.
                  neural networks). We show the utility of explanations via
                  novel experiments, both simulated and with human subjects, on
                  various scenarios that require trust: deciding if one should
                  trust a prediction, choosing between models, improving an
                  untrustworthy classifier, and identifying why a classifier
                  should not be trusted.},
  archivePrefix   = {arXiv},
  eprint          = {1602.04938},
  primaryClass    = {cs.LG},
}
@article{vstrumbelj2014explaining,
  title={Explaining prediction models and individual predictions with feature contributions},
  author={{\v{S}}trumbelj, Erik and Kononenko, Igor},
  journal={Knowledge and information systems},
  volume={41},
  number={3},
  pages={647--665},
  year={2014},
  publisher={Springer}
}
@article{camburu-2020-explain-deep,
  author          = {Camburu, Oana-Maria},
  title           = {Explaining Deep Neural Networks},
  journal         = {CoRR},
  year            = 2020,
  url             = {http://arxiv.org/abs/2010.01496v2},
  abstract        = {Deep neural networks are becoming more and more popular due
                  to their revolutionary success in diverse areas, such as
                  computer vision, natural language processing, and speech
                  recognition. However, the decision-making processes of these
                  models are generally not interpretable to users. In various
                  domains, such as healthcare, finance, or law, it is critical
                  to know the reasons behind a decision made by an artificial
                  intelligence system. Therefore, several directions for
                  explaining neural models have recently been explored. In this
                  thesis, I investigate two major directions for explaining deep
                  neural networks. The first direction consists of feature-based
                  post-hoc explanatory methods, that is, methods that aim to
                  explain an already trained and fixed model (post-hoc), and
                  that provide explanations in terms of input features, such as
                  tokens for text and superpixels for images (feature-based).
                  The second direction consists of self-explanatory neural
                  models that generate natural language explanations, that is,
                  models that have a built-in module that generates explanations
                  for the predictions of the model.},
  archivePrefix   = {arXiv},
  eprint          = {2010.01496},
  primaryClass    = {cs.CL},
}
@article{liu-2016-delvin-into,
  author          = {Liu, Yanpei and Chen, Xinyun and Liu, Chang and Song, Dawn},
  title           = {Delving Into Transferable Adversarial Examples and
                  Black-Box Attacks},
  journal         = {CoRR},
  year            = 2016,
  url             = {http://arxiv.org/abs/1611.02770v3},
  abstract        = {An intriguing property of deep neural networks is the
                  existence of adversarial examples, which can transfer among
                  different architectures. These transferable adversarial
                  examples may severely hinder deep neural network-based
                  applications. Previous works mostly study the transferability
                  using small scale datasets. In this work, we are the first to
                  conduct an extensive study of the transferability over large
                  models and a large scale dataset, and we are also the first to
                  study the transferability of targeted adversarial examples
                  with their target labels. We study both non-targeted and
                  targeted adversarial examples, and show that while
                  transferable non-targeted adversarial examples are easy to
                  find, targeted adversarial examples generated using existing
                  approaches almost never transfer with their target labels.
                  Therefore, we propose novel ensemble-based approaches to
                  generating transferable adversarial examples. Using such
                  approaches, we observe a large proportion of targeted
                  adversarial examples that are able to transfer with their
                  target labels for the first time. We also present some
                  geometric studies to help understanding the transferable
                  adversarial examples. Finally, we show that the adversarial
                  examples generated using ensemble-based approaches can
                  successfully attack Clarifai.com, which is a black-box image
                  classification system.},
  archivePrefix   = {arXiv},
  eprint          = {1611.02770},
  primaryClass    = {cs.LG},
}
@article{ren-2019-likel-ratios,
  author          = {Ren, Jie and Liu, Peter J. and Fertig, Emily and Snoek,
                  Jasper and Poplin, Ryan and DePristo, Mark A. and Dillon,
                  Joshua V. and Lakshminarayanan, Balaji},
  title           = {Likelihood Ratios for Out-Of-Distribution Detection},
  journal         = {CoRR},
  year            = 2019,
  url             = {http://arxiv.org/abs/1906.02845v2},
  abstract        = {Discriminative neural networks offer little or no
                  performance guarantees when deployed on data not generated by
                  the same process as the training distribution. On such
                  out-of-distribution (OOD) inputs, the prediction may not only
                  be erroneous, but confidently so, limiting the safe deployment
                  of classifiers in real-world applications. One such
                  challenging application is bacteria identification based on
                  genomic sequences, which holds the promise of early detection
                  of diseases, but requires a model that can output low
                  confidence predictions on OOD genomic sequences from new
                  bacteria that were not present in the training data. We
                  introduce a genomics dataset for OOD detection that allows
                  other researchers to benchmark progress on this important
                  problem. We investigate deep generative model based approaches
                  for OOD detection and observe that the likelihood score is
                  heavily affected by population level background statistics. We
                  propose a likelihood ratio method for deep generative models
                  which effectively corrects for these confounding background
                  statistics. We benchmark the OOD detection performance of the
                  proposed method against existing approaches on the genomics
                  dataset and show that our method achieves state-of-the-art
                  performance. We demonstrate the generality of the proposed
                  method by showing that it significantly improves OOD detection
                  when applied to deep generative models of images.},
  archivePrefix   = {arXiv},
  eprint          = {1906.02845},
  primaryClass    = {stat.ML},
}
@article{hemmer2018fault,
  title={Fault classification of axial and radial roller bearings using transfer learning through a pretrained convolutional neural network},
  author={Hemmer, Martin and Van Khang, Huynh and Robbersmyr, Kjell G and Waag, Tor I and Meyer, Thomas JJ},
  journal={Designs},
  volume={2},
  number={4},
  pages={56},
  year={2018},
  publisher={Multidisciplinary Digital Publishing Institute}
}
@article{zhou-2018-revis-impor,
  author          = {Zhou, Bolei and Sun, Yiyou and Bau, David and Torralba,
                  Antonio},
  title           = {Revisiting the Importance of Individual Units in Cnns Via
                  Ablation},
  journal         = {CoRR},
  year            = 2018,
  url             = {http://arxiv.org/abs/1806.02891v1},
  abstract        = {We revisit the importance of the individual units in
                  Convolutional Neural Networks (CNNs) for visual recognition.
                  By conducting unit ablation experiments on CNNs trained on
                  large scale image datasets, we demonstrate that, though
                  ablating any individual unit does not hurt overall
                  classification accuracy, it does lead to significant damage on
                  the accuracy of specific classes. This result shows that an
                  individual unit is specialized to encode information relevant
                  to a subset of classes. We compute the correlation between the
                  accuracy drop under unit ablation and various attributes of an
                  individual unit such as class selectivity and weight L1 norm.
                  We confirm that unit attributes such as class selectivity are
                  a poor predictor for impact on overall accuracy as found
                  previously in recent work \cite{morcos2018importance}.
                  However, our results show that class selectivity along with
                  other attributes are good predictors of the importance of one
                  unit to individual classes. We evaluate the impact of random
                  rotation, batch normalization, and dropout to the importance
                  of units to specific classes. Our results show that units with
                  high selectivity play an important role in network
                  classification power at the individual class level.
                  Understanding and interpreting the behavior of these units is
                  necessary and meaningful.},
  archivePrefix   = {arXiv},
  eprint          = {1806.02891},
  primaryClass    = {cs.CV},
}
@inproceedings{eykholt2018robust,
  title={Robust physical-world attacks on deep learning visual classification},
  author={Eykholt, Kevin and Evtimov, Ivan and Fernandes, Earlence and Li, Bo and Rahmati, Amir and Xiao, Chaowei and Prakash, Atul and Kohno, Tadayoshi and Song, Dawn},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1625--1634},
  year={2018}
}
@inproceedings{nguyen2015deep,
  title={Deep neural networks are easily fooled: High confidence predictions for unrecognizable images},
  author={Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={427--436},
  year={2015}
}
@article{li-2021-trocr,
  author          = {Li, Minghao and Lv, Tengchao and Cui, Lei and Lu, Yijuan
                  and Florencio, Dinei and Zhang, Cha and Li, Zhoujun and Wei,
                  Furu},
  title           = {Trocr: Transformer-Based Optical Character Recognition With
                  Pre-Trained Models},
  journal         = {CoRR},
  year            = 2021,
  url             = {http://arxiv.org/abs/2109.10282v3},
  abstract        = {Text recognition is a long-standing research problem for
                  document digitalization. Existing approaches for text
                  recognition are usually built based on CNN for image
                  understanding and RNN for char-level text generation. In
                  addition, another language model is usually needed to improve
                  the overall accuracy as a post-processing step. In this paper,
                  we propose an end-to-end text recognition approach with
                  pre-trained image Transformer and text Transformer models,
                  namely TrOCR, which leverages the Transformer architecture for
                  both image understanding and wordpiece-level text generation.
                  The TrOCR model is simple but effective, and can be
                  pre-trained with large-scale synthetic data and fine-tuned
                  with human-labeled datasets. Experiments show that the TrOCR
                  model outperforms the current state-of-the-art models on both
                  printed and handwritten text recognition tasks. The code and
                  models will be publicly available at https://aka.ms/TrOCR.},
  archivePrefix   = {arXiv},
  eprint          = {2109.10282},
  primaryClass    = {cs.CL},
}
@article{dosovitskiy-2020-image-is,
  author          = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov,
                  Alexander and Weissenborn, Dirk and Zhai, Xiaohua and
                  Unterthiner, Thomas and Dehghani, Mostafa and Minderer,
                  Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit,
                  Jakob and Houlsby, Neil},
  title           = {An Image Is Worth 16x16 Words: Transformers for Image
                  Recognition At Scale},
  journal         = {CoRR},
  year            = 2020,
  url             = {http://arxiv.org/abs/2010.11929v2},
  abstract        = {While the Transformer architecture has become the de-facto
                  standard for natural language processing tasks, its
                  applications to computer vision remain limited. In vision,
                  attention is either applied in conjunction with convolutional
                  networks, or used to replace certain components of
                  convolutional networks while keeping their overall structure
                  in place. We show that this reliance on CNNs is not necessary
                  and a pure transformer applied directly to sequences of image
                  patches can perform very well on image classification tasks.
                  When pre-trained on large amounts of data and transferred to
                  multiple mid-sized or small image recognition benchmarks
                  (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT)
                  attains excellent results compared to state-of-the-art
                  convolutional networks while requiring substantially fewer
                  computational resources to train.},
  archivePrefix   = {arXiv},
  eprint          = {2010.11929},
  primaryClass    = {cs.CV},
}
@article{moosavi-dezfooli-2016-univer-adver-pertur,
  author          = {Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and
                  Fawzi, Omar and Frossard, Pascal},
  title           = {Universal Adversarial Perturbations},
  journal         = {CoRR},
  year            = 2016,
  url             = {http://arxiv.org/abs/1610.08401v3},
  abstract        = {Given a state-of-the-art deep neural network classifier, we
                  show the existence of a universal (image-agnostic) and very
                  small perturbation vector that causes natural images to be
                  misclassified with high probability. We propose a systematic
                  algorithm for computing universal perturbations, and show that
                  state-of-the-art deep neural networks are highly vulnerable to
                  such perturbations, albeit being quasi-imperceptible to the
                  human eye. We further empirically analyze these universal
                  perturbations and show, in particular, that they generalize
                  very well across neural networks. The surprising existence of
                  universal perturbations reveals important geometric
                  correlations among the high-dimensional decision boundary of
                  classifiers. It further outlines potential security breaches
                  with the existence of single directions in the input space
                  that adversaries can possibly exploit to break a classifier on
                  most natural images.},
  archivePrefix   = {arXiv},
  eprint          = {1610.08401},
  primaryClass    = {cs.CV},
}
@article{deodato2020bayesian,
  title={Bayesian neural networks for cellular image classification and uncertainty analysis},
  author={Deodato, Giacomo and Ball, Christopher and Zhang, Xian},
  journal={bioRxiv},
  pages={824862},
  year={2020},
  publisher={Cold Spring Harbor Laboratory}
}
